---
title: 高并发系统优化
date: 2017-07-20
tags: 
	- 高并发
	- 优化
categories:
    - 优化
keywords: 高并发,系统优化
description: 对于高并发系统怎么样才能把系统优化的更好？响应时间更短？速度更快？总结一些工作中的经验来看一下。
---

现在社会尤其是电商互联网促销方式的出现，造成的网站面临着并发量越来越大的问题，对于这个状况如果解决不好将严重影响系统的响应速度，严重的情况下可能会造成服务器宕机等极其恶劣的影响，那么该如何解决或者说优化这个问题呢？根据实际工作中涉及到的方方面面，大体可以归结为以下几点：

### 应用和静态资源分离 ###

刚开始的时候应用和静态资源是保存在一起的，当并发量达到一定程度时就需要将静态资源保存到专门的服务器中，静态资源主要包括图片、视频、js、css和一些资源文件等，这些文件因为没有状态，所以分离比较简单，直接存放到相应的服务器就可以了，一般会使用专门的域名去访问，比如，京东的图片保存在img**.jd.com二级域名服务器上，通过不同的域名可以让浏览器直接访问资源服务器而不需要再访问应用服务器了。

对于js、css和一些资源文件，可以直接放在资源服务器上，但是对于图片这种最常见的做法是建立单独的图片服务器，会使用到类似HDFS这种技术的分布式文件存储，同时一般会提供多个不同的域名，这些不同的域名都可以访问到相同的图片信息，这样的好处是：如果一个页面有很多图片的时候，对于一个域名的并发访问时有限制的，如果只是一个域名，那么加载图片就会出现排队加载的情况，提供多个域名，并发量就上去了，加载页面速度也就提供高了。

### 页面缓存 ###
顾名思义页面缓存就是把内容缓存在客户端cookie的作法，这种技术一般是对于不经常发生数据变化的页面，技术实现比较简单就是在HTML的头部加入以下代码

	<HEAD> 
		<META HTTP-EQUIV="Pragma" CONTENT="no-cache"> 
		<META HTTP-EQUIV="Cache-Control" CONTENT="no-cache"> 
		<META HTTP-EQUIV="Expires" CONTENT="0"> 
	</HEAD>
> 说明：HTTP头信息“Expires”和“Cache-Control”为应用程序服务器提供了一个控制浏览器和代理服务器上缓存的机制。HTTP头信息Expires告诉代理服务器它的缓存页面何时将过期。HTTP1.1规范中新定义的头信息Cache-Control可以通知浏览器不缓存任何页面。当点击后退按钮时，浏览器重新访问服务器已获取页面。
> 
> Cache-Control的常用的参数：
> 
- no-cache，浏览器和缓存服务器都不应该缓存页面信息；
- public，浏览器和缓存服务器都可以缓存页面信息；
- no-store，请求和响应的信息都不应该被存储在对方的磁盘系统中；
- must-revalidate，对于客户机的每次请求，代理服务器必须想服务器验证缓存是否过时；

> Last-Modified 指页面的最后生成时间，GMT格式；

> expires 过期时限值，GMT格式，指浏览器或缓存服务器在该时间点后必须从服务器中获取新的页面信息；

> 上面两个值在JSP中设置值为字符型的GMT格式，无法生效，设置long类型才生效；

### 集群与分布式 ###
什么是集群什么是分布式？简单的说就是：

集群：同一个业务，部署在多个服务器上，同时对外提供服务，可以形成容灾以及提供并发支持数等

分布式：一个业务分拆多个子业务，部署在不同的服务器上，不同业务之间相互独立，减少不必要的影响，提高响应，对于某个子业务挂掉的情况下不影响其他的子业务的运行。

一般在大型网站的生产环境，这两种技术是同时应用的，业务在拆分成多个子业务的前提下，再把每个子业务部署到集群环境中去。现在比较大型的公司基本上都是使用云技术，在物理机上搭建许多docker服务器提供云服务，很方便应用的扩容和缩容。

### 反向代理 ###

基本上的思路呢就是服务器端的负载均衡器，客户端只能感知到代理服务器而不会知道具体是哪个服务器提供的处理。
![反向代理](https://github.com/gamesdoa/img0/raw/master/optimization/reverse-proxy.jpg)

反向代理的实现

1. 需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上
2. 服务器返回服务处理之后的结果到负载均衡设备
3. 负载均衡将服务器的服务返回用户
> 通俗的说用户和负载均衡设备直接通信，也意味着用户做服务器域名解析时，解析得到的IP其实是负载均衡的IP，而不是服务器的IP，这样有一个好处是，当新加入/移走服务器时，仅仅需要修改负载均衡的服务器列表，而不会影响现有的服务。

### CDN ###
CDN的全称是Content Delivery Network，即**内容分发网络**。

其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。

#### 关键技术 ####
 - 内容发布：它借助于建立索引、缓存、流分裂、组播（Multicast）等技术，将内容发布或投递到距离用户最近的远程服务点（POP）处；
 - 内容路由：它是整体性的网络负载均衡技术，通过内容路由器中的重定向（DNS）机制，在多个远程POP上均衡用户的请求，以使用户请求得到最近内容源的响应；
 - 内容交换：它根据内容的可用性、服务器的可用性以及用户的背景，在POP的缓存服务器上，利用应用层交换、流分裂、重定向（ICP、WCCP）等技术，智能地平衡负载流量；
 - 性能管理：它通过内部和外部监控系统，获取网络部件的状况信息，测量内容发布的端到端性能（如包丢失、延时、平均带宽、启动时间、帧速率等），保证网络处于最佳的运行状态。

#### 主要特点 ####
1. 本地Cache加速 提高了企业站点(尤其含有大量图片和静态页面站点)的访问速度，并大大提高以上性质站点的稳定性
2. 镜像服务 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。
3. 远程加速 远程访问用户根据DNS负载均衡技术智能自动选择Cache服务器，选择最快的Cache服务器，加快远程访问的速度
4. 带宽优化 自动生成服务器的远程Mirror（镜像）cache服务器，远程用户访问时从cache服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点WEB服务器负载等功能。
5. 集群抗攻击 广泛分布的CDN节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种D.D.o.S攻击对网站的影响，同时保证较好的服务质量 。

### 算法优化 ###
算法优化是性能局部优化的首先，常采用各种性能软件来度量CPU时间，内存占用，函数调用次数等以定位问题，然后根据具体情况采用不同的调优方法进行调优，比如利用空间换时间，或者使用合理的数据结构。
> 例如对于比较大的多层循环，可以做成多个map，将多层循环转换成单重循环。

算法优化也有不足点：只能够帮助消除一些明显的编程细节引起的瓶颈，如果想只是用算法优化完全解决性能问题基本上是不可能的，而且还具有非常大的难度。


### 软件优化 ###
- 合理的操作系统优化
- 数据库优化
- 中间件技术
- 本地缓存
- 分布式缓存


### 硬件优化 ###
- 更快的CPU
- 加内存减少分页
- 更快的网络IO设备（光纤以及专线加带宽，使用万兆千兆网卡代替千兆百兆网卡）
- 更快的本地IO设备（内存替代硬盘，SSD替代机械硬盘）
- 快速计算资源代替慢速计算资源（快速存储代替慢速存储）
- 本地计算换网络传输的优化（采用压缩内容的优化方式）

### 算法与资源之间的交互 ###
- 减少单台服务器的处理量（分而治之）
> 把大应用按业务分成独立的互相合作的系统，如：高层采用SOA，底层采用数据库分库分表
> 
> web服务器、应用服务器、数据库服务器、文件服务器，独立搭建部署
> 
> 采用读写分离，快慢服务分离
> 
> 数据库分库分表

- 充分利用系统资源
> 采用多进程、多线程、异步操作以及负载均衡等手段
> 负载均衡主要是防止某台服务器过满或过闲

- 减少不必要的计算次数
> 缓存计算结果，尤其服务器端缓存，以减少不必要的计算

- 减少不惜要的IO次数
> 网络IO次数：客户端缓存，CDN缓存，合并资源以减少请求次数
> 
> 磁盘IO次数：缓存常用数据，如利用redis、memcached进行缓存


