---
title: 海量数据系统优化
date: 2017-07-15
tags: 
	- 大数据优化
	- 优化
categories:
    - 优化
keywords: 海量数据,系统优化
description: 对于海量数据的系统怎么样才能是系统更优？总结一些工作中的经验来看一下。
---


## 海量数据优化 ##
现在社会尤其是互联网方面的蓬勃发展，造成的网站面临着数据量越来越大的问题，对于这个状况如果解决不好将严重影响系统的运行速度，那么该如何解决或者说优化这个问题呢？根据实际工作中涉及到的方方面面，大体可以归结为以下几点：

### 页面静态化 ###
页面静态化是将程序最后生成的页面保存起来，使用页面静态化后就不需要每次请求都重新生成页面了，这样不但不需要查询持久化存储，而且连应用程序处理都不需要，所以页面静态化同时对数据量大和并发量高两大问题都有好处。页面静态化可以在程序中使用模板技术生成，如常用的Velocity都可以根据模板生成静态页面，另外也可以使用缓存服务器在应用服务器的上一层缓存生成的页面，如可以使用varnish或者squid，另外Nginx也提供了相应的功能。

### 缓存 ###
缓存就是将从持久化存储中获取的数据暂时保存起来，在下次使用的时候无需重新到持久化存储中获取而直接使用，这样可以大大降低持久化存储的压力。

缓存的使用一般可以分为以下两种

- 直接保存在程序内存中
	> 程序直接操作主要是使用Map数据集合，尤其是ConcurrentHashMap线程安全的集合，在不需要强一致性的环境中也可以使用HashMap，毕竟ConcurrentHashMap需要同步处理，即便再轻量级的锁，还是会有额外开销，造成性能消耗。
- 使用缓存框架
	> Memcache和Redis是目前比较成熟的缓存框架，也是很多大型网站会用到的缓存框架，对于Memcache和Redis两者的主要区别
	> 
	> Redis的作者Salvatore Sanfilippo曾经对这两种基于内存的数据存储系统进行过比较：
	> 
	> - **Redis支持服务器端的数据操作**：Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。
	> - **内存使用效率对比**：使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。
	> - **性能对比**：由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。

缓存使用过程中最重要问题是什么时候创建或者更新获取，又或者缓存什么时候失效？对于这个问题：一般情况下有以下两种做法：

- 在程序获取数据的时候，如果缓存中不存在，则到持久化缓存中获取数据并创建缓存。
	>针对程序读取并创建缓存的情况，需要注意针对空值的处理，一般情况下空值也会存储一个缓存记录，防止出现无限查询持久化缓存的问题。同时针对这种情况，可能会造成数据的非实时一致，对于强一致性的地方不适合使用该方法。 
- 在数据创建时，存储到持久化缓存之后，同步创建缓存。
	> 这种做法一般是针对几乎不变化的数据，同时数据是由管理台创建出来的情况。同时针对这个情况，数据一般会以缓存数据为主，这种情况下程序处理过程中一般不会查询持久化存储更新缓存数据，程序在缓存中如果没有获取到数据默认就认为没有相应数据。
	
一般针对缓存都会设置一个过期时间，这样的好处是数据过期之后就可以再次获取最新的数据继续缓存，相当于变相的更新缓存数据。


### 数据库优化 ###
数据库优化主要的目的是在不增加硬件的情况下提高处理效率。数据库优化的方法非常多，常用的手段有表结构优化、SQL语句优化、分区、分表、索引优化、分库。

#### 表结构优化 ####
表结构设计的合理与否直接影响到性能，因为表结构是数据存储的基础。

一般没有固定的表结构设计，只能说那种设计更适合，虽然之前教科书上说表结构要满足第三范式，然而在实际使用中并没有什么鸟用，在表设计的时候往往会**故意引入冗余**，或者需要**把一张表拆分成多张表处理冷热字段数据**，不过这些情况都要根据实际进行设计，或许你能让表结构满足第三范式，但是小生在实际工作中很少能见到满足第三范式的表设计。
#### SQL语句优化 ####
SQL语句优化是查询数据优化中很重要的一部分，一般情况下SQL语句优化需要和索引优化配合使用，不过SQL优化一般都是可以从数据量上过滤方面下手，比如同一个语句你可以先过滤出少量的数据肯定比在大量数据中处理要速度快的多，在优化SQL的过程中一般可以使用explain查看语句执行花费来做为优化依据。对于查询sql来说还有一点，不要广泛的使用Select * 而是需要什么数据就查询什么数据，一个是可以使用到索引覆盖，另外就是会减少网络带宽占用。

#### 索引优化 ####
索引优化一般是根据对表的查询操作的所有SQL的整合，结合数据库存储引擎的原理，来设计优化索引，比如如果存储引擎使用了B+Tree方式存储数据，那么你的索引创建时就要遵循最左前缀，再比如如果你的存储引擎是聚族索引以及非聚族索引方式组织数据的，就要考虑索引能否覆盖等一系列的优化方案？

在索引优化的时候，同样需要尽量少的创建索引，并且能创建联合索引的情况下尽量创建联合索引而不是创建多个单列索引，因为索引在提高查询效率的情况下，会降低增删改的速度，因为每次数据改变的情况下，都需要更新索引信息。


#### 分区 ####

在支持分区的数据库引擎中，在数据量不断变大的情况下，如果可以使用分区存储数据的话无疑是很好的。

分区是将一张表的数据按照一定的规则分别存储到不同的区中保存，这样在查询数据的时候，按照分区的规则查询数据就可以直接定位到数据所在分区，只查询该分区上的数据，毕竟数据量才是造成效率下降的“罪魁祸首”，如果查询的数据范围小了，性能也就提高了。

分区还有一个好处就是对程序透明，不需要程序不需要做任何改动，唯一要求就是需要数据库存储引擎需要支持分区。


#### 分表 ####

分表一般是对于数据量对于分区之后还是显的数据较大的表，把原有的一张表拆分成多张表结构一样的表，然后按照某种路由规则，把数据平均的分散到各个表中。这样的好处就是分而治之，对于一张表的数据只是原有数据的一小部分，再表内还可以再分区，就可以极大的增加数据的数量级。

分表需要注意的一个很大的问题就是唯一主键的问题，因为数据将会被存储到多个表中，表中的主键就不能使用原来的自增主键这种简单的方式处理，很多时候会是使用主键生成器来实现主键的唯一性，主语主键生成器的设计思路，小生会单独开一篇博文介绍。

对于分表之后的查询，需要程序内做修改，需要指定每条记录的路由到哪个表上查询数据。


#### 分库 ####

对于更大级别的数据量来说，单单的分表页不能满足查询的性能需求了，这时候就需要分表了，把一个表分成多个库的多个表，以便承受更大的数据压力，这样的好处就是在查询时针对不同的数据查询的库都不一致，提高数据存储级别的同时增加了查询性能。

分库还有一种说法是不用的模块分到不同的库中，这是应用的水平拆分，可以提高查询性能，分摊数据库服务器的压力。

### 分离活跃数据 ###

有些应用虽然数据量很大，但是其中的活跃数据很少，对于这种类型的应用可以分离出来活跃数据，单独存储，而非活跃数据存储在另外一个表中。比如一个大型的论坛，注册用户很多，但是真正活跃登录用户只占很少一部分，这时候就可以把活跃用户单独存储在一个表，这种设计就要求程序要处理非活跃用户到活跃用户，以及清理活跃用户中的非活跃用户信息。

### 延迟修改 ###
这种一般是针对非关键性数据，并且修改极其频繁的情况，比如记录用户的pv，uv等信息，可以先记录缓存，然后隔一段时间去持久化一次数据，而不是每次数据变化就直接持久化数据。
### 读写分离 ###

读写分离的本质是对数据库进行集群，这样就可以在高并发的情况下将数据库的操作分配到多个数据库服务器去处理从而降低单台服务器的压力，对于数据库数据的一致性一般采用主备技术实现，而且都是一主多备，主服务器负责数据写入，备服务器负责数据读取。
这种技术的核心问题是数据一致性，也就是主备之间的数据同步问题，避免多点写的情况出现，所以一般就是采用一主多备架构，而且数据的同步可以使用各个数据库的备份技术实现，对于远地备份数据情况，最好是写专门的程序处理。

### NoSQL 和 Hadoop ###
NoSQL的核心就是非结构化，在使用时不需要先将表的结构定义出来，可以非常灵活地进行操作，另外因为NoSQL通过多个块存储数据的特点，其操作大数据的速度也非常快，这其中最具代表性的就是BigTable和Hadoop。

Hadoop是根据BigTable论文开发的开源版本，专门针对大数据处理的一套框架，Hadoop对数据的存储和处理都提供了相应的解决方案，底层数据的存储思路类是分布式加集群的方案，不过Hadoop是将同一个表中的数据分成多块保存到多个节点（分布式），而且每一块数据都有多个节点保存（集群），这里集群除了可以并行处理相同的数据，还可以保证数据的稳定性，在其中一个节点出现问题后数据不会丢失。这里的每个节点都不包含一个完整的表的数据，但是一个节点可以保存多个表的数据。

Hadoop对数据的处理是先对每一块的数据找到相应的节点并进行处理，然后再对每一个处理的结果进行处理，最后生成最终的结果。比如，要查找符合条件的记录，Hadoop的处理方式是先找到每一块中符合条件的记录，然后再将所有获取到的结果合并到一起，这样就可以将同一个查询分到多个服务器处理，处理的速度也就快了，这一点传统的数据库是做不到的。



