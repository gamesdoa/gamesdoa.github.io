<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>gamesdoa随记</title>
  <subtitle>边走边记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://gamesdoa.com/"/>
  <updated>2020-09-22T06:02:25.717Z</updated>
  <id>http://gamesdoa.com/</id>
  
  <author>
    <name>gamesdoa</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop 3.1.4 + Zookeeper 3.4.14 + Spark 2.4.7 + HBase 2.2.5 + Phoenix 5.0.0 高可用集群部署</title>
    <link href="http://gamesdoa.com/hadoop-zookeeper-spark-hbase-phoenix.html"/>
    <id>http://gamesdoa.com/hadoop-zookeeper-spark-hbase-phoenix.html</id>
    <published>2020-09-17T16:00:00.000Z</published>
    <updated>2020-09-22T06:02:25.717Z</updated>
    
    <content type="html"><![CDATA[<h1 id="集群环境：采用VMWare模拟3台主机。"><a href="#集群环境：采用VMWare模拟3台主机。" class="headerlink" title="集群环境：采用VMWare模拟3台主机。"></a>集群环境：采用VMWare模拟3台主机。</h1><table>
<thead>
<tr>
<th style="text-align:center">IP 地址</th>
<th style="text-align:center">主机名</th>
<th style="text-align:center">Hadoop</th>
<th style="text-align:center">Spark</th>
<th style="text-align:center">HBase</th>
<th style="text-align:center">Phoenix</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">192.168.112.18</td>
<td style="text-align:center">gamesdoa18</td>
<td style="text-align:center">namenode/datanode</td>
<td style="text-align:center">Master/Worker</td>
<td style="text-align:center">HMaster/HRigeonServer</td>
<td style="text-align:center">Server</td>
</tr>
<tr>
<td style="text-align:center">192.168.112.19</td>
<td style="text-align:center">gamesdoa19</td>
<td style="text-align:center">namenode/datanode</td>
<td style="text-align:center">Master/Worker</td>
<td style="text-align:center">HMaster/HRigeonServer</td>
<td style="text-align:center">Server</td>
</tr>
<tr>
<td style="text-align:center">192.168.112.20</td>
<td style="text-align:center">gamesdoa20</td>
<td style="text-align:center">namenode/datanode</td>
<td style="text-align:center">Master/Worker</td>
<td style="text-align:center">HMaster/HRigeonServer</td>
<td style="text-align:center">Server</td>
</tr>
</tbody>
</table>
<h2 id="用VMWare-Workstation准备虚拟环境，安装CentOS-7-8"><a href="#用VMWare-Workstation准备虚拟环境，安装CentOS-7-8" class="headerlink" title="用VMWare Workstation准备虚拟环境，安装CentOS 7.8"></a>用VMWare Workstation准备虚拟环境，安装CentOS 7.8</h2><h3 id="配置主机名及IP"><a href="#配置主机名及IP" class="headerlink" title="配置主机名及IP"></a><strong>配置主机名及IP</strong></h3><ul>
<li><p>配置主机名</p>
<pre><code>$ hostnamectl set-hostname gamesdoa18
$ hostname
gamesdoa18
</code></pre></li>
</ul>
<ul>
<li><p>编辑/etc/hosts</p>
<pre><code>$ vim /etc/hosts

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.112.18 gamesdoa18
192.168.112.19 gamesdoa19
192.168.112.20 gamesdoa20
</code></pre></li>
<li><p>设置IP路由</p>
<blockquote>
<p>编辑/etc/sysconfig/network-scripts/ifcfg-ens33</p>
</blockquote>
<pre><code>$ vim /etc/sysconfig/network-scripts/ifcfg-ens33

TYPE=Ethernet
PROXY_METHOD=none
BROWSER_ONLY=no
BOOTPROTO=static
DEFROUTE=yes
IPV4_FAILURE_FATAL=no
IPV6INIT=yes
IPV6_AUTOCONF=yes
IPV6_DEFROUTE=yes
IPV6_FAILURE_FATAL=no
IPV6_ADDR_GEN_MODE=stable-privacy
NAME=ens33
UUID=5ff3f099-11f8-4880-b5d4-6a70183d0572
DEVICE=ens33
ONBOOT=yes
IPADDR=192.168.112.18
NETMASK=255.255.255.0
GATEWAY=192.168.112.254
DNS1=61.139.2.69
IPV6_PRIVACY=no
</code></pre><blockquote>
<p>注意修改：BOOTPROTO、ONBOOT、IPADDR、NETMASK、GATEWAY、DNS1 信息</p>
</blockquote>
</li>
<li><p>重启网络</p>
<pre><code>$ systemctl restart network
</code></pre></li>
</ul>
<h3 id="安装-JDK-1-8"><a href="#安装-JDK-1-8" class="headerlink" title="安装 JDK 1.8"></a><strong>安装 JDK 1.8</strong></h3><ul>
<li><p>下载并解压</p>
<p>  在<a href="https://www.oracle.com/java/technologies/javase-downloads.html" target="_blank" rel="external">官网</a>下载所需版本的 JDK，这里我下载的版本为<a href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html" target="_blank" rel="external">JDK 1.8</a> ,下载后进行解压：</p>
<pre><code># tar -zxvf jdk-8u261-linux-x64.tar.gz
</code></pre></li>
<li><p>设置环境变量</p>
<pre><code># vim /etc/profile

export JAVA_HOME=/usr/java/jdk1.8.0_201  
export JRE_HOME=${JAVA_HOME}/jre  
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib  
export PATH=${JAVA_HOME}/bin:$PATH
</code></pre></li>
<li><p>执行 source 命令，使得配置立即生效：</p>
<pre><code># source /etc/profile
</code></pre></li>
<li><p>检查是否安装成功</p>
<pre><code># java -version

java version &quot;1.8.0_261&quot;
Java(TM) SE Runtime Environment (build 1.8.0_261-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.261-b12, mixed mode)
</code></pre></li>
</ul>
<h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a><strong>关闭防火墙</strong></h3><blockquote>
<p>在开始安装集群前，最好先关闭防火墙，否则后续会出现很多异常问题。</p>
</blockquote>
<pre><code># systemctl stop firewalld &amp; systemctl disable firewalld

[1] 7013
Removed symlink /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed symlink /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.
</code></pre><h3 id="关闭Swap"><a href="#关闭Swap" class="headerlink" title="关闭Swap"></a><strong>关闭Swap</strong></h3><pre><code>&gt;执行swapoff -a临时关闭，但系统重启后恢复

&gt;编辑/etc/fstab，注释掉包含swap的行后，重启
</code></pre><h3 id="禁用SELinux（仅限实验测试等环节使用）"><a href="#禁用SELinux（仅限实验测试等环节使用）" class="headerlink" title="禁用SELinux（仅限实验测试等环节使用）"></a><strong>禁用SELinux（仅限实验测试等环节使用）</strong></h3><pre><code>&gt;编辑/etc/selinux/config，更改SELINUX=disabled，重启。检查状态

    $ sestatus
    SELinux status:                 disabled
</code></pre><h2 id="Clone两个新的镜像"><a href="#Clone两个新的镜像" class="headerlink" title="Clone两个新的镜像"></a>Clone两个新的镜像</h2><p><img src="https://github.com/gamesdoa/img0/blob/master/bigdata/environ/clone.jpg" alt="克隆步骤"></p>
<blockquote>
<p>虚拟机(VM)–&gt; 管理(Manage) –&gt; 克隆(Clone)</p>
</blockquote>
<h2 id="分别更改新镜像的IP-hostname"><a href="#分别更改新镜像的IP-hostname" class="headerlink" title="分别更改新镜像的IP, hostname"></a>分别更改新镜像的IP, hostname</h2><h2 id="设置SSH免登录"><a href="#设置SSH免登录" class="headerlink" title="设置SSH免登录"></a>设置SSH免登录</h2><ul>
<li><p>生成公钥</p>
<blockquote>
<p>在gamesdoa18上执行</p>
</blockquote>
<pre><code>$ ssh-keygen -t rsa
</code></pre><blockquote>
<p>一路回车，默认值。</p>
</blockquote>
</li>
<li><p>分发公钥</p>
<pre><code>$ ssh-copy-id gamesdoa18
$ ssh-copy-id gamesdoa19
$ ssh-copy-id gamesdoa20
</code></pre></li>
<li><p>在其它主机上执行同样步骤</p>
<h2 id="创建相关目录"><a href="#创建相关目录" class="headerlink" title="创建相关目录"></a>创建相关目录</h2></li>
<li>相关文件目录都在/usr/local/app下</li>
<li>hadoop:程序安装到/usr/local/app/hadoop/hadoop-3.1.4，数据放在/usr/local/app/hadoop/data，日志在/usr/local/app/hadoop/hadoop-3.1.4/logs</li>
<li><p>zookeeper ：/usr/local/app/zookeeper/zookeeper-3.4.14</p>
<pre><code>$ for N in $(seq 18 20); do ssh -n root@gamesdoa$N mkdir /usr/local/app/zookeeper/ -p; done;
</code></pre></li>
<li><p>hbase ：/usr/local/app/hbase/hbase-2.2.5</p>
</li>
<li>phoenix ：/usr/local/app/apache-phoenix-5.0.0-HBase-2.0-bin</li>
<li>spark ：/usr/local/app/spark/spark-2.4.7-bin-hadoop2.7</li>
</ul>
<h1 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h1><h2 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h2><p>在<a href="https://zookeeper.apache.org/" target="_blank" rel="external">官网</a>下载所需发布版本的zookeeper，这里我下载的版本为<a href="https://www.apache.org/dyn/closer.lua/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz" target="_blank" rel="external">Apache ZooKeeper 3.4.14</a> ,下载后进行解压：</p>
<pre><code>$ sudo tar -zxvf zookeeper-3.4.14.tar.gz
</code></pre><h2 id="配置环境变量-每台服务器都需要配置"><a href="#配置环境变量-每台服务器都需要配置" class="headerlink" title="配置环境变量(每台服务器都需要配置)"></a>配置环境变量(每台服务器都需要配置)</h2><pre><code>$ sudo vim /etc/profile

export ZOOKEEPER_HOME=/usr/local/app/zookeeper/zookeeper-3.4.14
export PATH=$PATH:$ZOOKEEPER_HOME/bin

$ source /etc/profile
</code></pre><h2 id="创建配置文件zoo-cfg"><a href="#创建配置文件zoo-cfg" class="headerlink" title="创建配置文件zoo.cfg"></a>创建配置文件zoo.cfg</h2><pre><code>$ cd $ZOOKEEPER_HOME/conf
$ sudo cp zoo-sample.cfg zoo.cfg
$ sudo vim zoo.cfg

# ZooKeeper使用的基本时间单位（以毫秒为单位）。它用于做心跳，最小会话超时将是tickTime的两倍。
tickTime=1000
# 表示在leader选举结束后，followers与leader同步需要的时间，如果followers比较多或者说leader的数据灰常多时，同步时间相应可能会增加，那么这个值也需要相应增加。当然，这个值也是follower和observer在开始同步leader的数据时的最大等待时间(setSoTimeout)
initLimit=10
# 表示follower和observer与leader交互时的最大等待时间，只不过是在与leader同步完毕之后，进入正常请求转发或ping等消息交互时的超时时间。
syncLimit=5
# 存储内存数据库快照的位置，除非另有说明，否则指向数据库更新的事务日志。
dataDir=/usr/local/app/zookeeper/data/zookeeper-3.4.14
# 用于事务日志的不同目录。
dataLogDir=/usr/local/app/zookeeper/logs/zookeeper-3.4.14
# 侦听客户端连接的端口
clientPort=2181
# http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance
# server.serverid=host:tickpot:electionport
# server：固定写法
# serverid：每个服务器的指定ID（必须处于1-255之间，必须每一台机器不能重复）
# host：主机名
# tickpot：心跳通信端口
# electionport：选举端口
server.18=gamesdoa18:2888:3888
server.19=gamesdoa19:2888:3888
server.20=gamesdoa20:2888:3888
</code></pre><h2 id="复制zookeeper到其它机器上"><a href="#复制zookeeper到其它机器上" class="headerlink" title="复制zookeeper到其它机器上"></a>复制zookeeper到其它机器上</h2><pre><code>$ for N in $(seq 19 20); do scp -r /usr/local/app/zookeeper/zookeeper-3.4.14 -n root@gamesdoa$N:/usr/local/app/zookeeper/; done;
</code></pre><h2 id="为每台服务器创建身份标识"><a href="#为每台服务器创建身份标识" class="headerlink" title="为每台服务器创建身份标识"></a>为每台服务器创建身份标识</h2><ul>
<li>通过创建名为 myid 的文件将每台服务器标识身份，每个服务器对应一个文件，用于服务器快速选举，该文件位于配置文件 /usr/local/app/zookeeper/zookeeper-3.4.14/conf/zoo.cfg 中的 dataDir 配置项中。
  </li>
<li><p>接下来，我们在配置文件 /usr/local/app/zookeeper/zookeeper-3.4.14/conf/zoo.cfg 中配置的 dataDir 目录，创建 myid 文件，内容为 server. 后面的数字，记住只能是数字：</p>
<pre><code># gamesdoa18
$ echo 18 &gt; /usr/local/app/zookeeper/data/zookeeper-3.4.14/myid

# gamesdoa19
$ echo 19 &gt; /usr/local/app/zookeeper/data/zookeeper-3.4.14/myid

# gamesdoa20
$ echo 20 &gt; /usr/local/app/zookeeper/data/zookeeper-3.4.14/myid
</code></pre></li>
</ul>
<h2 id="在所有节点上启动zookeeper"><a href="#在所有节点上启动zookeeper" class="headerlink" title="在所有节点上启动zookeeper"></a>在所有节点上启动zookeeper</h2><p> 在所有机器上运行 zkServer.sh start 命令启动服务，然后输入 JPS 命令，在所有节点中，您将看到 QuorumPeerMain 服务。</p>
<pre><code># for N in $(seq 18 20); do ssh -n gamesdoa$N /usr/local/app/zookeeper/zookeeper-3.4.14/bin/zkServer.sh start; done;
# check if success
# for N in $(seq 18 20); do ssh -n gamesdoa$N /usr/local/java/jdk1.8.0_261/bin/jps; done;
44861 Jps
12143 QuorumPeerMain
</code></pre><h1 id="安装hadoop"><a href="#安装hadoop" class="headerlink" title="安装hadoop"></a>安装hadoop</h1><h2 id="下载安装包-1"><a href="#下载安装包-1" class="headerlink" title="下载安装包"></a>下载安装包</h2><p> 在<a href="https://hadoop.apache.org/" target="_blank" rel="external">官网</a>下载所需发布版本的hadoop，这里我下载的版本为<a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.4/hadoop-3.1.4.tar.gz" target="_blank" rel="external">Apache Hadoop 3.1.4</a> ,下载后进行解压：</p>
<pre><code># tar -zxvf hadoop-3.1.4.tar.gz
</code></pre><h2 id="配置环境变量-每台服务器都需要配置-1"><a href="#配置环境变量-每台服务器都需要配置-1" class="headerlink" title="配置环境变量(每台服务器都需要配置)"></a>配置环境变量(每台服务器都需要配置)</h2><pre><code># vim /etc/profile

export HADOOP_HOME=/usr/local/app/hadoop/hadoop-3.1.4
export PATH=${HADOOP_HOME}/bin:$PATH

执行 source 命令，使得配置立即生效：

# source /etc/profile
</code></pre><h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><ul>
<li><p>编辑 $HADOOP_HOME/etc/hadoop/core-site.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://gamesdoadata&lt;/value&gt;
        &lt;description&gt;默认文件系统的名称。一个URI，其方案和权限决定了FileSystem的实现。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
        &lt;value&gt;gamesdoa18:2181,gamesdoa19:2181,gamesdoa20:2181&lt;/value&gt;
        &lt;description&gt;由逗号分隔的ZooKeeper服务器地址列表，由ZKFailoverController在自动故障转移中使用。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/usr/local/app/hadoop/data/hadoop-3.1.4&lt;/value&gt;
        &lt;description&gt;数据目录目录,在hdfs-site.xml中会有引用&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
        &lt;value&gt;sshfence&lt;/value&gt;
        &lt;description&gt;用于服务防护的防护方法列表。可能包含内置方法（例如shell和sshfence）或用户定义的方法。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
        &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;
        &lt;description&gt;用于内置sshfence fencer的SSH私钥文件。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;io.file.buffer.size&lt;/name&gt;
        &lt;value&gt;131072&lt;/value&gt;
        &lt;description&gt;SequenceFiles中使用的读/写缓冲区的大小。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;
        &lt;value&gt;100&lt;/value&gt;
        &lt;description&gt;客户端为建立服务器连接而重试的次数。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;
        &lt;value&gt;5000&lt;/value&gt;
        &lt;description&gt;客户端在重试建立服务器连接之前将等待的毫秒数。&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
</ul>
<ul>
<li><p>编辑$HADOOP_HOME/etc/hadoop/hdfs-site.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.nameservices&lt;/name&gt;
        &lt;value&gt;gamesdoadata&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.namenodes.gamesdoadata&lt;/name&gt;
        &lt;value&gt;gamesdoa18,gamesdoa19,gamesdoa20&lt;/value&gt;
        &lt;description&gt;给定名称服务的前缀包含给定名称服务的逗号分隔的名称节点列表。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.gamesdoadata.gamesdoa18&lt;/name&gt;
        &lt;value&gt;gamesdoa18:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.gamesdoadata.gamesdoa19&lt;/name&gt;
        &lt;value&gt;gamesdoa19:8020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.rpc-address.gamesdoadata.gamesdoa20&lt;/name&gt;
        &lt;value&gt;gamesdoa20:8020&lt;/value&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.gamesdoadata.gamesdoa18&lt;/name&gt;
        &lt;value&gt;gamesdoa18:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.gamesdoadata.gamesdoa19&lt;/name&gt;
        &lt;value&gt;gamesdoa19:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address.gamesdoadata.gamesdoa20&lt;/name&gt;
        &lt;value&gt;gamesdoa20:50070&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
        &lt;value&gt;qjournal://gamesdoa18:8485;gamesdoa19:8485;gamesdoa20:8485/gamesdoadata&lt;/value&gt;
        &lt;description&gt;HA群集中多个名称节点之间的共享存储上的目录。
            此目录将由活动写入并由备用数据库读取，以保持命名空间同步。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.client.failover.proxy.provider.gamesdoadata&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
        &lt;description&gt;配置Java类的名称，DFS客户端将使用该名称来确定哪个NameNode是当前的Active，
            以及哪个NameNode当前正在为客户端请求提供服务。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;是否启用自动故障转移。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;3&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
        &lt;description&gt;如果为“true”，则启用HDFS中的权限检查。如果为“false”，则关闭权限检查，但所有其他行为都保持不变。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
        &lt;value&gt;${hadoop.tmp.dir}/journalnode&lt;/value&gt;
        &lt;description&gt;指定JournalNode在本地磁盘存放数据的位置&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file://${hadoop.tmp.dir}/namenode&lt;/value&gt;
        &lt;description&gt;设置namenode存放路径&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file://${hadoop.tmp.dir}/datanode&lt;/value&gt;
        &lt;description&gt;设置datanode存放径路&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.blocksize&lt;/name&gt;
        &lt;value&gt;268435456&lt;/value&gt;
        &lt;description&gt;大型文件系统的HDFS块大小为256MB。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
        &lt;value&gt;100&lt;/value&gt;
        &lt;description&gt;namenode的服务器线程数&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
</ul>
<ul>
<li><p>编辑$HADOOP_HOME/etc/hadoop/mapred.site.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
        &lt;description&gt;指定mr框架为yarn方式&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;
        &lt;value&gt;512&lt;/value&gt;
        &lt;description&gt;每个Map任务的物理内存限制&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;
        &lt;value&gt;512&lt;/value&gt;
        &lt;description&gt;每个Reduce任务的物理内存限制&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;0.0.0.0:10020&lt;/value&gt;
        &lt;description&gt;MapReduce JobHistory服务器IPC主机：端口&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;0.0.0.0:19888&lt;/value&gt;
        &lt;description&gt;MapReduce JobHistory服务器Web浏览时的主机：端口&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.application.classpath&lt;/name&gt;
        &lt;value&gt;
                /usr/local/app/hadoop/hadoop-3.1.4/etc/hadoop,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/common/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/common/lib/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/hdfs/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/hdfs/lib/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/mapreduce/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/mapreduce/lib/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/yarn/*,
                /usr/local/app/hadoop/hadoop-3.1.4/share/hadoop/yarn/lib/*
        &lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
</ul>
<ul>
<li>编辑$HADOOP_HOME/etc/hadoop/capacity-scheduler.xml</li>
</ul>
<ul>
<li><p>编辑$HADOOP_HOME/etc/hadoop/yarn-site.xml</p>
<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;configuration&gt;
&lt;!-- Site specific YARN configuration properties --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;启动后启用RM以恢复状态。如果为true，则必须指定yarn.resourcemanager.store.class。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;
        &lt;description&gt;用作持久存储的类。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
        &lt;value&gt;gamesdoa18:2181,gamesdoa19:2181,gamesdoa20&lt;/value&gt;
        &lt;description&gt;ZooKeeper服务的地址，多个地址使用逗号隔开&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;启用RM高可用性。启用时，（1）默认情况下，RM以待机模式启动，并在提示时转换为活动模式。（2）RM集合中的节点列在yarn.resourcemanager.ha.rm-ids中（3）如果明确指定了yarn.resourcemanager.ha.id，则每个RM的id来自yarn.resourcemanager.ha.id或者可以通过匹配yarn.resourcemanager.address。&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
        &lt;value&gt;rm18,rm19,rm20&lt;/value&gt;
        &lt;description&gt;启用HA时群集中的RM节点列表。最少2个,具体配置见下&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm18&lt;/name&gt;
        &lt;value&gt;gamesdoa18:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm19&lt;/name&gt;
        &lt;value&gt;gamesdoa19:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.webapp.address.rm20&lt;/name&gt;
        &lt;value&gt;gamesdoa20:8088&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
        &lt;value&gt;bd-yarn-ha&lt;/value&gt;
        &lt;description&gt;集群HA的id，用于在ZooKeeper上创建节点，区分使用同一个ZooKeeper集群的不同Hadoop集群&lt;/description&gt;
        &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm18&lt;/name&gt;
        &lt;value&gt;gamesdoa18&lt;/value&gt;
        &lt;description&gt;主机名&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm19&lt;/name&gt;
        &lt;value&gt;gamesdoa19&lt;/value&gt;
        &lt;description&gt;主机名&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname.rm20&lt;/name&gt;
        &lt;value&gt;gamesdoa20&lt;/value&gt;
        &lt;description&gt;主机名&lt;/description&gt;
    &lt;/property&gt;

    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;description&gt;reducer取数据的方式是mapreduce_shuffle&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;  
        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;  
        &lt;value&gt;2048&lt;/value&gt;  
        &lt;discription&gt;每个节点可用内存,单位MB&lt;/discription&gt;  
    &lt;/property&gt; 
    &lt;property&gt;  
        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;  
        &lt;value&gt;2&lt;/value&gt;  
        &lt;discription&gt;每个节点可用cpu&lt;/discription&gt;
    &lt;/property&gt;   
    &lt;property&gt;  
        &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;  
        &lt;value&gt;512&lt;/value&gt;  
        &lt;discription&gt;单个任务可申请最少内存，默认1024MB&lt;/discription&gt;  
    &lt;/property&gt;  
    &lt;property&gt;  
        &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;  
        &lt;value&gt;1024&lt;/value&gt;  
        &lt;discription&gt;单个任务可申请最大内存，默认8192MB&lt;/discription&gt;  
    &lt;/property&gt; 
    &lt;property&gt;  
        &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;  
        &lt;value&gt;1&lt;/value&gt;  
        &lt;discription&gt;最小的cores 1 个，默认的就是一个&lt;/discription&gt;  
    &lt;/property&gt; 
    &lt;property&gt;  
        &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;  
        &lt;value&gt;2&lt;/value&gt;  
        &lt;discription&gt;最多可分配的cores 2 个&lt;/discription&gt;  
    &lt;/property&gt; 
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
        &lt;discription&gt;是否开启聚合日志&lt;/discription&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds&lt;/name&gt;
        &lt;value&gt;-1&lt;/value&gt;
        &lt;discription&gt;定义NM唤醒上载日志文件的频率。默认值为-1。默认情况下，应用程序完成后将上载日志。通过设置此配置，可以在应用程序运行时定期上载日志。可设置的最小滚动间隔秒数为3600。&lt;/discription&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log.server.url&lt;/name&gt;
        &lt;value&gt;http://c0:19888/jobhistory/logs&lt;/value&gt;
        &lt;discription&gt; 配置日志服务器的地址&lt;/discription&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
        &lt;value&gt;-1&lt;/value&gt;
        &lt;discription&gt; 在删除聚合日志之前保留多长时间。-1禁用。单位是秒&lt;/discription&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
        &lt;value&gt;/usr/local/app/hadoop/data/hadoop-3.1.4/yarn/container-logs/&lt;/value&gt;
        &lt;discription&gt;nodemanager存放container日志的本地路径&lt;/discription&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
        &lt;value&gt;/tmp/logs&lt;/value&gt;
        &lt;discription&gt;nodemanager存放container日志的本地路径&lt;/discription&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre></li>
</ul>
<ul>
<li><p>编辑$HADOOP_HOME/etc/hadoop/hadoop-env.sh</p>
<pre><code>export JAVA_HOME=/usr/local/java/jdk1.8.0_261
HDFS_DATANODE_USER=hadoop
# HDFS_DATANODE_SECURE_USER=
HDFS_ZKFC_USER=hadoop
HDFS_JOURNALNODE_USER=hadoop
HDFS_NAMENODE_USER=hadoop
HDFS_SECONDARYNAMENODE_USER=hadoop

YARN_RESOURCEMANAGER_USER=hadoop
YARN_NODEMANAGER_USER=hadoop
</code></pre></li>
<li><p>编辑$HADOOP_HOME/etc/hadoop/workers</p>
<pre><code>gamesdoa18
gamesdoa19
gamesdoa20
</code></pre></li>
</ul>
<h2 id="复制hadoop程序到其余机器"><a href="#复制hadoop程序到其余机器" class="headerlink" title="复制hadoop程序到其余机器"></a>复制hadoop程序到其余机器</h2><pre><code># for N in $(seq 19 20); do scp -r /usr/local/app/hadoop gamesdoa$N:/usr/local/app/hadoop; done;
</code></pre><h2 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h2><ul>
<li><p>启动JournalNode集群</p>
<pre><code># for N in $(seq 18 20); do ssh gamesdoa$N /usr/local/app/hadoop/hadoop-3.1.4/bin/hdfs --daemon start journalnode; done;
# check if success
# for N in $(seq 18 20); do ssh -n gamesdoa$N /usr/local/java/jdk1.8.0_261/bin/jps; done;
</code></pre></li>
<li><p>格式化NameNode(该命令只能执行一次，如果需要再次执行需要把原有的文件删除)</p>
<pre><code>//在gamesdoa18上
# hdfs namenode -format
</code></pre></li>
<li><p>启动zookeeper故障转移控制器，格式化zookeeper</p>
<pre><code># hdfs zkfc -formatZK
# zkCli.sh
//验证 zkfc 是否成功, 执行 ls / 命令如果显示hadoop-ha则表示成功
zk: localhost:2181(CONNECTED) 0] ls /
[zookeeper, hadoop-ha]
</code></pre></li>
<li><p>启动NameNode</p>
<pre><code>//在gamesdoa18上
# hdfs --daemon start namenode

// 在gamesdoa19上
# hdfs namenode -bootstrapStandby
# hdfs --daemon start namenode

// 在gamesdoa20上
# hdfs namenode -bootstrapStandby
# hdfs --daemon start namenode

// gamesdoa18上启动 hdfs
# /usr/local/app/hadoop/hadoop-3.1.4/sbin/start-dfs.sh
// check status
# hdfs haadmin -getAllServiceState
gamesdoa18:8020                                    active    
gamesdoa19:8020                                    standby   
gamesdoa20:8020                                    standby     

// gamesdoa18上启动 YARN
# /usr/local/app/hadoop/hadoop-3.1.4/sbin/start-yarn.sh
</code></pre></li>
<li><p>验证高可用性</p>
<pre><code>// gamesdoa18 查看状态
[gamesdoa18]# hdfs haadmin -getAllServiceState
gamesdoa18:8020        active    
gamesdoa19:8020        standby   
gamesdoa20:8020        standby     
// gamesdoa19 上 kill namenode
[gamesdoa19]# jps
102275 NameNode
[gamesdoa19]# kill -9 102275
// gamesdoa18 查看状态
[gamesdoa18]# hdfs haadmin -getAllServiceState
gamesdoa18:8020        active    
gamesdoa19:8020        Failed to connect: Call From gamesdoa18/192.168.112.18 to gamesdoa19:8020 failed on connection exception: java.net.ConnectException: 拒绝连接; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused   
gamesdoa20:8020        standby     
</code></pre></li>
</ul>
<h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><ul>
<li><p>在<a href="https://spark.apache.org/" target="_blank" rel="external">官网</a>下载所需发布版本的Spark，这里我下载的版本为<a href="https://spark.apache.org/downloads.html" target="_blank" rel="external">Apache Spark 2.4.7</a> ,选择 Spark 版本和对应的 Hadoop 版本后再下载,下载后进行解压：</p>
<pre><code># tar -zxvf spark-2.4.7-bin-hadoop2.7.tgz
</code></pre></li>
</ul>
<h2 id="配置环境变量-每台服务器都需要配置-2"><a href="#配置环境变量-每台服务器都需要配置-2" class="headerlink" title="配置环境变量(每台服务器都需要配置)"></a>配置环境变量(每台服务器都需要配置)</h2><pre><code># vim /etc/profile

export SPARK_HOME=/usr/local/app/spark/spark-2.4.7-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

# source /etc/profile
</code></pre><h2 id="运行环境配置"><a href="#运行环境配置" class="headerlink" title="运行环境配置"></a>运行环境配置</h2><blockquote>
<p>进入 ${SPARK_HOME}/conf 目录，拷贝配置样本进行修改：</p>
</blockquote>
<pre><code># cp spark-env.sh.template spark-env.sh
</code></pre><blockquote>
<p>spark-env.sh中添加内容 vim  spark-env.sh</p>
</blockquote>
<pre><code># 配置JDK安装位置
export JAVA_HOME=/usr/local/java/jdk1.8.0_261
# 配置hadoop配置文件的位置
export HADOOP_CONF_DIR=/usr/local/app/hadoop/hadoop-3.1.4
# 配置zookeeper地址
export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=gamesdoa18:2181,gamesdoa19:2181,gamesdoa20:2181 -Dspark.deploy.zookeeper.dir=/spark-2.4.7&quot;
export SPARK_LOG_DIR=/usr/local/app/spark/logs/spark-2.4.7-bin-hadoop2.7
# Spark Work内存使用量
export SPARK_WORKER_MEMORY=512M

# 该参数决定了yarn集群中，最多能够同时启动的EXECUTOR的实例个数。
export SPARK_EXECUTOR_INSTANCES=3

# 设置每个EXECUTOR能够使用的CPU core的数量。
export SPARK_EXECUTOR_CORES=3

# 该参数设置的是每个EXECUTOR分配的内存的数量
export SPARK_EXECUTOR_MEMORY=512M

#该参数设置的是DRIVER分配的内存的大小
export SPARK_DRIVER_MEMORY=1G

# Spark Application在Yarn中的名字
export SPARK_YARN_APP_NAME=&quot;gamesdoa.Spark-2.4.7&quot;
</code></pre><h2 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h2><pre><code># cp spark-defaults.conf.template  spark-defaults.conf
</code></pre><blockquote>
<p>spark-defaults.conf中添加内容 vim  spark-defaults.conf</p>
</blockquote>
<pre><code># 如果没有适合当前本地性要求的任务可供运行，将跑得慢的任务在空闲计算资源上再度调度的行为,这个参数会引发一些tmp文件被删除的问题，一般设置为false
spark.speculation        false

# 如果设置为true,前台用jdbc方式连接，显示的会是乱码
spark.sql.hive.convertMetastoreParquet  false

# 应用程序上载到HDFS的复制份数
spark.yarn.submit.file.replication 3

# Spark application master给YARN ResourceManager 发送心跳的时间间隔（ms）
spark.yarn.scheduler.heartbeat.interal-ms  5000

# 仅适用于HashShuffleMananger的实现，同样是为了解决生成过多文件的问题，采用的方式是在不同批次运行的Map任务之间重用Shuffle输出文件，也就是说合并的是不同批次的Map任务的输出数据，但是每个Map任务所需要的文件还是取决于Reduce分区的数量，因此，它并不减少同时打开的输出文件的数量，因此对内存使用量的减少并没有帮助。只是HashShuffleManager里的一个折中的解决方案。
spark.shuffle.consolidateFiles  true

# 一个partition对应着一个task,如果数据量过大，可以调整次参数来减少每个task所需消耗的内存.
spark.sql.shuffle.partitions 100

# Spark SQL在每次执行次，先把SQL查询编译JAVA字节码。针对执行时间长的SQL查询或频繁执行的SQL查询，此配置能加快查询速度，因为它产生特殊的字节码去执行。但是针对很短的查询，可能会增加开销，因为它必须先编译每一个查询
spark.sql.codegen true

# 我们都知道shuffle默认情况下的文件数据为map tasks * reduce tasks,通过设置其为true,可以使spark合并shuffle的中间文件为reduce的tasks数目。
spark.shuffle.consolidateFiles true

# 是否记录Spark事件，对于在应用程序完成后重建Web UI非常有用。
spark.eventLog.enabled true

# 是否压缩已记录的事件，如果spark.eventLog.enabled为true。压缩将使用spark.io.compression.codec。
spark.eventLog.compress true

# 如果spark.eventLog.enabled为true，则记录Spark事件的基目录。在此基本目录中，Spark为每个应用程序创建一个子目录，并将特定于该应用程序的事件记录在此目录中。用户可能希望将其设置为统一位置（如HDFS目录），以便历史记录服务器可以读取历史记录文件。
spark.eventLog.dir hdfs://gamesdoadata/tmp/logs/spark_logs
# 配置hdfs相关文件，需要把$HADOOP_HOME/etc/hadoop/路径下的两个文件拷贝到$SPARK_HOME/conf路径下，然后再配置文件：cp $HADOOP_HOME/etc/hadoop/hdfs-site.xml ./
spark.files   file:///usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/conf/hdfs-site.xml,file:///usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/conf/core-site.xml
</code></pre><h2 id="从服务配置"><a href="#从服务配置" class="headerlink" title="从服务配置"></a>从服务配置</h2><pre><code># cp slaves.template slaves
</code></pre><blockquote>
<p>slaves中添加内容 vim  slaves</p>
</blockquote>
<pre><code>gamesdoa18
gamesdoa19
gamesdoa20
</code></pre><h2 id="复制spark到其它节点"><a href="#复制spark到其它节点" class="headerlink" title="复制spark到其它节点"></a>复制spark到其它节点</h2><pre><code># for N in $(seq 19 20); do scp -r /usr/local/app/spark gamesdoa$N:/usr/local/app/spark; done;
</code></pre><h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><pre><code># 在所有服务器上启动master and workers
[gamesdoa18] # /usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/sbin/start-all.sh
[gamesdoa19] # /usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/sbin/start-master.sh
[gamesdoa20] # /usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/sbin/start-master.sh
#创建hdfs文件夹
[root@gamesdoa18]# hadoop fs -mkdir /tmp
[root@gamesdoa18]# hadoop fs -mkdir /tmp/logs
[root@gamesdoa18]# hadoop fs -mkdir /tmp/logs/spark_logs

# test 
[gamesdoa18] # /usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/bin/spark-shell
# test cluster
[gamesdoa18] # /usr/local/app/spark/spark-2.4.7-bin-hadoop2.7/bin/spark-shell --master yarn --deploy-mode client
</code></pre><p><img src="https://github.com/gamesdoa/img0/blob/master/bigdata/environ/spark_start.jpg" alt="启动"></p>
<h1 id="安装HBase"><a href="#安装HBase" class="headerlink" title="安装HBase"></a>安装HBase</h1><h2 id="下载安装包-2"><a href="#下载安装包-2" class="headerlink" title="下载安装包"></a>下载安装包</h2><blockquote>
<p>在<a href="https://hbase.apache.org/" target="_blank" rel="external">官网</a>下载所需发布版本的Spark，这里我下载的版本为<a href="https://hbase.apache.org/downloads.html" target="_blank" rel="external">Apache HBase 2.2.5</a> ,下载后进行解压：</p>
</blockquote>
<pre><code># tar -zxvf hbase-2.2.5-bin.tar.gz
</code></pre><h2 id="配置环境变量-每台服务器都需要配置-3"><a href="#配置环境变量-每台服务器都需要配置-3" class="headerlink" title="配置环境变量(每台服务器都需要配置)"></a>配置环境变量(每台服务器都需要配置)</h2><pre><code># vim /etc/profile

export HBASE_HOME=/usr/local/app/hbase/hbase-2.2.5
export PATH=$HBASE_HOME/bin:$PATH

# source /etc/profile
</code></pre><h2 id="修改hbase-site-xml"><a href="#修改hbase-site-xml" class="headerlink" title="修改hbase-site.xml"></a>修改hbase-site.xml</h2><blockquote>
<p>进入 ${HBASE_HOME}/conf 目录，拷贝配置样本进行修改：</p>
</blockquote>
<p> hbase-site.xml中修改内容 vim hbase-site.xml</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;!-- hbase存放数据目录 --&gt;
        &lt;value&gt;hdfs://gamesdoadata:8020/hbase/hbase_db&lt;/value&gt;
        &lt;description&gt;端口要和Hadoop的fs.defaultFS端口一致&lt;/description&gt;
　　&lt;/property&gt;
　　&lt;property&gt;
　　　　&lt;name&gt;hbase.cluster.distributed&lt;/name&gt;
　　　　&lt;value&gt;true&lt;/value&gt;
        &lt;description&gt;集群将处于的模式。可能的值是对于独立模式为false，对于分布式模式为true&lt;/description&gt;
　　&lt;/property&gt;
　　&lt;property&gt;
　　　　&lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
　　　　&lt;value&gt;gamesdoa18,gamesdoa19,gamesdoa20&lt;/value&gt;
        &lt;description&gt;逗号分隔的ZooKeeper集合中的服务器列表个&lt;/description&gt;
　　&lt;/property&gt; 　　　
    &lt;property&gt;
        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;
        &lt;value&gt;/usr/local/app/hbase/data/hbase-2.2.5&lt;/value&gt;
        &lt;description&gt;zookooper配置、日志等的存储位置，必须为以存在&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.master.port&lt;/name&gt;
        &lt;value&gt;16000&lt;/value&gt;
        &lt;description&gt;HBase Master应绑定的端口&lt;/description&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.master.info.port&lt;/name&gt;
        &lt;value&gt;16010&lt;/value&gt;
        &lt;description&gt;hbase web 端口&lt;/description&gt;
　　&lt;/property&gt;
　　&lt;property&gt;
        &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hbase.wal.provider&lt;/name&gt;
        &lt;value&gt;filesystem&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><h2 id="修改hbase-env-sh"><a href="#修改hbase-env-sh" class="headerlink" title="修改hbase-env.sh"></a>修改hbase-env.sh</h2><p>hbase-env.sh中修改内容 vim hbase-env.sh</p>
<pre><code>#!/usr/bin/env bash        
# The java implementation to use.  Java 1.8+ required.
export JAVA_HOME=/usr/local/java/jdk1.8.0_261
# Extra Java CLASSPATH elements.  HDFS客户端配置，如果在 Hadoop 集群上进行了 HDFS 客户端配置的更改，比如将副本系数 dfs.replication 设置成 5，则必须使 HBase 知道，否则 HBase 将依旧使用默认的副本系数 3 来创建文件，将 Hadoop 配置文件的位置信息添加到 hbase-env.sh 的 HBASE_CLASSPATH 属性，示例如下：
export HBASE_CLASSPATH=/usr/local/app/hadoop/hadoop-3.1.4/etc/hadoop

export HBASE_OPTS=&quot;$HBASE_OPTS -XX:+UseConcMarkSweepGC&quot;

# Where log files are stored.  $HBASE_HOME/logs by default.
export HBASE_LOG_DIR=/usr/local/app/hbase/logs/hbase-2.2.5

# Tell HBase whether it should manage it&apos;s own instance of ZooKeeper or not.
export HBASE_MANAGES_ZK=false
</code></pre><h2 id="编辑slaves"><a href="#编辑slaves" class="headerlink" title="编辑slaves"></a>编辑slaves</h2><pre><code># vim regionservers
gamesdoa18
gamesdoa19
gamesdoa20
</code></pre><h2 id="新建backup-masters文件"><a href="#新建backup-masters文件" class="headerlink" title="新建backup-masters文件"></a>新建backup-masters文件</h2><pre><code># vim backup-masters
gamesdoa19
gamesdoa20
</code></pre><blockquote>
<p>backup-masters 这个文件是不存在的，需要新建，主要用来指明备用的 master 节点，可以指定1个或者多个。</p>
</blockquote>
<h2 id="分发安装包"><a href="#分发安装包" class="headerlink" title="分发安装包"></a>分发安装包</h2><pre><code># for N in $(seq 19 20); do scp -r /usr/local/app/hbase gamesdoa$N:/usr/local/app/hbase; done;
</code></pre><h2 id="启动HBase集群"><a href="#启动HBase集群" class="headerlink" title="启动HBase集群"></a>启动HBase集群</h2><blockquote>
<p>进入 gamesdoa18 的 ${HBASE_HOME}/bin，使用以下命令启动 HBase 集群。执行此命令后，会在 gamesdoa18 上启动 Master 服务，在 gamesdoa19,gamedoa20 上启动备用 Master 服务，在 regionservers 文件中配置的所有节点启动 region server 服务。</p>
</blockquote>
<pre><code># cd ${HBASE_HOME}/bin
# start-hbase.sh
# hbase shell
    &gt;list
    &gt;version
    &gt;quit
</code></pre><p><img src="https://github.com/gamesdoa/img0/blob/master/bigdata/environ/HBASE_start.jpg" alt="启动"><br><img src="https://github.com/gamesdoa/img0/blob/master/bigdata/environ/hbase_webui.jpg" alt="可视化查看"></p>
<h1 id="安装Phoenix-5-0-0-HBase-2-0"><a href="#安装Phoenix-5-0-0-HBase-2-0" class="headerlink" title="安装Phoenix_5.0.0_HBase_2.0"></a>安装Phoenix_5.0.0_HBase_2.0</h1><h2 id="下载安装包-3"><a href="#下载安装包-3" class="headerlink" title="下载安装包"></a>下载安装包</h2><blockquote>
<p>在<a href="https://phoenix.apache.org/" target="_blank" rel="external">官网</a>下载所需发布版本的phoenix，这里我下载的版本为<a href="https://phoenix.apache.org/download.html" target="_blank" rel="external">Apache Phoenix 5.0.0-HBase-2.0</a>,下载后进行解压：</p>
</blockquote>
<pre><code># tar -zxvf apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz
</code></pre><h2 id="配置环境变量-每台服务器都需要配置-4"><a href="#配置环境变量-每台服务器都需要配置-4" class="headerlink" title="配置环境变量(每台服务器都需要配置)"></a>配置环境变量(每台服务器都需要配置)</h2><pre><code># vim /etc/profile

export HBASE_HOME=/usr/local/app/hbase/hbase-2.2.5
export PATH=$HBASE_HOME/bin:$PATH

# source /etc/profile
</code></pre><h2 id="设置jars"><a href="#设置jars" class="headerlink" title="设置jars"></a>设置jars</h2><p> 拷贝Phoenix目录下的phoenix-core-5.0.0-HBase-2.0.jar, phoenix-5.0.0-HBase-2.0-server.jar到Hbase Server的lib目录下，将phoenix-5.0.0-HBase-2.0-client.jar拷贝到客户端。</p>
<h2 id="创建符号链接"><a href="#创建符号链接" class="headerlink" title="创建符号链接"></a>创建符号链接</h2><blockquote>
<p>在bin目录下创建hadoop core-site.xml、hdfs-site.xml以及hbase-site.xml的符号连接</p>
</blockquote>
<pre><code># cd $PHOENIX_HOME/bin
# ln -s /usr/local/app/hadoop/hadoop-3.1.4/etc/hadoop/core-site.xml ./core-site.xml
# ln -s /usr/local/app/hadoop/hadoop-3.1.4/etc/hadoop/hdfs-site.xml ./hdfs-site.xml
# ln -s /usr/local/app/hbase/hbase-2.2.5/conf/hbase-site.xml ./hbase-site.xml
</code></pre><h2 id="分发安装包-1"><a href="#分发安装包-1" class="headerlink" title="分发安装包"></a>分发安装包</h2><pre><code># for N in $(seq 19 20); do scp -r /usr/local/app/apache-phoenix-5.0.0-HBase-2.0-bin gamesdoa$N:/usr/local/app/apache-phoenix-5.0.0-HBase-2.0-bin; done;
</code></pre><h2 id="重新启动HBase集群，并测试phoenix"><a href="#重新启动HBase集群，并测试phoenix" class="headerlink" title="重新启动HBase集群，并测试phoenix"></a>重新启动HBase集群，并测试phoenix</h2><pre><code># cd ${HBASE_HOME}/bin
# stop-hbase.sh
# start-hbase.sh
# cd $PHOENIX_HOME/bin
# sqlline.py gamesdoa18,gamesdoa19,gamesdoa20:2181
# psql.py gamesdoa18,gamesdoa19,gamesdoa20:2181 create_table.sql table_data.csv table_query.sql
</code></pre>]]></content>
    
    <summary type="html">
    
      记录一下手动布署hadoop集群具体步骤。
    
    </summary>
    
      <category term="大数据" scheme="http://gamesdoa.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop" scheme="http://gamesdoa.com/tags/Hadoop/"/>
    
      <category term="Zookeeper" scheme="http://gamesdoa.com/tags/Zookeeper/"/>
    
      <category term="Spark" scheme="http://gamesdoa.com/tags/Spark/"/>
    
      <category term="HBase" scheme="http://gamesdoa.com/tags/HBase/"/>
    
      <category term="Phoenix" scheme="http://gamesdoa.com/tags/Phoenix/"/>
    
  </entry>
  
  <entry>
    <title>UOS打包符合商店的deb包</title>
    <link href="http://gamesdoa.com/uos-deb.html"/>
    <id>http://gamesdoa.com/uos-deb.html</id>
    <published>2020-08-04T16:00:00.000Z</published>
    <updated>2020-08-05T08:25:13.265Z</updated>
    
    <content type="html"><![CDATA[<h2 id="构建一个规范的软件目录"><a href="#构建一个规范的软件目录" class="headerlink" title="构建一个规范的软件目录"></a>构建一个规范的软件目录</h2><ul>
<li><p>新建文件夹 com.domainname-version 例如 com.gamesdoa-1.0.0</p>
</li>
<li><p>在 com.gamesdoa-1.0.0文件夹下 新建 com.gamesdoa 目录</p>
</li>
<li><p>在 com.gamesdoa 目录下新建entries、files两个文件夹和 info 文件</p>
</li>
<li><p>在entries 下新建applications文件夹</p>
</li>
<li><p>在applications下新建桌面文件appname.desktop 例如 IPBindClient.desktop</p>
<pre><code>[Desktop Entry]
Name=IP绑定工具
Type=Application
Categories=Utility;
Exec=/opt/apps/com.gamesdoa/files/IPBindClient
Icon=/opt/apps/com.gamesdoa/files/IPBindClient.png
Terminal=false
</code></pre></li>
<li><p><strong>将库和二进制可执行文件放在files目录（二进制可以执行的文件）</strong></p>
</li>
<li><p>修改 info 文件</p>
<pre><code>info
{
&quot;appid&quot;:&quot;com.gamesdoa&quot;,
&quot;name&quot;:&quot;IP绑定工具&quot;,
&quot;version&quot;:&quot;1.0.0&quot;,
&quot;arch&quot;:[&quot;amd64&quot;],
&quot;permissions&quot;:
{
&quot;autostart&quot;:false,
&quot;notification&quot;:false,
&quot;trayicon&quot;:true,
&quot;clipboard&quot;:true,
&quot;account&quot;:false,
&quot;bluetooth&quot;:false,
&quot;camera&quot;:false,
&quot;audio_record&quot;:true,
&quot;installed_apps&quot;:false
}
}
</code></pre></li>
</ul>
<h2 id="使用dh-make生成debian目录"><a href="#使用dh-make生成debian目录" class="headerlink" title="使用dh_make生成debian目录"></a>使用dh_make生成debian目录</h2><p>在com.gamesdoa-1.0.0目录下运行命令</p>
<pre><code>dh_make --createorig -s
</code></pre><blockquote>
<p>如果不存在dh_make指令，运行下面命令安装</p>
<pre><code>sudo apt-get install build-essential dh-make
</code></pre><p>如果需要切换超级用户</p>
<pre><code>sudo  su
</code></pre></blockquote>
<p>确认信息输入y即可</p>
<h2 id="整理自动生成的debian"><a href="#整理自动生成的debian" class="headerlink" title="整理自动生成的debian"></a>整理自动生成的debian</h2><ul>
<li><p>修改自动生成debian目录下的control文件</p>
<pre><code>Source: com.gamesdoa
Section: utils
Priority: optional
Maintainer: unknown &lt;yang@unknown&gt;
Build-Depends: debhelper (&gt;= 11)
Standards-Version: 4.1.3
Homepage: &lt;insert the upstream URL, if relevant&gt;
#Vcs-Browser: https://salsa.debian.org/debian/com.gamesdoa
#Vcs-Git: https://salsa.debian.org/debian/com.gamesdoa.git

Package: com.gamesdoa
Architecture: amd64
Depends: ${shlibs:Depends}, ${misc:Depends}
Description: &lt;insert up to 60 chars description&gt;
 &lt;insert long description, indented with spaces&gt;
</code></pre><blockquote>
<p>注意 Section、Priority、Architecture、Package</p>
</blockquote>
</li>
<li><p>在debian 目录下新建install文件</p>
<pre><code>touch install
</code></pre><p>  在install文件指定安装路径，这里填写</p>
<pre><code>com.gamesdoa/ /opt/apps
com.gamesdoa/entries/applications/IPBindClient.desktop /usr/share/applications
</code></pre><blockquote>
<p>将com.gamesdoa目录安装到/opt/apps目录下</p>
<p>将桌面文件安装到/usr/share/applications目录下（菜单可见）</p>
</blockquote>
</li>
<li><p>修改rules文件</p>
<pre><code>#!/usr/bin/make -f
# See debhelper(7) (uncomment to enable)
# output every command that modifies files on the build system.
#export DH_VERBOSE = 1

# see FEATURE AREAS in dpkg-buildflags(1)
#export DEB_BUILD_MAINT_OPTIONS = hardening=+all

# see ENVIRONMENT in dpkg-buildflags(1)
# package maintainers to append CFLAGS
#export DEB_CFLAGS_MAINT_APPEND  = -Wall -pedantic
# package maintainers to append LDFLAGS
#export DEB_LDFLAGS_MAINT_APPEND = -Wl,--as-needed

%:
    dh $@
override_dh_auto_build:

override_dh_shlibdeps:

override_dh_strip:

# dh_make generated override targets
# This is example for Cmake (See https://bugs.debian.org/641051 )
#override_dh_auto_configure:
#    dh_auto_configure -- #    -DCMAKE_LIBRARY_PATH=$(DEB_HOST_MULTIARCH)
</code></pre></li>
</ul>
<pre><code>&gt; override了三处
</code></pre><ul>
<li><p>删除所有EX、ex结尾的文件</p>
<pre><code>rm *.EX *.ex
</code></pre></li>
</ul>
<h2 id="编译并生成deb包"><a href="#编译并生成deb包" class="headerlink" title="编译并生成deb包"></a>编译并生成deb包</h2><ul>
<li><p>在com.gamesdoa-1.0.0目录下执行(777权限可能导致失败)</p>
<pre><code>dpkg-source -b .
</code></pre><blockquote>
<p>可能由于gcc版本的问题出错，略过</p>
</blockquote>
</li>
<li><p>执行下面的命令构建deb包 </p>
<pre><code>dpkg-buildpackage -us -uc -nc
</code></pre></li>
</ul>
<h2 id="整理deb包内部结构"><a href="#整理deb包内部结构" class="headerlink" title="整理deb包内部结构"></a>整理deb包内部结构</h2><ul>
<li><p>解压到temp目录下</p>
<pre><code>fakeroot dpkg-deb -R com.gamesdoa_1.0.0-1_amd64.deb temp
</code></pre></li>
<li><p>整理包内目录结构</p>
<pre><code>mv temp/usr/share/doc temp/opt/apps/com.gamesdoa/files
</code></pre></li>
<li><p>最后重新归档安装包</p>
<pre><code>fakeroot dpkg-deb -b temp com.gamesdoa_1.0.0_amd64.deb
</code></pre></li>
</ul>
]]></content>
    
    <summary type="html">
    
      如何在UOS系统上打包符合商店规则的deb包。
    
    </summary>
    
      <category term="uos" scheme="http://gamesdoa.com/categories/uos/"/>
    
    
      <category term="uos" scheme="http://gamesdoa.com/tags/uos/"/>
    
      <category term="linux" scheme="http://gamesdoa.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Thread中start和run方法的区别</title>
    <link href="http://gamesdoa.com/thread-start-run.html"/>
    <id>http://gamesdoa.com/thread-start-run.html</id>
    <published>2017-09-27T16:00:00.000Z</published>
    <updated>2017-09-28T07:17:14.814Z</updated>
    
    <content type="html"><![CDATA[<h1 id="认识Thread的-start-和-run"><a href="#认识Thread的-start-和-run" class="headerlink" title="认识Thread的 start() 和 run()"></a>认识Thread的 start() 和 run()</h1><p>我们通过API定义来看一下start() 和 run()的区别</p>
<h2 id="start"><a href="#start" class="headerlink" title="start()"></a>start()</h2><p>JDK中的注释是这样的：</p>
<pre><code>Causes this thread to begin execution; 
the Java Virtual Machine calls the run method of this thread.
The result is that two threads are running concurrently: 
the current thread (which returns from the call to the start method) 
and the other thread (which executes its run method).
It is never legal to start a thread more than once.
In particular, a thread may not be restarted once it has completed execution.
</code></pre><p>大体意思是：可以是线程开始执行，java虚拟机将会调用次线程的run方法。这样运行的结果是将会有两个线程同时运行（一个是当前线程，也就是调用start方法的线程，另外一个是执行run方法的线程），并且该方法启动线程只能启动一次，不允许重复启动，也就是说一旦线程完成执行，线程就不能重新启动。</p>
<blockquote>
<p>用start方法来启动线程，真正实现了多线程运行，这时无需等待run方法体代码执行完毕而直接继续执行下面的代码。通过调用Thread类的 start()方法来启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到cpu时间片，就开始执行run()方法，这里方法 run()称为线程体，它包含了要执行的这个线程的内容，Run方法运行结束，此线程随即终止。</p>
</blockquote>
<h2 id="run"><a href="#run" class="headerlink" title="run()"></a>run()</h2><p>JDK中的注释是这样的：</p>
<blockquote>
<p>When an object implementing interface  Runnable is used to create a thread, starting the thread causes the object’s run method to be called in that separately executing  thread.</p>
<p>The general contract of the method run is that it may  take any action whatsoever.</p>
</blockquote>
<p>大体意思是：使用实现接口Runnable的对象来创建线程时，启动时会在单独执行的线程中调用run方法。一般来说，该方法不执行任何的操作返回（void）。</p>
<blockquote>
<p>Thread 的子类应该重写该方法。</p>
<p>run()方法只是类的一个普通方法，如果直接调用Run方法，程序中依然只有主线程这一个线程，其程序执行路径还是顺序执行，要等待run方法体执行完毕后才可继续执行下面的代码，这样就没有达到写线程的目的。</p>
</blockquote>
<h2 id="总结对比"><a href="#总结对比" class="headerlink" title="总结对比"></a>总结对比</h2><p>从API不难看出，start方法是启动一个线程并会调用内部的run方法运行，而run方法只是thread的一个普通方法，他的执行还是在当前线程中。</p>
<h1 id="一个例子"><a href="#一个例子" class="headerlink" title="一个例子"></a>一个例子</h1><pre><code>package com.gamesdoa.test.thread;

import org.junit.Test;
import java.util.concurrent.TimeUnit;
/**
 * Created by gamesdoa on 2017/9/28.
 */
public class TreadRandT {
    @Test
    public void testStart() throws InterruptedException {
        Thread t = new Thread() {
            public void run() {
                call();
            }
        };
        t.start();
        try {
            t.start();
        }catch (Exception e){
            e.printStackTrace();
        }
        System.out.println(&quot;线程：&quot; + Thread.currentThread().getName() 
            + &quot;; 我是主线程&quot;);
        TimeUnit.MILLISECONDS.sleep(100l);
    }

    @Test
    public void testRun() {
        Thread t = new Thread() {
            public void run() {
                call();
            }
        };
        t.run();
        t.run();
        System.out.println(&quot;线程：&quot; + Thread.currentThread().getName()
            + &quot;; 我是主线程&quot;);
    }

    private void call() {
        System.out.println(&quot;线程：&quot; + Thread.currentThread().getName()
            + &quot;; call被调用了&quot;);
    }

    @Test
    public void testAll() throws InterruptedException {
        testStart();
        System.out.println(&quot;------------我是华丽的分割线--------------&quot;);
        testRun();
    }
}
</code></pre><p>运行结果如下：</p>
<pre><code>调用start方法：
线程：main; 我是主线程
java.lang.IllegalThreadStateException
    at java.lang.Thread.start(Thread.java:705)
    at com.gamesdoa.test.thread.TreadRandT.testStart(TreadRandT.java:21)
    at com.gamesdoa.test.thread.TreadRandT.testAll(TreadRandT.java:51)&lt;27 internal calls&gt;
线程：Thread-0; call被调用了

------------我是华丽的分割线--------------

调用run方法：
线程：main; call被调用了
线程：main; call被调用了
线程：main; 我是主线程
</code></pre><blockquote>
<p>注 ： 可以看到，我们在调用 start 方法启动线程的时候会有一个新的线程被启动（Thread-0），在Thread-0里面才执行的call调用，是一个单独的线程，这样也就可以处理成多线程系统。 重复调用start将会报IllegalThreadStateException异常。</p>
<p>再看 run 方法，该方法的调用call执行的时候，还是在主线程中顺序执行，调用 run 方法在前，也就先执行， 主线程的输出在后，也就后执行，同样这里可以看到重复执行run方法时完全允许的。</p>
<p>为什么会在start的方法执行完之后休眠100毫秒？ </p>
<p>因为如果不加入休眠的话，当另外一个线程启动之后处于可运行状态，如果没有获取到CPU时间，主线程就直接运行完了，那么这里讲不会看到被调用的输出，这也正说明了多线程的执行规则，无序的。</p>
</blockquote>
<h1 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h1><p>上面说到线程的状态，那么我们最后再在这里补充一下线程的状态：<br><img src="https://github.com/gamesdoa/img0/raw/master/java/thread/thread-state.jpg" alt="线程运行状态"></p>
<blockquote>
<p>上图可以看出来，线程有三个状态， 可运行 ， 运行中 ， 阻塞 。</p>
<p>可运行在获取到CPU时间之后转换成运行中的状态</p>
<p>运行中在CPU时间到期可以转换成可运行状态，同时遇到阻塞事件的时候状态就会转换成阻塞的状态</p>
<p>阻塞状态在阻塞条件满足的情况下会变成可运行状态。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      工作使用java多年，没有分清java中的线程在run和start方法的的区别，通过API和一个例子来看一下到底他们有什么区别
    
    </summary>
    
      <category term="java" scheme="http://gamesdoa.com/categories/java/"/>
    
    
      <category term="java" scheme="http://gamesdoa.com/tags/java/"/>
    
      <category term="Thread" scheme="http://gamesdoa.com/tags/Thread/"/>
    
  </entry>
  
  <entry>
    <title>springBean生命周期</title>
    <link href="http://gamesdoa.com/spring-bean-lifecycle.html"/>
    <id>http://gamesdoa.com/spring-bean-lifecycle.html</id>
    <published>2017-08-14T16:00:00.000Z</published>
    <updated>2017-09-13T06:53:39.912Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Bean生命周期流程图"><a href="#Bean生命周期流程图" class="headerlink" title="Bean生命周期流程图"></a>Bean生命周期流程图</h1><p>先看一个本博主理解的生命周期的流程图：<br><img src="https://github.com/gamesdoa/img0/raw/master/spring/spring-bean-lifecycle.jpg" alt="springbean生命周期"></p>
<h1 id="文字描述Bean生命周期"><a href="#文字描述Bean生命周期" class="headerlink" title="文字描述Bean生命周期"></a>文字描述Bean生命周期</h1><h2 id="Spring容器启动"><a href="#Spring容器启动" class="headerlink" title="Spring容器启动"></a>Spring容器启动</h2><ul>
<li>首先会使用IOC的一套机制把定义的Bean信息加载并转化成BeanDefinition存储（如果你不了解这个过程的话可以看这里<a href="http://gamesdoa.com/spring-ioc.html" title="spring IOC 解析">http://gamesdoa.com/spring-ioc.html</a>)</li>
<li><p>当存储为BeanDefinition之后如果存在<strong>BeanFactoryPostProcessor</strong>的实现类的话就会先实例化该实现，并执行该实例的<em>postProcessBeanFactory</em>方法，该方法生命是这样的：</p>
<pre><code>public void postProcessBeanFactory(ConfigurableListableBeanFactory arg0) throws BeansException
</code></pre><blockquote>
<p>该方法可以使用arg0.getBeanDefinition(“beanName”) 获取beanName对应的BeanDefinition信息，既然获取到了BeanDefinition那么就可以做很多操作了，比如修改scope，修改懒加载，等等，具体可以做哪些操作可以参看<strong>org.springframework.beans.factory.config.BeanDefinition</strong>，当然也可以直接修改属性值，使用如下代码：</p>
<p><em>beanDefinition.getPropertyValues().addPropertyValue(“propertyName”, “propertyValue”);</em> </p>
<p>这里相当于直接修改XML文件内的设值。针对BeanDefinition属性信息的更多操作参看<strong>org.springframework.beans.MutablePropertyValues</strong></p>
</blockquote>
</li>
<li><p>处理完BeanDefinition之后，如果存在<strong>BeanPostProcessor</strong>的实现的话会接着实例化该接口</p>
</li>
<li><p>接下来如果存在<strong>InstantiationAwareBeanPostProcessorAdapter</strong>的实现的话会接着实例化该接口</p>
</li>
<li><p>判断该 BeanDefinition 的scope属性</p>
<ul>
<li><p>如果scope属性是prototype，那么直接略过，将初始化的时间交给业务程序，只有在业务程序调用该bean的时候才会再进行初始化过程</p>
</li>
<li><p>如果scope属性是singleton，并且不是懒加载的话，将立刻开始初始化过程</p>
</li>
</ul>
</li>
</ul>
<h2 id="Bean初始化过程"><a href="#Bean初始化过程" class="headerlink" title="Bean初始化过程"></a>Bean初始化过程</h2><ul>
<li><p>首先执行 InstantiationAwareBeanPostProcessorAdapter 的 postProcessBeforeInstantiation 方法，这个执行将会在实例化bean之前调用，如果有需要的话可以在这里处理一些信息，比如安全验证什么的，该方法的声明如下：</p>
<pre><code>// beanClass 需要实例化的Bean的Class
// beanName 配置的该Bean的id/name
public Object postProcessBeforeInstantiation(Class beanClass,
                                     String beanName) throws BeansException
</code></pre></li>
<li>接下来就调用bean的构造器</li>
<li>然后执行 InstantiationAwareBeanPostProcessorAdapter 的 postProcessPropertyValues 方法，这个执行就是将 BeanDefinition 中的属性值设置给生成的实例对应的属性。</li>
<li>如果bean实现了 BeanNameAware 的话就执行该接口的 setBeanName 方法</li>
<li>如果bean实现了 BeanFactoryAware 的话就执行该接口的 setBeanFactory 方法</li>
<li>如果bean实现了 ApplicationContextAware 的话就执行该接口的 setApplicationContext 方法<blockquote>
<p>上面这三个实现的执行顺序是固定的</p>
</blockquote>
</li>
<li><p>然后执行 <strong>BeanPostProcessor</strong> 的 postProcessBeforeInitialization 方法，这时候bean已经生成了，可以根据需求在这里对对象进行修改，该方法的声明是这样的</p>
<pre><code>//arg0 生成出来的对象
//arg1 生成出来的对象对应的Id/name
public Object postProcessBeforeInitialization(Object arg0, String arg1)
        throws BeansException
</code></pre><blockquote>
<p><strong>BeanPostProcessor 针对容器中的所有Bean定制初始化的过程，该接口中包含两个方法，postProcessBeforeInitialization和postProcessAfterInitialization。</strong></p>
<p><strong>postProcessBeforeInitialization 方法在容器中的Bean初始化之前执行</strong> </p>
<p><strong>postProcessAfterInitialization 方法在容器中的Bean初始化之后执行。</strong></p>
</blockquote>
</li>
<li><p>如果bean实现了 InitializingBean 的话就执行该接口的 afterPropertiesSet 方法，该方法可以在Bean属性值设置好之后做一些操作，比如检查Bean中某个属性是否被正常的设置好值了。(存在一个问题如果实现该接口就跟spring进行了强耦合，因此spring建议使用下一个步骤这种方式来处理就是在XML定义init-method 属性的方式)</p>
</li>
<li>在xml声明bean的时候如果使用了 init-method 属性则调用<bean>的 init-method 属性指定的初始化方法</bean></li>
<li><p>然后执行 BeanPostProcessor 的 postProcessAfterInitialization 方法，可以根据需求在这里对对象进行修改，该方法的声明是这样的</p>
<pre><code>//arg0 生成出来的对象
//arg1 生成出来的对象对应的Id/name
public Object postProcessAfterInitialization(Object arg0, String arg1)
        throws BeansException
</code></pre></li>
<li><p>首先执行 InstantiationAwareBeanPostProcessorAdapter 的 postProcessAfterInitialization 方法，这个执行将会在实例化Bean之后调用，如果有需要的话可以在这里处理一些信息，比如安全验证什么的，该方法的声明如下：</p>
<pre><code>public Object postProcessAfterInitialization(Object bean, String beanName)
throws BeansException
</code></pre></li>
</ul>
<h2 id="Bean销毁过程"><a href="#Bean销毁过程" class="headerlink" title="Bean销毁过程"></a>Bean销毁过程</h2><ul>
<li>如果scope属性是prototype，则在GC时销毁该实例，</li>
<li>如果scope属性是singleton，则需要在容器销毁时才销毁该实例</li>
</ul>
<p>调回过程如下： </p>
<ul>
<li>如果Bean实现了 DisposableBean 接口，则调用该接口的 destroy 方法，可以在销毁Bean之前做一些操作，比如释放资源啥的。(存在一个问题如果实现该接口就跟spring进行了强耦合，因此spring建议使用下一个步骤这种方式来处理就是在XML定义 destroy-method 属性的方式)</li>
<li>在xml声明bean的时候如果使用了 destroy-method 属性则调用<bean>的 destroy-method 属性指定的销毁方法</bean></li>
</ul>
<p>至此：Bean的整个生命周期的描述完毕。</p>
<blockquote>
<p>备注：实现*Aware接口 可以在Bean中使用Spring框架的一些对象，例如在我们这里使用过的BeanNameAware，BeanFactoryAware，ApplicationContextAware等。</p>
<p>ApplicationContextAware: 获得ApplicationContext对象,可以用来获取所有Bean definition的名字。</p>
<p>BeanFactoryAware:获得BeanFactory对象，可以用来检测Bean的作用域。</p>
<p>BeanNameAware:获得Bean在配置文件中定义的名字。</p>
<p>ResourceLoaderAware:获得ResourceLoader对象，可以获得classpath中某个文件。</p>
<p>ServletContextAware:在一个MVC应用中可以获取ServletContext对象，可以读取context中的参数。</p>
<p>ServletConfigAware在一个MVC应用中可以获取ServletConfig对象，可以读取config中的参数。</p>
</blockquote>
<h1 id="代码演示Bean生命周期"><a href="#代码演示Bean生命周期" class="headerlink" title="代码演示Bean生命周期"></a>代码演示Bean生命周期</h1><p>在代码展示的时候我们先声明一个简单的SpringBean ， 为了演示需要，我们让这个Bean尽可能的实现所有初始化以及销毁时需要经过的接口类，在Bean声明之后我们顺着bean生命周期的流程图上的路线，把经过的各个接口都实现一下，以便我们查看效果。</p>
<h2 id="Spring-Bean"><a href="#Spring-Bean" class="headerlink" title="Spring Bean"></a>Spring Bean</h2><p>首先来声明一个简单的 Spring bean，代码如下：</p>
<pre><code>package com.gamesdoa.test.spring.lifecycle;

import org.springframework.beans.BeansException;
import org.springframework.beans.factory.*;
import org.springframework.context.ApplicationContext;
import org.springframework.context.ApplicationContextAware;

/**
 * Created by gamesdoa
 */
public class Product implements BeanFactoryAware, BeanNameAware,
        ApplicationContextAware, InitializingBean, DisposableBean {

    private String name;
    private String description;
    private int stock;

    private BeanFactory beanFactory;
    private String beanName;
    private ApplicationContext applicationContext;

    public Product() {
        System.out.println(&quot;4、  【构造器】调用Product的构造器&quot;);
    }

    public String getName() {
        return name;
    }

    public void setName(String name) {
        System.out.println(&quot;4、  【注入属性】注入属性name&quot;);
        this.name = name;
    }

    public int getStock() {
        return stock;
    }

    public void setStock(int stock) {
        System.out.println(&quot;4、  【注入属性】注入属性stock&quot;);
        this.stock = stock;
    }

    public String getDescription() {
        return description;
    }

    public void setDescription(String description) {
        System.out.println(&quot;4、  【注入属性】注入属性description&quot;);
        this.description = description;
    }

    @Override
    public String toString() {
        return &quot;4、  Product [name=&quot; + name + &quot;, description=&quot;
                + description + &quot;, stock=&quot; + stock + &quot;]&quot;;
    }

    // 覆盖实现BeanFactoryAware接口方法
    @Override
    public void setBeanFactory(BeanFactory arg0) throws BeansException {
        System.out.println(&quot;4、  【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()&quot;);
        this.beanFactory = arg0;
    }

    // 覆盖实现BeanNameAware接口方法
    @Override
    public void setBeanName(String arg0) {
        System.out.println(&quot;4、  【BeanNameAware接口】调用BeanNameAware.setBeanName()&quot;);
        this.beanName = arg0;
    }

    // 覆盖实现ApplicationContextAware接口方法
    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        System.out.println(&quot;4、  【ApplicationContextAware接口】调用ApplicationContextAware.setApplicationContext()&quot;);
        this.applicationContext = applicationContext;
    }

    // 覆盖实现InitializingBean接口方法
    @Override
    public void afterPropertiesSet() throws Exception {
        System.out.println(&quot;4、  【InitializingBean接口】调用InitializingBean.afterPropertiesSet()&quot;);
    }

    // 覆盖实现DiposibleBean接口方法
    @Override
    public void destroy() throws Exception {
        System.out.println(&quot;4、  【DiposibleBean接口】调用DiposibleBean.destory()&quot;);
    }

    // 通过XML配置的Bean的init-method属性指定的初始化方法
    public void myInit() {
        System.out.println(&quot;4、  【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法&quot;);
    }

    // 通过XML配置的Bean的destroy-method属性指定的销毁方法
    public void myDestory() {
        System.out.println(&quot;4、  【destroy-method】调用&lt;bean&gt;的destroy-method属性指定的销毁方法&quot;);
    }
}
</code></pre><h2 id="BeanFactoryPostProcessor"><a href="#BeanFactoryPostProcessor" class="headerlink" title="BeanFactoryPostProcessor"></a>BeanFactoryPostProcessor</h2><p>接下来我们看一下经过的第一个接口：BeanFactoryPostProcessor ， 实现如下：</p>
<pre><code>package com.gamesdoa.test.spring.lifecycle;

import org.springframework.beans.BeansException;
import org.springframework.beans.factory.config.BeanDefinition;
import org.springframework.beans.factory.config.BeanFactoryPostProcessor;
import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;

/**
 * Created by gamesdoa.
 */
public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor {

    public MyBeanFactoryPostProcessor() {
        super();
        System.out.println(&quot;1、  我是BeanFactoryPostProcessor接口实现类的构造器！！&quot;);
    }

    @Override
    public void postProcessBeanFactory(ConfigurableListableBeanFactory arg0) throws BeansException {
        System.out.println(&quot;1、  调用 BeanFactoryPostProcessor 接口的 postProcessBeanFactory 方法&quot;);
        BeanDefinition bd = arg0.getBeanDefinition(&quot;product&quot;);
        bd.getPropertyValues().addPropertyValue(&quot;stock&quot;, &quot;2000&quot;);
    }
}
</code></pre><h2 id="BeanPostProcessor"><a href="#BeanPostProcessor" class="headerlink" title="BeanPostProcessor"></a>BeanPostProcessor</h2><p>接下来是经过的第二个接口： BeanPostProcessor ， 实现如下：</p>
<pre><code>package com.gamesdoa.test.spring.lifecycle;

import org.springframework.beans.BeansException;
import org.springframework.beans.factory.config.BeanPostProcessor;

/**
 * Created by gamesdoa.
 */
public class MyBeanPostProcessor implements BeanPostProcessor {

    public MyBeanPostProcessor() {
        super();
        System.out.println(&quot;2、  我是 BeanPostProcessor 接口实现类的构造器！！&quot;);
    }

    @Override
    public Object postProcessAfterInitialization(Object arg0, String arg1) throws BeansException {
        System.out.println(&quot;2、  调用 BeanPostProcessor 接口的 postProcessAfterInitialization 方法对属性进行更改！&quot;);
        return arg0;
    }

    @Override
    public Object postProcessBeforeInitialization(Object arg0, String arg1) throws BeansException {
        System.out.println(&quot;2、  调用 BeanPostProcessor 接口的 postProcessBeforeInitialization 方法对属性进行更改！&quot;);
        return arg0;
    }
}
</code></pre><h2 id="InstantiationAwareBeanPostProcessorAdapter"><a href="#InstantiationAwareBeanPostProcessorAdapter" class="headerlink" title="InstantiationAwareBeanPostProcessorAdapter"></a>InstantiationAwareBeanPostProcessorAdapter</h2><p>接下来是第三个接口： InstantiationAwareBeanPostProcessorAdapter ，实现如下：</p>
<pre><code>package com.gamesdoa.test.spring.lifecycle;

import org.springframework.beans.BeansException;
import org.springframework.beans.PropertyValues;
import org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessorAdapter;

import java.beans.PropertyDescriptor;

/**
 * Created by gamesdoa.
 */
public class MyInstantiationAwareBeanPostProcessor extends
        InstantiationAwareBeanPostProcessorAdapter {

    public MyInstantiationAwareBeanPostProcessor() {
        super();
        System.out.println(&quot;3、  我是InstantiationAwareBeanPostProcessorAdapter接口实现类的构造器！！&quot;);
    }

    // 接口方法、实例化Bean之前调用
    @Override
    public Object postProcessBeforeInstantiation(Class beanClass,String beanName) throws BeansException {
        System.out.println(&quot;3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessBeforeInstantiation 方法&quot;);
        return null;
    }

    // 接口方法、实例化Bean之后调用
    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
        System.out.println(&quot;3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessAfterInitialization 方法&quot;);
        return bean;
    }

    // 接口方法、设置属性时调用
    @Override
    public PropertyValues postProcessPropertyValues(PropertyValues pvs,PropertyDescriptor[] pds, 
                                                    Object bean, String beanName) throws BeansException {
        System.out.println(&quot;3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessPropertyValues 方法&quot;);
        return pvs;
    }
}
</code></pre><h2 id="定义配置文件"><a href="#定义配置文件" class="headerlink" title="定义配置文件"></a>定义配置文件</h2><p>配置文件如下spring-beans.xml：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:p=&quot;http://www.springframework.org/schema/p&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
            http://www.springframework.org/schema/beans/spring-beans-3.2.xsd&quot;&gt;

    &lt;bean id=&quot;beanPostProcessor&quot; class=&quot;com.gamesdoa.test.spring.lifecycle.MyBeanPostProcessor&quot;/&gt;

    &lt;bean id=&quot;instantiationAwareBeanPostProcessor&quot;
          class=&quot;com.gamesdoa.test.spring.lifecycle.MyInstantiationAwareBeanPostProcessor&quot;/&gt;

    &lt;bean id=&quot;beanFactoryPostProcessor&quot;
          class=&quot;com.gamesdoa.test.spring.lifecycle.MyBeanFactoryPostProcessor&quot;/&gt;

    &lt;bean id=&quot;product&quot; class=&quot;com.gamesdoa.test.spring.lifecycle.Product&quot; init-method=&quot;myInit&quot;
          destroy-method=&quot;myDestory&quot; scope=&quot;singleton&quot; p:name=&quot;iphone 100&quot; p:description=&quot;我是未来的iphone 100&quot;
          p:stock=&quot;900&quot; /&gt;
&lt;/beans&gt;
</code></pre><h2 id="测试类"><a href="#测试类" class="headerlink" title="测试类"></a>测试类</h2><pre><code>package com.gamesdoa.test.spring.lifecycle;

import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

/**
 * Created by gamesdoa.
 */
public class BeanLifeCycleTest {

    public static void main(String[] args) {
        System.out.println(&quot;0、  现在开始初始化容器&quot;);
        ApplicationContext factory = new ClassPathXmlApplicationContext(&quot;spring/spring-beans.xml&quot;);
        System.out.println(&quot;0、  容器初始化成功&quot;);
        //得到Product，并使用
        Product product = factory.getBean(&quot;product&quot;,Product.class);
        System.out.println(&quot;0、  hashCode : &quot; + product.hashCode());
        System.out.println(product);

        product = factory.getBean(&quot;product&quot;,Product.class);
        System.out.println(&quot;0、  hashCode : &quot; + product.hashCode());
        System.out.println(product);

        System.out.println(&quot;0、  现在开始关闭容器！&quot;);
        ((ClassPathXmlApplicationContext)factory).registerShutdownHook();
    }
}
</code></pre><h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><p>这里我们分别看一下scope 分别为 singleton 和 prototype 时的运行结果：</p>
<h3 id="singleton-的运行结果"><a href="#singleton-的运行结果" class="headerlink" title="singleton 的运行结果"></a>singleton 的运行结果</h3><pre><code>0、  现在开始初始化容器
1、  我是BeanFactoryPostProcessor接口实现类的构造器！！
1、  调用 BeanFactoryPostProcessor 接口的 postProcessBeanFactory 方法
2、  我是 BeanPostProcessor 接口实现类的构造器！！
3、  我是InstantiationAwareBeanPostProcessorAdapter接口实现类的构造器！！

3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessBeforeInstantiation 方法
4、  【构造器】调用Product的构造器
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessPropertyValues 方法
4、  【注入属性】注入属性description
4、  【注入属性】注入属性name
4、  【注入属性】注入属性stock
4、  【BeanNameAware接口】调用BeanNameAware.setBeanName()
4、  【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()
4、  【ApplicationContextAware接口】调用ApplicationContextAware.setApplicationContext()
2、  调用 BeanPostProcessor 接口的 postProcessBeforeInitialization 方法对属性进行更改！
4、  【InitializingBean接口】调用InitializingBean.afterPropertiesSet()
4、  【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法
2、  调用 BeanPostProcessor 接口的 postProcessAfterInitialization 方法对属性进行更改！
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessAfterInitialization 方法

0、  容器初始化成功

0、  hashCode : 1345604737
4、  Product [name=iphone 100, description=我是未来的iphone 100, stock=2000]
0、  hashCode : 1345604737
4、  Product [name=iphone 100, description=我是未来的iphone 100, stock=2000]

0、  现在开始关闭容器！
4、  【DiposibleBean接口】调用DiposibleBean.destory()
4、  【destroy-method】调用&lt;bean&gt;的destroy-method属性指定的销毁方法
</code></pre><h3 id="prototype的运行结果"><a href="#prototype的运行结果" class="headerlink" title="prototype的运行结果"></a>prototype的运行结果</h3><pre><code>0、  现在开始初始化容器
1、  我是BeanFactoryPostProcessor接口实现类的构造器！！
1、  调用 BeanFactoryPostProcessor 接口的 postProcessBeanFactory 方法
2、  我是 BeanPostProcessor 接口实现类的构造器！！
3、  我是InstantiationAwareBeanPostProcessorAdapter接口实现类的构造器！！
0、  容器初始化成功
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessBeforeInstantiation 方法

4、  【构造器】调用Product的构造器
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessPropertyValues 方法
4、  【注入属性】注入属性description
4、  【注入属性】注入属性name
4、  【注入属性】注入属性stock
4、  【BeanNameAware接口】调用BeanNameAware.setBeanName()
4、  【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()
4、  【ApplicationContextAware接口】调用ApplicationContextAware.setApplicationContext()
2、  调用 BeanPostProcessor 接口的 postProcessBeforeInitialization 方法对属性进行更改！
4、  【InitializingBean接口】调用InitializingBean.afterPropertiesSet()
4、  【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法
2、  调用 BeanPostProcessor 接口的 postProcessAfterInitialization 方法对属性进行更改！
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessAfterInitialization 方法

0、  hashCode : 1431641429
4、  Product [name=iphone 100, description=我是未来的iphone 100, stock=2000]

4、  【构造器】调用Product的构造器
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessPropertyValues 方法
4、  【注入属性】注入属性description
4、  【注入属性】注入属性name
4、  【注入属性】注入属性stock
4、  【BeanNameAware接口】调用BeanNameAware.setBeanName()
4、  【BeanFactoryAware接口】调用BeanFactoryAware.setBeanFactory()
4、  【ApplicationContextAware接口】调用ApplicationContextAware.setApplicationContext()
2、  调用 BeanPostProcessor 接口的 postProcessBeforeInitialization 方法对属性进行更改！
4、  【InitializingBean接口】调用InitializingBean.afterPropertiesSet()
4、  【init-method】调用&lt;bean&gt;的init-method属性指定的初始化方法
2、  调用 BeanPostProcessor 接口的 postProcessAfterInitialization 方法对属性进行更改！
3、  调用 InstantiationAwareBeanPostProcessor 接口的 postProcessAfterInitialization 方法

0、  hashCode : 1190716215
4、  Product [name=iphone 100, description=我是未来的iphone 100, stock=2000]

0、  现在开始关闭容器！
</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>为了能够直观的看出 scope 分别为 singleton 和 prototype 的区别，我这里专门使用了两次该Bean，我们可以看出</p>
<ul>
<li>当 scope 配置为 singleton 的时候，该bean的初始化是在容器启动时就实例化好了的，在业务程序中使用的时候每次获取的对象也都是同一个，你可以看到两次获取的 hashCode 是一致的。</li>
<li>当 scope 配置为 prototype 的时候，该bean的初始化是在业务程序使用该对象的时候即时初始化的，每次调用该Bean的时候都会重新初始化该对象，你可以看到两次获取的 hashCode 是不一致的。</li>
</ul>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>至此，spring bean的生命周期我们就解析完了，该篇中我们先给出了流程图，然后又采用文字进行了描述，最后使用代码给出了生命周期的演示。</p>
]]></content>
    
    <summary type="html">
    
      spring经过IOC把XML定义转换成BeanDefinition之后，要经过哪些步骤才能把BeanDefinition转换成Bean的实例的呢？这个实例的生命周期又是如何的呢？
    
    </summary>
    
      <category term="spring" scheme="http://gamesdoa.com/categories/spring/"/>
    
    
      <category term="spring" scheme="http://gamesdoa.com/tags/spring/"/>
    
      <category term="bean生命周期" scheme="http://gamesdoa.com/tags/bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
    
  </entry>
  
  <entry>
    <title>spring AOP解析</title>
    <link href="http://gamesdoa.com/spring-aop.html"/>
    <id>http://gamesdoa.com/spring-aop.html</id>
    <published>2017-08-04T16:00:00.000Z</published>
    <updated>2017-08-25T03:44:33.043Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是AOP"><a href="#什么是AOP" class="headerlink" title="什么是AOP"></a>什么是AOP</h1><p>AOP全称：Aspect Oriented Programming ，翻译成中文就是面向切面编程，主要的作用就是通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术.</p>
<p>AOP是spring核心组件中的一个比较重要的组成部分，可以利用AOP对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。</p>
<p>AOP一般用到哪些地方呢？</p>
<blockquote>
<p>一般在我们开发工程中经常使用AOP的地方主要是：日志记录，性能统计，安全控制，事务处理，异常处理等。</p>
</blockquote>
<p>AOP联盟对于AOP给出来一个框架，其中的概念如下：</p>
<ol>
<li>join point（连接点）：是程序执行中的一个精确执行点，例如类中的一个方法。它是一个抽象的概念，在实现AOP时，并不需要去定义一个join point。</li>
<li>point cut（切入点）：本质上是一个捕获连接点的结构。在AOP中，可以定义一个point cut，来捕获相关方法的调用。</li>
<li>advice（通知）：是point cut的执行代码，是执行“方面”的具体逻辑。</li>
<li>aspect（方面）：point cut和advice结合起来就是aspect，它类似于OOP中定义的一个类，但它代表的更多是对象间横向的关系。</li>
<li>introduce（引入）：为对象引入附加的方法或属性，从而达到修改对象结构的目的。有的AOP工具又将其称为mixin。</li>
</ol>
<p>Spring在实现AOP的时候遵循了该框架，但是也有一些变化：</p>
<ul>
<li>Advice接口 : 扩展了很多子接口，例如：BeforeAdvice、AfterAdvice、AfterReturningAdvice、ThrowsAdvice等，所有实现可以查看org.springframework.aop包下的声明。</li>
<li>Pointcut接口 ： 切入点决定要切入哪些方法，spring采用Pointcut作为切入点的抽象，其中getMethodMatcher()方法返回MethodMatcher，是一个定义的匹配规则，比如正则表达式。</li>
<li>Advisor接口 ： 通知器或者通知者，作为通知器当然是需要知道通知什么，因此：Advisor依赖于Advice，源码中也可以看到有Advice getAdvice()方法。Advisor的子接口PointcutAdvisor还依赖于Pointcut接口源码中Pointcut getPointcut()方法。也就是说：接口接口更确切的定位应该是包含了要通知谁和要通知什么，因此需要获取Advice和Pointcut。</li>
</ul>
<blockquote>
<p>Spring AOP相关的接口声明都在 <strong>org.springframework.aop</strong> 包下，需要了解更多可以自行查看。</p>
</blockquote>
<h1 id="Spring-AOP如何使用"><a href="#Spring-AOP如何使用" class="headerlink" title="Spring AOP如何使用"></a>Spring AOP如何使用</h1><p>我们用过一个简单的例子来看一下Spring 中如何使用AOP：</p>
<ul>
<li><p>使用AOP的话需要引入相应的JAR包：</p>
<ul>
<li>spring-beans</li>
<li>spring-aop</li>
<li>aspectjweaver</li>
<li>cglib-nodep</li>
<li>aopalliance</li>
</ul>
</li>
<li><p>我们采用普通的面向接口开发的形式编写我们的java代码：</p>
</li>
</ul>
<p>接口声明：</p>
<pre><code>package com.gamesdoa.test.aop;
public interface AopService {
    String saveBean();
    String delBean();
}
</code></pre><p>实现：</p>
<pre><code>package com.gamesdoa.test.aop.impl;

import com.gamesdoa.test.aop.AopService;

public class AopServiceImpl implements AopService {
    public String saveBean() {
        System.out.println(&quot;I&apos;m save!&quot;);
        return &quot;save&quot;;
    }

    public String delBean() {
        System.out.println(&quot;I&apos;m del!&quot;);
        return &quot;del&quot;;
    }
}
</code></pre><p>定义一个横切关注点，用于方法调用前后输出不同的时间：</p>
<pre><code>package com.gamesdoa.test.aop;

public class AopHandler {
    //方法开始前输出进入时间
    public void enterTime() {
        System.out.println(&quot;enter time:&quot; + System.currentTimeMillis());
    }
    //方法接受后输出离开时间
    public void leaveTime() {
        System.out.println(&quot;leave time:&quot; + System.currentTimeMillis());
    }

}
</code></pre><p>定义一个XML文件spring-aop.xml：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans
        http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
        http://www.springframework.org/schema/aop
        http://www.springframework.org/schema/aop/spring-aop-3.1.xsd&quot;&gt;

    &lt;bean id=&quot;aopServiceImpl&quot; class=&quot;com.gamesdoa.test.aop.impl.AopServiceImpl&quot; /&gt;
    &lt;bean id=&quot;timeHandler&quot; class=&quot;com.gamesdoa.test.aop.AopHandler&quot; /&gt;

    &lt;aop:config proxy-target-class=&quot;true&quot;&gt;
        &lt;aop:aspect id=&quot;time&quot; ref=&quot;timeHandler&quot;&gt;
            &lt;aop:pointcut id=&quot;addAllMethod&quot; expression=&quot;execution(* com.gamesdoa.test.aop.AopService.*(..))&quot; /&gt;&lt;!-- 哪些方法需要织入 --&gt;
            &lt;!-- 这里还可以是异常时，返回前，等等详情查看springapi --&gt;
            &lt;aop:before method=&quot;enterTime&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt;&lt;!-- 开始前 --&gt;
            &lt;aop:after method=&quot;leaveTime&quot; pointcut-ref=&quot;addAllMethod&quot; /&gt;&lt;!-- 结束后 --&gt;
        &lt;/aop:aspect&gt;
    &lt;/aop:config&gt;
&lt;/beans&gt;
</code></pre><p>编写测试类：</p>
<pre><code>package com.gamesdoa.test.aop;

import org.junit.Test;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.ClassPathXmlApplicationContext;

public class TestAop {
    @Test
    public void testAop() {
        ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;spring-aop.xml&quot;);

        AopService service = (AopService)ac.getBean(&quot;aopServiceImpl&quot;);
        service.saveBean();
        System.out.println(&quot;------------我是华丽的分界线------------&quot;);
        service.delBean();
    }
}
</code></pre><p>接下来就是运行了，运行结果是这样的：</p>
<pre><code>enter time:1503629611721
I&apos;m save!
leave time:1503629611722
------------我是华丽的分界线------------
enter time:1503629611722
I&apos;m del!
leave time:1503629611722
</code></pre><p>可以看出来运行时先输入了进入时间，然后运行方法内的实现，最后返回结束之后输出了离开时间。</p>
]]></content>
    
    <summary type="html">
    
      spring几大核心组件中有一个就是AOP(Aspect Oriented Programming)，那么什么是AOP呢？我们应该怎么样使用？它的原理是什么？它对我们的编程有什么影响?下面我们就来分析分析
    
    </summary>
    
      <category term="spring" scheme="http://gamesdoa.com/categories/spring/"/>
    
    
      <category term="spring" scheme="http://gamesdoa.com/tags/spring/"/>
    
      <category term="aop" scheme="http://gamesdoa.com/tags/aop/"/>
    
  </entry>
  
  <entry>
    <title>spring IOC解析</title>
    <link href="http://gamesdoa.com/spring-ioc.html"/>
    <id>http://gamesdoa.com/spring-ioc.html</id>
    <published>2017-07-29T16:00:00.000Z</published>
    <updated>2017-08-23T08:23:30.782Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是IOC"><a href="#什么是IOC" class="headerlink" title="什么是IOC"></a>什么是IOC</h1><p>IOC全称：Inversion of Control ，翻译成中文就是控制反转，主要的作用就是把我们原来在程序里面关联两个对象使用的new Object()方法，交给容器控制，也就是说将<strong>对象的创建和依赖关系交给容器</strong></p>
<p>那么对象之间的依赖怎么表示呢？</p>
<blockquote>
<p>可以用 xml ， properties 文件等语义化配置文件表示。</p>
</blockquote>
<p>描述对象关系的文件存放在哪里？</p>
<blockquote>
<p>可能是 classpath ， filesystem ，或者是 URL 网络资源， servletContext 等。</p>
</blockquote>
<h1 id="Spring-IOC体系结构"><a href="#Spring-IOC体系结构" class="headerlink" title="Spring IOC体系结构"></a>Spring IOC体系结构</h1><p>Spring IOC体系结构中有两个最重要的接口：</p>
<ul>
<li>BeanFactory：核心工厂接口，这个主要是创建Bean的</li>
<li>BeanDefinition ： bean对象以及其相互关系的定义接口</li>
</ul>
<h2 id="BeanFactory"><a href="#BeanFactory" class="headerlink" title="BeanFactory"></a>BeanFactory</h2><p><img src="https://github.com/gamesdoa/img0/raw/master/spring/BeanFactory.jpg" alt="BeanFactory架构图"><br>从这个架构图中可以看出BeanFactory的架构继承实现关系</p>
<p>BeanFactory作为最顶层的一个接口类，它定义了IOC容器的基本功能规范；</p>
<p>BeanFactory 有三个子类：ListableBeanFactory、HierarchicalBeanFactory 和AutowireCapableBeanFactory。从上图中我们可以发现最终的默认实现类是 DefaultListableBeanFactory，他实现了所有的接口。</p>
<p>spring为何要定义这么多层次的接口？其实这个设计主要是为了区分在 Spring 内部在操作过程中对象的传递和转化过程中，对对象的数据访问所做的限制。</p>
<blockquote>
<p>ListableBeanFactory 接口表示这些 Bean 是可列表的;</p>
<p>HierarchicalBeanFactory 表示的是这些 Bean 是有继承关系的，也就是每个Bean 有可能有父 Bean;</p>
<p>AutowireCapableBeanFactory 接口定义 Bean 的自动装配规则</p>
</blockquote>
<pre><code>package org.springframework.beans.factory;

import org.springframework.beans.BeansException;

public interface BeanFactory {

    /**
     * 用于取消引用FactoryBean实例，并将其与FactoryBean创建的bean进行区分
     * 例如，如果获取名为myJndiObject的bean是FactoryBean，则获取＆myJndiObject将返回工厂，
     * 而不返回工厂返回的实例。
     */
    String FACTORY_BEAN_PREFIX = &quot;&amp;&quot;;

    /**
     * 返回指定bean的一个可能是共享的或独立的实例。
     * 如果在此工厂实例中找不到该bean，将查找父工厂。
     * @param 要查找的bean名称
     * @返回一个Bean的实例
     * @throws NoSuchBeanDefinitionException如果没有bean定义指定名称
     * @throws BeansException如果无法获取该bean
     */
    Object getBean(String name) throws BeansException;

    /**
     * 返回指定bean的一个可能是共享的或独立的实例。
     * 如果在此工厂实例中找不到该bean，将查找父工厂。
     * @param 要查找的bean名称
     * @param requiredType键入bean必须匹配。可以是一个接口或超类，或匹配任意的null。
         例如，如果值是Object.class，这个方法将无论什么类都成功返回实例。
     * @返回一个Bean的实例
     * @throws NoSuchBeanDefinitionException如果没有这样的bean定义
     * @throws BeanNotOfRequiredTypeException如果bean不是必需的类型
     * @throws BeansException如果无法创建bean 
     */
    &lt;T&gt; T getBean(String name, Class&lt;T&gt; requiredType) throws BeansException;

    /**
     * 返回与给定对象类型唯一匹配的bean实例（如果有的话）。
     * @param requiredType键入bean必须匹配;可以是一个接口或超类。不允许为null。
     * 此方法进入ListableBeanFactory按类型查找区域，但也可以根据名称翻译成常规的副名称查找给定类型。
     * 对于多组bean的更广泛的检索操作，使用ListableBeanFactory或BeanFactoryUtils。
     * 返回匹配所需类型的单个bean的实例
     * @throws NoSuchBeanDefinitionException如果没有找到一个匹配的bean
     */
    &lt;T&gt; T getBean(Class&lt;T&gt; requiredType) throws BeansException;

    /**
     *返回指定bean的一个可能是共享的或独立的实例。
     * 允许指定显式构造函数参数/工厂方法参数，覆盖bean定义中指定的默认参数（如果有）。
     * @param 要查找的bean名称
     * @param args使用参数，如果使用明确的参数创建一个原型静态工厂方法。在任何其他情况下使用非空args值无效。
     * @返回一个Bean的实例
     * @throws NoSuchBeanDefinitionException如果没有这样的bean定义
     * @throws BeanDefinitionStoreException如果已经给出了参数受影响的bean不是原型
     * @throws BeansException如果无法创建bean
     */
    Object getBean(String name, Object... args) throws BeansException;

    /**
     *这个bean工厂是否包含一个bean定义或外部注册的具有给定名称的单例实例？
     *如果给定的名称是别名，它将被翻译回相应的规范bean名称。
     *如果这个工厂是分层的，如果在这个工厂实例中找不到该bean，则会在其他工厂中查找，直到找到或者所有工厂查询完。
     *如果在相应的范围内找到匹配给定名称的bean定义或单例实例，该方法将返回true，无论找到的bean是具体还是抽象，懒加载或立即加载。
      因此，请注意，此方法的真实返回值并不一定表示#getBean将能够获取相同名称的实例。
     * @param 要查找的bean名称
     * @返回是否存在具有给定名称的bean
     */
    boolean containsBean(String name);

    /**
     * 这个bean是不是单例的？ 也就是说，#getBean是否会始终返回相同的实例？
     * 注意：此方法返回false并不能清楚的说明是单例。它也可能是非单例实例，只是对应的作用域不同。 使用#isPrototype操作来显式检查是否全局单例。
     * 将别名转换回相应的规范bean名称。 如果在此工厂实例中找不到该bean，将查询父工厂。
     * @param 要查找的bean名称
     * @返回这个bean是否对应于单例实例
     * @throws NoSuchBeanDefinitionException如果没有给定名称的bean
     */
    boolean isSingleton(String name) throws NoSuchBeanDefinitionException;

    /**
     * bean是不是一个原型，#getBean是不是会一直返回独立的实例？
     * 注意：此方法返回false并不能清楚的说明是单例。它也可能是非单例实例，只是对应的作用域不同。 使用{@link #isSingleton}操作来显式检查共享的单例实例。
     * 将别名转换回相应的规范bean名称。 如果在此工厂实例中找不到该bean，将查询父工厂。
     * @param 要查找的bean名称
     * @返回这个bean是否会始终提供独立的实例
     * @throws NoSuchBeanDefinitionException如果没有给定名称的bean
     */
    boolean isPrototype(String name) throws NoSuchBeanDefinitionException;

    /**
     *检查给定名称的bean是否与指定的类型匹配。 
     * 更具体地说，检查给定名称的{@link #getBean}调用是否返回可分配给指定目标类型的对象。
     * 将别名转换回相应的规范bean名称。 如果在此工厂实例中找不到该bean，将查询父工厂。
     * @param 要查找的bean名称
     * @param targetType匹配的类型
     * @return  true 如果bean类型匹配， false 如果不匹配或无法确定
     * @throws NoSuchBeanDefinitionException如果没有给定名称的bean
     */
    boolean isTypeMatch(String name, Class&lt;?&gt; targetType) throws NoSuchBeanDefinitionException;

    /**
     *确定具有给定名称的bean的类型。 更具体地说，确定{@link #getBean}将为给定名称返回的对象的类型。
     * 对于{@link FactoryBean}，返回FactoryBean创建的对象类型，如{@link FactoryBean＃getObjectType（））所示。
     * 将别名转换回相应的规范bean名称。 如果在此工厂实例中找不到该bean，将查询父工厂。
     * @param命名要查询的bean的名称 返回bean的类型，如果不可确定，则返回null
     * @throws NoSuchBeanDefinitionException如果没有给定名称的bean
     */
    Class&lt;?&gt; getType(String name) throws NoSuchBeanDefinitionException;

    /**
     *返回给定bean名称的别名（如果有）。 当在{@link #getBean}调用中使用时，所有这些别名都指向同一个bean。
     * 如果给定的名称是别名，将返回相应的原始bean名称和其他别名（如果有的话），原始bean名称是数组中的第一个元素。
     * 如果在此工厂实例中找不到该bean，将查找父工厂。
     * @param 要查找的bean名称
     * @返回别名，如果没有，则返回一个空数组
     */
    String[] getAliases(String name);

}
</code></pre><p>从源码上看BeanFactory里只对IOC容器的基本行为作了定义，根本不关心你的bean是如何定义又是怎样加载的。正如我们只关心工厂里能得到什么产品对象，至于工厂是怎么生产这些对象的，这个基本接口时不需要关心的。</p>
<p>而要知道工厂是如何产生对象的，我们需要看具体的IOC容器实现，spring提供了许多IOC容器的实现。</p>
<blockquote>
<p>比如XmlBeanFactory，ClasspathXmlApplicationContext等。</p>
<ul>
<li>XmlBeanFactory就是针对最基本的ioc容器的实现，这个IOC容器可以读取XML文件定义的BeanDefinition（XML文件中对bean的描述）。</li>
<li>ApplicationContext是Spring提供的一个高级的IoC容器，它除了能够提供IoC容器的基本功能外，还为用户提供了其他的附加服务。<blockquote>
<p>从ApplicationContext接口的实现，我们看出其特点：</p>
</blockquote>
</li>
</ul>
</blockquote>
<pre><code>org.springframework.context

import org.springframework.beans.factory.HierarchicalBeanFactory;
import org.springframework.beans.factory.ListableBeanFactory;
import org.springframework.beans.factory.config.AutowireCapableBeanFactory;
import org.springframework.core.env.EnvironmentCapable;
import org.springframework.core.io.support.ResourcePatternResolver;

public interface ApplicationContext extends EnvironmentCapable, 
    ListableBeanFactory, HierarchicalBeanFactory,
    MessageSource, ApplicationEventPublisher, ResourcePatternResolver {
    }
</code></pre><blockquote>
<blockquote>
<ol>
<li>支持信息源，可以实现国际化。（实现MessageSource接口）</li>
<li>支持应用事件。(实现ApplicationEventPublisher接口)</li>
<li>访问资源。(实现ResourcePatternResolver接口)</li>
</ol>
</blockquote>
</blockquote>
<h2 id="BeanDefinition"><a href="#BeanDefinition" class="headerlink" title="BeanDefinition"></a>BeanDefinition</h2><p><img src="https://github.com/gamesdoa/img0/raw/master/spring/BeanDefinition.jpg" alt="BeanDefinition设计架构"></p>
<ul>
<li>注 BeanDefinition是用来描述各种bean对象以及其相互的关系的定义继承了两个接口 <blockquote>
<p>AttributeAccessor:使其具有了处理属性的能力</p>
<p>BeanMetadataElement : 使其具有了获取bean配置定义的元素 </p>
</blockquote>
</li>
</ul>
<p>看一下源码：</p>
<pre><code>package org.springframework.beans.factory.config;

import org.springframework.beans.BeanMetadataElement;
import org.springframework.beans.MutablePropertyValues;
import org.springframework.core.AttributeAccessor;

public interface BeanDefinition extends AttributeAccessor, BeanMetadataElement {

    /**
     * 单例表示 : &quot;singleton&quot;.
     * 扩展bean工厂可能会支持更多的范围。
     */
    String SCOPE_SINGLETON = ConfigurableBeanFactory.SCOPE_SINGLETON;

    /**
     * 标准原型范围的范围标识符：“原型”。
     * 扩展bean工厂可能会支持更多的范围。
     */
    String SCOPE_PROTOTYPE = ConfigurableBeanFactory.SCOPE_PROTOTYPE;


    /**
     * 角色提示，表明一个  BeanDefinition 是应用程序的主要部分。
     * 通常对应于用户定义的bean。
     */
    int ROLE_APPLICATION = 0;


    /**
     * 返回此bean定义的父定义的名称（如果有）。
     */
    String getParentName();

    /**
     * 设置此bean定义的父定义的名称（如果有）。
     */
    void setParentName(String parentName);

    /**
     * 返回此bean定义的当前bean类名。
     * 请注意，这不一定是在运行时使用的实际类名，以便于子类定义从其父类覆盖/继承类名。 
     * 因此，不要认为这是在运行时确定的bean类型，而仅仅是在各个bean定义级别使用它来做解析的目的。
     */
    String getBeanClassName();

    /**
     * 覆盖此bean定义的bean类名称。
     * 可以在bean工厂之后处理修改类名称，通常用解析变量替换原始类名。
     */
    void setBeanClassName(String beanClassName);

    /**
     * 返回工厂bean名称，如果有的话。
     */
    String getFactoryBeanName();

    /**
     * 指定要使用的工厂bean（如果有）。
     */
    void setFactoryBeanName(String factoryBeanName);

    /**
     * 返回工厂方式，如果有的话
     */
    String getFactoryMethodName();

    /**
     * 指定工厂方法（如果有）。 该方法将使用构造函数参数进行调用，如果没有指定，则不使用参数。 
     * 该方法将在指定的工厂bean（如果有）或其他方式在本地bean类上作为静态方法调用。
    * @param factoryMethodName 静态工厂方法名称，如果正常的构造函数创建应该使用null
     */
    void setFactoryMethodName(String factoryMethodName);

    /**
     * 返回此bean的当前目标作用域的名称，如果不知道返回null
     */
    String getScope();

    /**
     * 覆盖当前的目标作用域
     * @see #SCOPE_SINGLETON
     * @see #SCOPE_PROTOTYPE
     */
    void setScope(String scope);

    /**
     * 返回这个bean是否应该被懒加载，即启动时不需要立即实例化。
     * 仅适用于单例
     */
    boolean isLazyInit();

    /**
     * 设置这个bean是否需要懒加载
     * 如果是false，那么bean将在启动时被bean factory实例化，bean factory会对单例立即初始化
     */
    void setLazyInit(boolean lazyInit);

    /**
     * 获取依赖的beanName
     */
    String[] getDependsOn();

    /**
     * 设置依赖的beanName
     * bean factory将保证这些bean首先被初始化.
     */
    void setDependsOn(String[] dependsOn);

    /**
     * 返回这个bean是否是自动关联到其他bean。
     */
    boolean isAutowireCandidate();

    /**
     * 设置这个bean是否自动关联到其他的bean.
     */
    void setAutowireCandidate(boolean autowireCandidate);

    /**
     * 返回该bean是否是主要的关联着。 如果这个值对于多个匹配bean中的一个bean是真实的，则它将作为一个主要关联者。
     */
    boolean isPrimary();

    /**
     * 设置这个bean是否是为主要的关联者。
     * 如果这个值对于多个匹配bean中的一个bean是真实的，则它将用作主要关联者
     */
    void setPrimary(boolean primary);


    /**
     * 返回此bean的构造函数的参数值。
     * 可以在bean factory 处理期间修改返回的实例。
     * @返回ConstructorArgumentValues对象（never  null）
     */
    ConstructorArgumentValues getConstructorArgumentValues();

    /**
     * 返回要应用于bean的新实例的属性值.
     * 可以在bean factory 处理期间修改返回的实例。
     * @return the MutablePropertyValues object (never &lt;code&gt;null&lt;/code&gt;)
     */
    MutablePropertyValues getPropertyValues();


    /**
     * 返回是否是一个单例，如果是一个单例，在所有调用上返回同一个实例。
     */
    boolean isSingleton();

    /**
     * 返回这是否为原型，如果是每个调用返回一个独立的实例。
     * @see #SCOPE_PROTOTYPE
     */
    boolean isPrototype();

    /**
     * 返回这个bean是否是“抽象的”，也就是，不要进行实例化。
     */
    boolean isAbstract();

    /**
     * 获取此BeanDefinition的角色提示。 角色提示为工具提供了特定BeanDefinition的重要性
     * @see #ROLE_APPLICATION
     * @see #ROLE_INFRASTRUCTURE
     * @see #ROLE_SUPPORT
     */
    int getRole();

    /**
     * 返回这个bean定义的可读的描述。
     */
    String getDescription();

    /**
     *返回此bean定义来源的资源的描述（用于出现错误情况下显示上下文）。
     */
    String getResourceDescription();

    /**
     * 返回原始BeanDefinition，不存在返回null。
     * 允许检索装饰的bean定义（如果有）。
     * 请注意，此方法返回当前发起者。通过发起者链迭代，以查找用户定义的原始BeanDefinition。
     */
    BeanDefinition getOriginatingBeanDefinition();

}
</code></pre><p>从源码来看这里和依赖关系相关的方法主要是 <strong>getDependsOn()</strong>和<strong>setDependsOn()</strong>，也是在初始化过程中把读取到的依赖关系通过set方法设置到BeanDefinition中保存的。</p>
<h1 id="spring-IOC-流程"><a href="#spring-IOC-流程" class="headerlink" title="spring IOC 流程"></a>spring IOC 流程</h1><p><strong>流程概述</strong></p>
<p>在使用spring IOC的情况下，需要什么信息才能创建bean呢？</p>
<ol>
<li>需要持有各种bean的定义</li>
<li>需要持有bean之间的依赖关系</li>
<li>需要一个工具完成上述需求的读取</li>
</ol>
<p>前面介绍BeanFactory的时候我们说到，BeanFactory的默认实现是DefaultListableBeanFactory，我们参看源码可以看到在DefaultListableBeanFactory中持有一个BeanDefinition的集合，该集合记录了从Resource定位、载入和注册的bean的定义和依赖关系。</p>
<pre><code>private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;();
</code></pre><blockquote>
<p>总结的来说：</p>
<ul>
<li>需要一个file指向我们的xml：资源定位，指到XML的位置</li>
<li>需要一个Reader读取XML： DOM解析</li>
<li>需要将解析出来的数据设置到beanDefinitionMap中。</li>
</ul>
</blockquote>
<p><strong>ClasspathXmlApplicationContext解析</strong></p>
<h2 id="整体看继承实现关系"><a href="#整体看继承实现关系" class="headerlink" title="整体看继承实现关系"></a>整体看继承实现关系</h2><p>ClasspathXmlApplicationContext是ApplicationContext容器继承体系中的一个具体实现，该体系中还包含XmlWebApplicationContext和FileSystemXmlApplicationContext等，其继承体系如下图所示：<br><img src="https://github.com/gamesdoa/img0/raw/master/spring/ApplicationContext.jpg" alt="XmlWebApplicationContext设计架构图"></p>
<blockquote>
<ul>
<li>图中关注标红的对象ApplicationContext基本接口；</li>
<li>ClasspathXmlApplicationContext这个类是从classpath下加载配置文件(适合于相对路径方式加载)；</li>
<li>XmlWebApplicationContext专为web工程定制的方法，推荐Web项目中使用；</li>
<li>FileSystemXmlApplicationContext这个类是从文件绝对路径加载配置文件。</li>
</ul>
<p>注：ApplicationContext允许上下文嵌套，通过保持父上下文可以维持一个上下文体系。对于bean的查找可以在这个上下文体系中发生，首先检查当前上下文，其次是父上下文，逐级向上，这样为不同的Spring应用提供了一个共享的bean定义环境。(在BeanFactory源码中获取bean的方法注释中有提到过)</p>
</blockquote>
<h2 id="ClasspathXmlApplicationContext的IOC容器流程"><a href="#ClasspathXmlApplicationContext的IOC容器流程" class="headerlink" title="ClasspathXmlApplicationContext的IOC容器流程"></a>ClasspathXmlApplicationContext的IOC容器流程</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre><code>//该方法参数中classpath: 前缀是不需要的，默认就是指项目的classpath路径下面；
//这也就是说用ClassPathXmlApplicationContext时默认的根目录是在WEB-INF/classes下面，而不是项目根目录。
ApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;/applicationcontext.xml&quot;);
</code></pre><h3 id="ClassPathXmlApplicationContext完整源码"><a href="#ClassPathXmlApplicationContext完整源码" class="headerlink" title="ClassPathXmlApplicationContext完整源码"></a>ClassPathXmlApplicationContext完整源码</h3><p>下面我们来看一下ClassPathXmlApplicationContext源码中都干了些什么事情？</p>
<pre><code>package org.springframework.context.support;

import org.springframework.beans.BeansException;
import org.springframework.context.ApplicationContext;
import org.springframework.core.io.ClassPathResource;
import org.springframework.core.io.Resource;
import org.springframework.util.Assert;

public class ClassPathXmlApplicationContext extends AbstractXmlApplicationContext {

    private Resource[] configResources;

    /**
     * 用bean-style的配置创建一个新的ClassPathXmlApplicationContext.
     */
    public ClassPathXmlApplicationContext() {
    }

    /**
     * 用bean-style的配置创建一个新的ClassPathXmlApplicationContext.
     * @param parent 父上下文
     */
    public ClassPathXmlApplicationContext(ApplicationContext parent) {
        super(parent);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * @param configLocation 资源位置
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String configLocation) throws BeansException {
        this(new String[] {configLocation}, true, null);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * @param configLocations 资源位置数组
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String... configLocations) throws BeansException {
        this(configLocations, true, null);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * @param configLocations 资源位置数组
     * @param parent 父上下文
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String[] configLocations, ApplicationContext parent) throws BeansException {
        this(configLocations, true, parent);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件中加载定义。
     * @param configLocations 资源位置数组
     * @param refresh 是否自动刷新上下文，加载所有bean定义并创建所有单例。或者，在进一步配置上下文之后手动调用刷新。
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh) throws BeansException {
        this(configLocations, refresh, null);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件中加载定义。
     * @param configLocations 资源位置数组
     * @param refresh 是否自动刷新上下文，加载所有bean定义并创建所有单例。或者，在进一步配置上下文之后手动调用刷新。
     * @param parent 父上下文
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException {
        super(parent);
        setConfigLocations(configLocations);
        if (refresh) {
            refresh();
        }
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * 这是一个加载资源路径相对于给定类的方法。
     * 为了充分的灵活性，请考虑使用GenericApplicationContext与XmlBeanDefinitionReader和ClassPathResource参数。
     * @param path 类路径内的相对（或绝对）路径
     * @param clazz 加载资源的类（给定基础的路径）
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String path, Class clazz) throws BeansException {
        this(new String[] {path}, clazz);
    }

    /**
     * 创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * @param paths 类路径内的相对（或绝对）路径数组
     * @param clazz 加载资源的类（给定基础的路径）
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String[] paths, Class clazz) throws BeansException {
        this(paths, clazz, null);
    }

    /**
     * 根据给定的路径创建一个新的ClassPathXmlApplicationContext，并从给定的XML文件加载definitions并自动刷新上下文。
     * @param paths 类路径内的相对（或绝对）路径数组
     * @param clazz 加载资源的类（给定基础的路径）
     * @param parent 父上下文
     * @throws BeansException 如果创建失败抛出异常
     */
    public ClassPathXmlApplicationContext(String[] paths, Class clazz, ApplicationContext parent)
            throws BeansException {
        super(parent);
        Assert.notNull(paths, &quot;Path array must not be null&quot;);
        Assert.notNull(clazz, &quot;Class argument must not be null&quot;);
        this.configResources = new Resource[paths.length];
        for (int i = 0; i &lt; paths.length; i++) {
            this.configResources[i] = new ClassPathResource(paths[i], clazz);
        }
        refresh();
    }

    @Override
    protected Resource[] getConfigResources() {
        return this.configResources;
    }
}
</code></pre><h3 id="解析初始化"><a href="#解析初始化" class="headerlink" title="解析初始化"></a>解析初始化</h3><p>回到我们刚刚的初始化部分，将会调用构造函数：</p>
<pre><code>public ClassPathXmlApplicationContext(String configLocation) throws BeansException {
    this(new String[] {configLocation}, true, null);
}
</code></pre><p>该构造函数实际上调用</p>
<pre><code>public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException {
    super(parent);
    setConfigLocations(configLocations);
    if (refresh) {
        refresh();
    }
}
</code></pre><blockquote>
<p>通过分析ClassPathXmlApplicationContext的源代码和我们单独提出来的初始化方法可以知道，在创建ClassPathXmlApplicationContext容器时，构造方法做以下三项工作：</p>
<ul>
<li>用父类容器的构造方法(super(parent)方法)为容器设置好Bean资源加载器。主要是设置了下面这三个属性<blockquote>
<p>this.parent = parent;//父上下文</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>this.resourcePatternResolver = getResourcePatternResolver();//资源解析器</p>
<p>this.environment = this.createEnvironment();//环境</p>
</blockquote>
<ul>
<li>调用父类AbstractRefreshableConfigApplicationContext的setConfigLocations(configLocations)方法设置Bean定义的资源文件的路径。</li>
<li>是否立刻刷新上下文，如果不立刻刷新的话可以在进一步配置上下文之后手动调用刷新。</li>
</ul>
</blockquote>
<h4 id="设置Bean资源加载器"><a href="#设置Bean资源加载器" class="headerlink" title="设置Bean资源加载器"></a>设置Bean资源加载器</h4><p>接下来看一下ClassPathXmlApplicationContext的父类AbstractApplicationContext在初始化IoC容器中会做哪些事情，也就是设置Bean资源加载器这里，我们可以从架构图上看到AbstractApplicationContext并不是ClassPathXmlApplicationContext的直接父类，而是四层父类，中间的父类在初始化的时候只是调用了super(parent)方法，具体的处理还是在AbstractApplicationContext中，这部分的主要源码如下：</p>
<pre><code>public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext, DisposableBean {  
    //静态初始化块，在整个容器创建过程中只执行一次  
    static {  
        //为了避免应用程序在Weblogic8.1关闭时出现类加载异常加载问题，加载IoC容器关闭事件(ContextClosedEvent)类  
        ContextClosedEvent.class.getName();  
    }
    ……
    //ClassPathXmlApplicationContextt调用父类构造方法调用的就是该方法  
    public AbstractApplicationContext(ApplicationContext parent) {  
        this.parent = parent;
        this.resourcePatternResolver = getResourcePatternResolver();
        this.environment = this.createEnvironment();
    }  
    //获取一个Spring Source的加载器用于读入Spring Bean定义资源文件  
    protected ResourcePatternResolver getResourcePatternResolver() {
        //AbstractApplicationContext继承DefaultResourceLoader，也是一个Spring资源加载器，其getResource(String location)方法用于载入资源 
        return new PathMatchingResourcePatternResolver(this);
    } 
    ……  
}
</code></pre><p>AbstractApplicationContext构造方法中调用的getResourcePatternResolver()方法中创建了一个新的PathMatchingResourcePatternResolver创建Spring资源加载器：</p>
<pre><code>public class PathMatchingResourcePatternResolver implements ResourcePatternResolver {
    ……
    public PathMatchingResourcePatternResolver(ResourceLoader resourceLoader) {
        Assert.notNull(resourceLoader, &quot;ResourceLoader must not be null&quot;);
        this.resourceLoader = resourceLoader;
    }
    ……
}
</code></pre><h4 id="定位bean定义的资源文件"><a href="#定位bean定义的资源文件" class="headerlink" title="定位bean定义的资源文件"></a>定位bean定义的资源文件</h4><p>在设置完容器的资源加载器之后，接下来ClassPathXmlApplicationContext执行setConfigLocations方法通过调用其父类AbstractRefreshableConfigApplicationContext的方法进行对指定Bean定义的资源文件的定位，该方法的源码如下：</p>
<pre><code>public abstract class AbstractRefreshableConfigApplicationContext extends AbstractRefreshableApplicationContext 
    implements BeanNameAware, InitializingBean {
    ……

    /**
     * 在init-param style中设置此应用程序上下文的配置位置，即用逗号，分号或空格分隔的不同位置。
     * 如果未设置，则实施可能会使用默认值。
     */
    public void setConfigLocation(String location) {
        setConfigLocations(StringUtils.tokenizeToStringArray(location, CONFIG_LOCATION_DELIMITERS));
    }

    /**
     * 设置此应用程序上下文的配置位置.
     * 如果未设置，则使用时可能会使用默认值。
     */
    public void setConfigLocations(String[] locations) {
        if (locations != null) {
            Assert.noNullElements(locations, &quot;Config locations must not be null&quot;);
            this.configLocations = new String[locations.length];
            for (int i = 0; i &lt; locations.length; i++) {
                //resolvePath为同一个类中将字符串解析为路径的方法
                this.configLocations[i] = resolvePath(locations[i]).trim();
            }
        }
        else {
            this.configLocations = null;
        }
    }
    ……
}
</code></pre><blockquote>
<p>通过这两个方法的源码我们可以看出，我们既可以使用一个字符串来配置多个Spring Bean定义文件，也可以使用字符串数组，即下面两种方式都是可以的：</p>
<ul>
<li>ClasspathResource res = new ClasspathResource(“a.xml,b.xml,……”);  多个资源文件路径之间可以是用”,;/t/n”等分隔。</li>
<li>ClasspathResource res = new ClasspathResource(newString[]{“a.xml”,”b.xml”,……});</li>
</ul>
</blockquote>
<p>到这里，Spring IoC容器在初始化时将配置的Bean定义文件定位为Spring封装的Resource的工作就完成了。</p>
<h4 id="refresh方法"><a href="#refresh方法" class="headerlink" title="refresh方法"></a>refresh方法</h4><p>我们说过初始化过程包含Resource定位、载入和Bean注册三个步骤，各个我们学习了Resource定位问题，下面我们来看一下载入这一步。<br>我们看到在初始化的第三步判断是否立刻刷新上下文，这里就是载入的入口部分了，也就是refresh()方法，refresh()是一个模板方法。</p>
<h5 id="refresh源码"><a href="#refresh源码" class="headerlink" title="refresh源码"></a>refresh源码</h5><p>ClassPathXmlApplicationContext通过调用其父类AbstractApplicationContext的refresh()函数启动整个IoC容器对Bean定义的载入过程：</p>
<pre><code>public abstract class AbstractApplicationContext extends DefaultResourceLoader
    implements ConfigurableApplicationContext, DisposableBean {
    ……
    public void refresh() throws BeansException, IllegalStateException {
        synchronized (this.startupShutdownMonitor) {
            // 调用容器准备刷新的方法，获取容器的当时时间，同时给容器设置同步标识  
            prepareRefresh();

            // 告诉子类启动refreshBeanFactory()方法，Bean定义资源文件的载入从子类的refreshBeanFactory()方法启动  
            ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();

            // 为BeanFactory配置容器特性，例如类加载器、事件处理器等 
            prepareBeanFactory(beanFactory);

            try {
                // 为容器的某些子类指定特殊的BeanPost事件处理器  
                postProcessBeanFactory(beanFactory);

                //调用所有该上下文中注册的BeanFactoryPostProcessor的Bean 
                invokeBeanFactoryPostProcessors(beanFactory);

                // 为BeanFactory注册BeanPost事件处理器. 
                // BeanPostProcessor是Bean后置处理器，用于监听容器触发的事件  
                registerBeanPostProcessors(beanFactory);

                // 初始化该上下文的信息源，和国际化相关.
                initMessageSource();

                // 初始化该上下文容器事件传播器.
                initApplicationEventMulticaster();

                // 在特定的上下文子类中初始化其他特殊的bean.
                onRefresh();

                // 检查监听器bean并注册它们.
                registerListeners();

                // 实例化所有剩下的（非lazy-init）单例.
                finishBeanFactoryInitialization(beanFactory);

                // 最后一步：发布相应的事件.
                finishRefresh();
            } catch (BeansException ex) {
                //销毁已经创建的单例，以避免资源悬空.
                destroyBeans();
                // 重置 &apos;active&apos; 标识.
                cancelRefresh(ex);
                // 抛出异常给调用者.
                throw ex;
            }
        }
    }
    ……
    /**
     * 告诉子类启动refreshBeanFactory()方法，
     * @return 刷新的BeanFactory实例
     */
    protected ConfigurableListableBeanFactory obtainFreshBeanFactory() {
        //这里使用了委派设计模式，父类定义了抽象的refreshBeanFactory()方法，具体实现调用子类容器的refreshBeanFactory()方法
        refreshBeanFactory();
        ConfigurableListableBeanFactory beanFactory = getBeanFactory();
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Bean factory for &quot; + getDisplayName() + &quot;: &quot; + beanFactory);
        }
        return beanFactory;
    }
    ……
    protected abstract void refreshBeanFactory() throws BeansException, IllegalStateException;
    ……
}
</code></pre><p>Spring IoC容器载入Bean定义的资源文件从其子类容器的refreshBeanFactory()方法启动，所以整个refresh()中“ConfigurableListableBeanFactory beanFactory =obtainFreshBeanFactory();”这句以后代码的都是注册容器的信息源和生命周期事件，载入过程就是从这句代码启动。</p>
<p>refresh()方法的作用是：在创建IoC容器前，如果已经有容器存在，则需要把已有的容器销毁和关闭，以保证在refresh之后使用的是新建立起来的IoC容器。refresh的作用类似于对IoC容器的重启，在新建立好的容器中对容器进行初始化，对Bean定义资源进行载入。</p>
<h5 id="refreshBeanFactory源码"><a href="#refreshBeanFactory源码" class="headerlink" title="refreshBeanFactory源码"></a>refreshBeanFactory源码</h5><ul>
<li>AbstractApplicationContext类中只抽象定义了refreshBeanFactory()方法，容器真正调用的是其子类AbstractRefreshableApplicationContext实现的refreshBeanFactory()方法，</li>
</ul>
<p>方法的源码如下：</p>
<pre><code>public abstract class AbstractRefreshableApplicationContext extends AbstractApplicationContext {
    ……
    /**
     * 此实现将对该上下文的底层BeanFactory进行实际刷新，关闭以前的BeanFactory（如果有），
     * 并为上下文生命周期的下一阶段初始化一个新的BeanFactory。
     */
    @Override
    protected final void refreshBeanFactory() throws BeansException {
        if (hasBeanFactory()) {
            //如果已经有容器，销毁容器中的bean，关闭容器 
            destroyBeans();
            closeBeanFactory();
        }
        try {
            //创建新的IoC容器也就是BeanFactory
            DefaultListableBeanFactory beanFactory = createBeanFactory();
            beanFactory.setSerializationId(getId());
            //对IoC容器进行定制化，如设置启动参数，开启注解的自动装配等 
            customizeBeanFactory(beanFactory);
            //调用载入Bean定义的方法，这里又使用了委派模式，在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器
            loadBeanDefinitions(beanFactory);
            synchronized (this.beanFactoryMonitor) {
                this.beanFactory = beanFactory;
            }
        }
        catch (IOException ex) {
            throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + getDisplayName(), ex);
        }
    }
    ……
    /**
     * 通常通过委托一个或多个bean definition readers将beande finition加载到给定的bean工厂中。
     * @param beanFactory 用于加载bean definitions的beanFactory
     * @throws BeansException 如果解析bean definitions失败
     * @throws IOException if 如果加载bean definitions文件失败
     */
    protected abstract void loadBeanDefinitions(DefaultListableBeanFactory beanFactory)
            throws BeansException, IOException;
    ……
}
</code></pre><blockquote>
<p>在这个方法中，先判断BeanFactory是否存在，如果存在则先销毁beans并关闭beanFactory，接着创建DefaultListableBeanFactory，并调用loadBeanDefinitions(beanFactory)装载bean定义。</p>
<h5 id="loadBeanDefinitions源码"><a href="#loadBeanDefinitions源码" class="headerlink" title="loadBeanDefinitions源码"></a>loadBeanDefinitions源码</h5><ul>
<li>AbstractRefreshableApplicationContext中只定义了抽象的loadBeanDefinitions()方法，容器真正调用的是其子类AbstractXmlApplicationContext对该方法的实现.</li>
</ul>
</blockquote>
<p>主要源码如下：</p>
<pre><code>public abstract class AbstractXmlApplicationContext extends AbstractRefreshableConfigApplicationContext {
    ……
    /**
     * 通过 XmlBeanDefinitionReader 加载 bean definitions.
     */
    @Override
    protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException {
        // 根据给定的BeanFactory创建一个新的XmlBeanDefinitionReader.
        XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory);

        // 根据上下文资源环境配置bean definition reader的环境.
        beanDefinitionReader.setEnvironment(this.getEnvironment());

        //为Bean读取器设置Spring资源加载器，AbstractXmlApplicationContext的  
        //祖先父类AbstractApplicationContext继承DefaultResourceLoader，因此，容器本身也是一个资源加载器 
        beanDefinitionReader.setResourceLoader(this);

        //为Bean读取器设置SAX xml解析器 
        beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this));

        // 允许子类提供reader的自定义初始化，然后继续实现加载bean definitions。
        initBeanDefinitionReader(beanDefinitionReader);

        //Bean读取器真正实现加载的方法
        loadBeanDefinitions(beanDefinitionReader);
    }
    ……
    /**
     * 使用给定的XmlBeanDefinitionReader加载bean definitions。
     * bean工厂的生命周期由#refreshBeanFactory方法处理; 因此这个方法只是加载和/或注册bean定义。
     * @param reader the XmlBeanDefinitionReader to use
     * @throws BeansException in case of bean registration errors
     * @throws IOException if the required XML document isn&apos;t found
     */
    protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException {
        //获取Bean定义资源的定位
        Resource[] configResources = getConfigResources();
        if (configResources != null) {
            //Xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位的Bean定义资源  
            reader.loadBeanDefinitions(configResources);
        }

        //如果子类中获取的Bean定义资源定位为空，则获取FileSystemXmlApplicationContext构造方法中setConfigLocations方法设置的资源
        String[] configLocations = getConfigLocations();
        if (configLocations != null) {
            //Xml Bean读取器调用其父类AbstractBeanDefinitionReader读取定位的Bean定义资源 
            reader.loadBeanDefinitions(configLocations);
        }
    }
    ……
    /**
     * 返回一个资源对象数组，引用这个上下文应该构建的XML bean定义文件。
     * 默认实现返回null。 子类可以覆盖此提供预先构建的资源对象而不是位置字符串。
     * 这里使用了委托模式，调用子类的获取Bean定义资源定位的方法，该方法在ClassPathXmlApplicationContext中进行实现，
     * FileSystemXmlApplicationContext中并没有实现
     * @return an array of Resource objects, or &lt;code&gt;null&lt;/code&gt; if none
     * @see #getConfigLocations()
     */
    protected Resource[] getConfigResources() {
        return null;
    }
    ……
}
</code></pre><blockquote>
<p>Xml Bean读取器(XmlBeanDefinitionReader)调用其父类AbstractBeanDefinitionReader的reader.loadBeanDefinitions方法读取Bean定义资源。</p>
</blockquote>
<p>ClassPathXmlApplicationContext中重写了getConfigResources()方法，返回configResources的属性的值。</p>
<pre><code>public class ClassPathXmlApplicationContext extends AbstractXmlApplicationContext {
    ……
    @Override
    protected Resource[] getConfigResources() {
        return this.configResources;
    }
    ……
}
</code></pre><p>然后根据情况判断是否执行reader.loadBeanDefinitions(configResources)分支，之后再获取getConfigLocations(),判断是否执行reader.loadBeanDefinitions(configLocations)分支。</p>
<h5 id="读取Bean定义资源"><a href="#读取Bean定义资源" class="headerlink" title="读取Bean定义资源"></a>读取Bean定义资源</h5><p>读取Bean定义资源的实际工作是在其抽象父类AbstractBeanDefinitionReader中定义的，主要源码：</p>
<pre><code>public abstract class AbstractBeanDefinitionReader implements EnvironmentCapable, BeanDefinitionReader {
    ……

    //重载方法，调用下面的loadBeanDefinitions(String, Set&lt;Resource&gt;);方法 
    public int loadBeanDefinitions(String location) throws BeanDefinitionStoreException {
        return loadBeanDefinitions(location, null);
    }

    /**
     * 从指定的资源位置加载bean定义。
     * 该位置也可以是一个location pattern，前提是该bean定义阅读器的ResourceLoader是ResourcePatternResolver。
     * @param location 要加载这个bean定义阅读器的ResourceLoader（或ResourcePatternResolver）
     * @param actualResources 要在加载过程中解析的实际资源对象填充的集合。可能是null来表示调用者对这些资源对象不感兴趣。
     * @return the number of bean definitions found
     * @throws BeanDefinitionStoreException in case of loading or parsing errors
     */
    public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException {
        //获取在IoC容器初始化过程中设置的资源加载器  
        ResourceLoader resourceLoader = getResourceLoader();
        if (resourceLoader == null) {
            throw new BeanDefinitionStoreException(
                    &quot;Cannot import bean definitions from location [&quot; + location + &quot;]: no ResourceLoader available&quot;);
        }

        if (resourceLoader instanceof ResourcePatternResolver) {
            // 可以用资源模式匹配.
            try {
                //将指定位置的Bean定义资源文件解析为Spring IoC容器封装的资源加载多个指定位置的Bean定义资源文件  
                Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location);
                //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能 
                int loadCount = loadBeanDefinitions(resources);
                if (actualResources != null) {
                    for (Resource resource : resources) {
                        actualResources.add(resource);
                    }
                }
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location pattern [&quot; + location + &quot;]&quot;);
                }
                return loadCount;
            }
            catch (IOException ex) {
                throw new BeanDefinitionStoreException(
                        &quot;Could not resolve bean definition resource pattern [&quot; + location + &quot;]&quot;, ex);
            }
        }
        else {
            //只能通过绝对URL加载单个资源。
            Resource resource = resourceLoader.getResource(location);
            //委派调用其子类XmlBeanDefinitionReader的方法，实现加载功能
            int loadCount = loadBeanDefinitions(resource);
            if (actualResources != null) {
                actualResources.add(resource);
            }
            if (logger.isDebugEnabled()) {
                logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location [&quot; + location + &quot;]&quot;);
            }
            return loadCount;
        }
    }

    //重载方法，调用loadBeanDefinitions(String); 
    public int loadBeanDefinitions(String... locations) throws BeanDefinitionStoreException {
        Assert.notNull(locations, &quot;Location array must not be null&quot;);
        int counter = 0;
        for (String location : locations) {
            counter += loadBeanDefinitions(location);
        }
        return counter;
    }
    ……
}
</code></pre><blockquote>
<p>loadBeanDefinitions(Resource…resources)方法和上面分析的3个方法类似，同样也是调用XmlBeanDefinitionReader的loadBeanDefinitions方法。从对AbstractBeanDefinitionReader的loadBeanDefinitions方法源码分析可以看出该方法做了以下两件事：</p>
<ul>
<li>调用资源加载器的获取资源方法resourceLoader.getResource(location)，获取到要加载的资源。</li>
<li>真正执行加载功能是其子类XmlBeanDefinitionReader的loadBeanDefinitions方法。</li>
</ul>
<p>通过ResourceLoader resourceLoader = getResourceLoader(); 和</p>
<p>Resource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location);</p>
<p>可以知道此时调用的是DefaultResourceLoader中的getSource()方法定位Resource</p>
</blockquote>
<h5 id="获取要读入的资源"><a href="#获取要读入的资源" class="headerlink" title="获取要读入的资源"></a>获取要读入的资源</h5><p>XmlBeanDefinitionReader通过调用其父类DefaultResourceLoader的getResource方法获取要加载的资源，其源码如下</p>
<pre><code>public class DefaultResourceLoader implements ResourceLoader {
    ……
    public Resource getResource(String location) {
        Assert.notNull(location, &quot;Location must not be null&quot;);
        //是不是classpath:，也就是相对路径
        if (location.startsWith(CLASSPATH_URL_PREFIX)) {
            return new ClassPathResource(location.substring(CLASSPATH_URL_PREFIX.length()), getClassLoader());
        }
        else {
            try {
                // 尝试将该位置解析为URL...
                URL url = new URL(location);
                return new UrlResource(url);
            }
            catch (MalformedURLException ex) {
                // 没有URL - &gt;解析为资源路径。
                return getResourceByPath(location);
            }
        }
    }
    ……
}
</code></pre><p>我们解析的 ClassPathXmlApplicationContext 符合location.startsWith(CLASSPATH_URL_PREFIX) 所以新建一个ClassPathResource返回，如果是FileSystemXmlApplicationContext的话，因为是绝对路径是应该是调用FileSystemXmlApplicationContext的getResourceByPath()方法返回Resource。</p>
<h5 id="加载Bean定义资源"><a href="#加载Bean定义资源" class="headerlink" title="加载Bean定义资源"></a>加载Bean定义资源</h5><p>Bean定义的Resource得到了，继续回到XmlBeanDefinitionReader的loadBeanDefinitions(Resource …)方法看到代表bean文件的资源定义以后的载入过程。</p>
<pre><code>public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader {
    /**
     * 从指定的XML文件加载bean定义。
     * @param resource the resource descriptor for the XML file
     * @return the number of bean definitions found
     * @throws BeanDefinitionStoreException in case of loading or parsing errors
     */
    public int loadBeanDefinitions(Resource resource) throws BeanDefinitionStoreException {
        //将读入的XML资源进行特殊编码处理 
        return loadBeanDefinitions(new EncodedResource(resource));
    }

    /**
     * 从指定的XML文件加载bean定义。
     * @param encodedResource  XML文件的资源描述符，允许指定用于解析文件的编码
     * @return the number of bean definitions found
     * @throws BeanDefinitionStoreException in case of loading or parsing errors
     */
    public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException {
        Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;);
        if (logger.isInfoEnabled()) {
            logger.info(&quot;Loading XML bean definitions from &quot; + encodedResource.getResource());
        }

        Set&lt;EncodedResource&gt; currentResources = this.resourcesCurrentlyBeingLoaded.get();
        if (currentResources == null) {
            currentResources = new HashSet&lt;EncodedResource&gt;(4);
            this.resourcesCurrentlyBeingLoaded.set(currentResources);
        }
        if (!currentResources.add(encodedResource)) {
            throw new BeanDefinitionStoreException(
                    &quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;);
        }
        try {
            //将资源文件转为InputStream的IO流 
            InputStream inputStream = encodedResource.getResource().getInputStream();
            try {
                //从InputStream中得到XML的解析源 
                InputSource inputSource = new InputSource(inputStream);
                if (encodedResource.getEncoding() != null) {
                    inputSource.setEncoding(encodedResource.getEncoding());
                }
                //这里是具体的读取过程  
                return doLoadBeanDefinitions(inputSource, encodedResource.getResource());
            }
            finally {
                //关闭从Resource中得到的IO流   
                inputStream.close();
            }
        }
        catch (IOException ex) {
            throw new BeanDefinitionStoreException(
                    &quot;IOException parsing XML document from &quot; + encodedResource.getResource(), ex);
        }
        finally {
            currentResources.remove(encodedResource);
            if (currentResources.isEmpty()) {
                this.resourcesCurrentlyBeingLoaded.remove();
            }
        }
    }
    /**
     * //从特定XML文件中实际载入Bean定义资源的方法 
     * @param inputSource the SAX InputSource to read from
     * @param resource the resource descriptor for the XML file
     * @return the number of bean definitions found
     * @throws BeanDefinitionStoreException in case of loading or parsing errors
     */
    protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource)
            throws BeanDefinitionStoreException {
        try {
            int validationMode = getValidationModeForResource(resource);
            //将XML文件转换为DOM对象，解析过程由documentLoader实现  
            Document doc = this.documentLoader.loadDocument(
                    inputSource, getEntityResolver(), this.errorHandler, validationMode, isNamespaceAware());
            //这里是启动对Bean定义解析的详细过程，该解析过程会用到Spring的Bean配置规则
            return registerBeanDefinitions(doc, resource);
        }
        ……
    }
}
</code></pre><blockquote>
<p>通过源码分析，载入Bean定义资源文件的最后一步是将Bean定义资源转换为Document对象，该过程由documentLoader实现</p>
</blockquote>
<h5 id="换为Document对象"><a href="#换为Document对象" class="headerlink" title="换为Document对象"></a>换为Document对象</h5><pre><code>public class DefaultDocumentLoader implements DocumentLoader {
    //使用标准的JAXP将载入的Bean定义资源转换成document对象
    public Document loadDocument(InputSource inputSource, EntityResolver entityResolver,
            ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception {
        //创建文件解析器工厂 
        DocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware);
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Using JAXP provider [&quot; + factory.getClass().getName() + &quot;]&quot;);
        }
        //创建文档解析器
        DocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler);
        //解析Spring的Bean定义资源
        return builder.parse(inputSource);
    }

    protected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware)
            throws ParserConfigurationException {
        //创建文档解析工厂 
        DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();
        factory.setNamespaceAware(namespaceAware);
        //设置解析XML的校验
        if (validationMode != XmlValidationModeDetector.VALIDATION_NONE) {
            factory.setValidating(true);
            if (validationMode == XmlValidationModeDetector.VALIDATION_XSD) {
                factory.setNamespaceAware(true);
                try {
                    factory.setAttribute(SCHEMA_LANGUAGE_ATTRIBUTE, XSD_SCHEMA_LANGUAGE);
                }
                catch (IllegalArgumentException ex) {
                    ParserConfigurationException pcex = new ParserConfigurationException(
                            &quot;Unable to validate using XSD: Your JAXP provider [&quot; + factory +
                            &quot;] does not support XML Schema. Are you running on Java 1.4 with Apache Crimson? &quot; +
                            &quot;Upgrade to Apache Xerces (or Java 1.5) for full XSD support.&quot;);
                    pcex.initCause(ex);
                    throw pcex;
                }
            }
        }
        return factory;
    }
}
</code></pre><blockquote>
<p>该解析过程调用JavaEE标准的JAXP标准进行处理。</p>
</blockquote>
<p>至此Spring IoC容器根据定位的Bean定义资源文件，将其加载读入并转换成为Document对象过程完成。</p>
<h5 id="解析Bean定义资源"><a href="#解析Bean定义资源" class="headerlink" title="解析Bean定义资源"></a>解析Bean定义资源</h5><p>XmlBeanDefinitionReader类中的doLoadBeanDefinitions方法是从特定XML文件中实际载入Bean定义资源的方法，该方法在载入Bean定义资源之后将其转换为Document对象，接下来调用registerBeanDefinitions启动Spring IoC容器对Bean定义的解析过程，registerBeanDefinitions方法源码如下：</p>
<pre><code>public class XmlBeanDefinitionReader extends AbstractBeanDefinitionReader {
    //按照Spring的Bean语义要求将Bean定义资源解析并转换为容器内部数据结构
    public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {
        //得到BeanDefinitionDocumentReader来对xml格式的BeanDefinition解析 
        BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();
        documentReader.setEnvironment(this.getEnvironment());
        //获得容器中注册的Bean数量
        int countBefore = getRegistry().getBeanDefinitionCount();

        //解析过程入口，这里使用了委派模式，BeanDefinitionDocumentReader只是个接口，
        //具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成  
        documentReader.registerBeanDefinitions(doc, createReaderContext(resource));
        //统计解析的Bean数量
        return getRegistry().getBeanDefinitionCount() - countBefore;
    }

    //创建BeanDefinitionDocumentReader对象，解析Document对象
    protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() {
        return BeanDefinitionDocumentReader.class.cast(BeanUtils.instantiateClass(this.documentReaderClass));
    }
}
</code></pre><blockquote>
<p>Bean定义资源的载入解析分为以下两个过程：</p>
<ul>
<li>通过调用XML解析器将Bean定义资源文件转换得到Document对象，但是这些Document对象并没有按照Spring的Bean规则进行解析。这一步是载入的过程</li>
<li>在完成通用的XML解析之后，按照Spring的Bean规则对Document对象进行解析。</li>
</ul>
</blockquote>
<h5 id="对Document解析"><a href="#对Document解析" class="headerlink" title="对Document解析"></a>对Document解析</h5><p>BeanDefinitionDocumentReader接口通过registerBeanDefinitions方法调用其实现类DefaultBeanDefinitionDocumentReader对Document对象进行解析，解析的代码如下：</p>
<pre><code>public class DefaultBeanDefinitionDocumentReader implements BeanDefinitionDocumentReader {
    public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) {
        this.readerContext = readerContext;

        logger.debug(&quot;Loading bean definitions&quot;);
        Element root = doc.getDocumentElement();

        doRegisterBeanDefinitions(root);
    }

    /**
     * 在给定的根{&lt;beans /&gt;元素中注册每个bean定义。
     */
    protected void doRegisterBeanDefinitions(Element root) {
        String profileSpec = root.getAttribute(PROFILE_ATTRIBUTE);
        if (StringUtils.hasText(profileSpec)) {
            Assert.state(this.environment != null, &quot;environment property must not be null&quot;);
            String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS);
            if (!this.environment.acceptsProfiles(specifiedProfiles)) {
                return;
            }
        }

        // 任何嵌套的&lt;beans&gt;元素将导致此方法中的递归。 
        // 为了正确地传播和保存&lt;beans&gt; default- *属性，请跟踪当前（父）委托，它可能为null。
        // 创建一个引用父（parent）的新的（子）代理，以便进行回退，然后最终将this.delegate重置为原始（父）引用。 
        // 这种行为模拟一堆代理，而不需要一个代理。
        BeanDefinitionParserDelegate parent = this.delegate;
        this.delegate = createHelper(readerContext, root, parent);

        preProcessXml(root);
        parseBeanDefinitions(root, this.delegate);
        postProcessXml(root);

        this.delegate = parent;
    }
    protected BeanDefinitionParserDelegate createHelper(XmlReaderContext readerContext, Element root, BeanDefinitionParserDelegate parentDelegate) {
        BeanDefinitionParserDelegate delegate = new BeanDefinitionParserDelegate(readerContext, environment);
        delegate.initDefaults(root, parentDelegate);
        return delegate;
    }

    protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) {
        if (delegate.isDefaultNamespace(root)) {
            NodeList nl = root.getChildNodes();
            for (int i = 0; i &lt; nl.getLength(); i++) {
                Node node = nl.item(i);
                if (node instanceof Element) {
                    Element ele = (Element) node;
                    if (delegate.isDefaultNamespace(ele)) {
                        parseDefaultElement(ele, delegate);
                    }
                    else {
                        delegate.parseCustomElement(ele);
                    }
                }
            }
        }
        else {
            delegate.parseCustomElement(root);
        }
    }

    private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) {
        if (delegate.nodeNameEquals(ele, IMPORT_ELEMENT)) {
            importBeanDefinitionResource(ele);
        } else if (delegate.nodeNameEquals(ele, ALIAS_ELEMENT)) {
            processAliasRegistration(ele);
        } else if (delegate.nodeNameEquals(ele, BEAN_ELEMENT)) {
            processBeanDefinition(ele, delegate);
        } else if (delegate.nodeNameEquals(ele, NESTED_BEANS_ELEMENT)) {
            // 递归
            doRegisterBeanDefinitions(ele);
        }
    }

    protected void importBeanDefinitionResource(Element ele) {
        String location = ele.getAttribute(RESOURCE_ATTRIBUTE);
        if (!StringUtils.hasText(location)) {
            getReaderContext().error(&quot;Resource location must not be empty&quot;, ele);
            return;
        }

        // 解决系统属性：例如“${user.dir}”
        location = environment.resolveRequiredPlaceholders(location);

        Set&lt;Resource&gt; actualResources = new LinkedHashSet&lt;Resource&gt;(4);

        // 发现位置是绝对的还是相对的URI
        boolean absoluteLocation = false;
        try {
            absoluteLocation = ResourcePatternUtils.isUrl(location) || ResourceUtils.toURI(location).isAbsolute();
        } catch (URISyntaxException ex) {
            // 不能转换为URI，考虑到位置相对，除非是众所周知的Spring前缀“classpath *：”
        }

        // 绝对还是相对？
        if (absoluteLocation) {
            try {
                int importCount = getReaderContext().getReader().loadBeanDefinitions(location, actualResources);
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Imported &quot; + importCount + &quot; bean definitions from URL location [&quot; + location + &quot;]&quot;);
                }
            } catch (BeanDefinitionStoreException ex) {
                getReaderContext().error(
                        &quot;Failed to import bean definitions from URL location [&quot; + location + &quot;]&quot;, ele, ex);
            }
        }
        else {
            // 没有URL - &gt;考虑相对于当前文件的资源位置。
            try {
                int importCount;
                Resource relativeResource = getReaderContext().getResource().createRelative(location);
                if (relativeResource.exists()) {
                    importCount = getReaderContext().getReader().loadBeanDefinitions(relativeResource);
                    actualResources.add(relativeResource);
                } else {
                    String baseLocation = getReaderContext().getResource().getURL().toString();
                    importCount = getReaderContext().getReader().loadBeanDefinitions(
                            StringUtils.applyRelativePath(baseLocation, location), actualResources);
                }
                if (logger.isDebugEnabled()) {
                    logger.debug(&quot;Imported &quot; + importCount + &quot; bean definitions from relative location [&quot; + location + &quot;]&quot;);
                }
            } catch (IOException ex) {
                getReaderContext().error(&quot;Failed to resolve current resource location&quot;, ele, ex);
            } catch (BeanDefinitionStoreException ex) {
                getReaderContext().error(&quot;Failed to import bean definitions from relative location [&quot; + location + &quot;]&quot;, ele, ex);
            }
        }
        Resource[] actResArray = actualResources.toArray(new Resource[actualResources.size()]);
        getReaderContext().fireImportProcessed(location, actResArray, extractSource(ele));
    }

    /**
     * 处理给定的别名元素，使用注册表注册别名。
     */
    protected void processAliasRegistration(Element ele) {
        String name = ele.getAttribute(NAME_ATTRIBUTE);
        String alias = ele.getAttribute(ALIAS_ATTRIBUTE);
        boolean valid = true;
        if (!StringUtils.hasText(name)) {
            getReaderContext().error(&quot;Name must not be empty&quot;, ele);
            valid = false;
        }
        if (!StringUtils.hasText(alias)) {
            getReaderContext().error(&quot;Alias must not be empty&quot;, ele);
            valid = false;
        }
        if (valid) {
            try {
                getReaderContext().getRegistry().registerAlias(name, alias);
            }
            catch (Exception ex) {
                getReaderContext().error(&quot;Failed to register alias &apos;&quot; + alias +
                        &quot;&apos; for bean with name &apos;&quot; + name + &quot;&apos;&quot;, ele, ex);
            }
            getReaderContext().fireAliasRegistered(name, alias, extractSource(ele));
        }
    }

    /**
     * 处理给定的bean元素，解析bean定义并将其注册到注册表。
     */
    protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) {
        BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele);
        if (bdHolder != null) {
            bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder);
            try {
                // 注册最终解析的实例.
                BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, getReaderContext().getRegistry());
            }
            catch (BeanDefinitionStoreException ex) {
                getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; +
                        bdHolder.getBeanName() + &quot;&apos;&quot;, ele, ex);
            }
            // 发送注册事件.
            getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder));
        }
    }

}
</code></pre><blockquote>
<p>通过上述Spring IoC容器对载入的Bean定义Document解析可以看出，我们使用Spring时，在Spring配置文件中可以使用<import>元素来导入IoC容器所需要的其他资源，Spring IoC容器在解析时会首先将指定导入的资源加载进容器中。使用<ailas>别名时，Spring IoC容器首先将别名元素所定义的别名注册到容器中。</ailas></import></p>
<p>对于既不是<import>元素，又不是<alias>元素的元素，即Spring配置文件中普通的<bean>元素的解析由BeanDefinitionParserDelegate类的parseBeanDefinitionElement方法来实现。</bean></alias></import></p>
</blockquote>
<h5 id="BeanDefinitionParserDelegate"><a href="#BeanDefinitionParserDelegate" class="headerlink" title="BeanDefinitionParserDelegate"></a>BeanDefinitionParserDelegate</h5><p>该类主要作用是用于解析XML定义的bean定义为BeanDefinition对象。</p>
<p>解析Bean定义资源文件中的<bean>元素的方法：</bean></p>
<pre><code>//解析&lt;Bean&gt;元素的入口  
public BeanDefinitionHolder parseBeanDefinitionElement(Element ele) {}
//解析Bean定义资源文件中的&lt;Bean&gt;元素，这个方法中主要处理&lt;Bean&gt;元素的id，name 和别名属性  
public BeanDefinitionHolder parseBeanDefinitionElement(Element ele, BeanDefinition containingBean) { }
//详细对&lt;Bean&gt;元素中配置的Bean定义其他属性进行解析，由于上面的方法中已经对
//Bean的id、name和别名等属性进行了处理，该方法中主要处理除这三个以外的其他属性数据  
public AbstractBeanDefinition parseBeanDefinitionElement(Element ele, String beanName, BeanDefinition containingBean) { }
</code></pre><p>解析<property>元素的方法：</property></p>
<pre><code>//解析&lt;Bean&gt;元素中的&lt;property&gt;子元素  
public void parsePropertyElements(Element beanEle, BeanDefinition bd) {}
//解析&lt;property&gt;元素  
public void parsePropertyElement(Element ele, BeanDefinition bd) {}
//解析获取property值  
public Object parsePropertyValue(Element ele, BeanDefinition bd, String propertyName) { } 
</code></pre><p>解析<property>元素的子元素的方法：</property></p>
<pre><code>//解析&lt;property&gt;元素中ref,value或者集合等子元素  
public Object parsePropertySubElement(Element ele, BeanDefinition bd, String defaultValueType) {}
</code></pre><p>解析<list>子元素的方法：</list></p>
<pre><code>//解析&lt;list&gt;集合子元素  
public List parseListElement(Element collectionEle, BeanDefinition bd) {}
 //具体解析&lt;list&gt;集合元素，&lt;array&gt;、&lt;list&gt;和&lt;set&gt;都使用该方法解析  
protected void parseCollectionElements(
        NodeList elementNodes, Collection&lt;Object&gt; target, BeanDefinition bd, String defaultElementType) {} 
</code></pre><p>经过对Spring Bean定义资源文件转换的Document对象中的元素解析，Spring IoC现在已经将XML形式定义的Bean定义资源文件转换为BeanDefinition，它是Bean定义资源文件中配置的POJO对象在Spring IoC容器中的映射，我们可以通过AbstractBeanDefinition为入口，对IoC容器进行索引、查询和操作。</p>
<p>通过Spring IoC容器对Bean定义资源的解析后，IoC容器大致完成了管理Bean对象的初始化过程，接下来需要向容器注册Bean定义信息才能全部完成IoC容器的初始化过程</p>
<h5 id="IoC容器中的注册"><a href="#IoC容器中的注册" class="headerlink" title="IoC容器中的注册"></a>IoC容器中的注册</h5><p>DefaultBeanDefinitionDocumentReader对Bean定义转换的Document对象解析的结果中最后调用processBeanDefinition()方法，其中就有调用BeanDefinitionReaderUtils的registerBeanDefinition方法向IoC容器注册解析的Bean，BeanDefinitionReaderUtils的注册的源码如下：</p>
<pre><code>//将解析的BeanDefinitionHold注册到容器中 
public static void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)  
throws BeanDefinitionStoreException {  
    //获取解析的BeanDefinition的名称
     String beanName = definitionHolder.getBeanName();  
    //向IoC容器注册BeanDefinition 
    registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());  
    //如果解析的BeanDefinition有别名，向容器为其注册别名  
     String[] aliases = definitionHolder.getAliases();  
    if (aliases != null) {  
        for (String aliase : aliases) {  
            registry.registerAlias(beanName, aliase);  
        }  
    }  
}
</code></pre><p>当调用BeanDefinitionReaderUtils向IoC容器注册解析的BeanDefinition时，真正完成注册功能的是DefaultListableBeanFactory。</p>
<h5 id="注册解析后的BeanDefinition"><a href="#注册解析后的BeanDefinition" class="headerlink" title="注册解析后的BeanDefinition"></a>注册解析后的BeanDefinition</h5><p>DefaultListableBeanFactory中使用一个HashMap的集合对象存放IoC容器中注册解析的BeanDefinition，向IoC容器注册的主要源码如下：</p>
<pre><code>//存储注册的俄BeanDefinition  
private final Map&lt;String, BeanDefinition&gt; beanDefinitionMap = new ConcurrentHashMap&lt;String, BeanDefinition&gt;();  
//向IoC容器注册解析的BeanDefiniton  
public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition)  
       throws BeanDefinitionStoreException {  
   Assert.hasText(beanName, &quot;Bean name must not be empty&quot;);  
   Assert.notNull(beanDefinition, &quot;BeanDefinition must not be null&quot;);  
   //校验解析的BeanDefiniton  
   if (beanDefinition instanceof AbstractBeanDefinition) {  
       try {  
           ((AbstractBeanDefinition) beanDefinition).validate();  
       }  
       catch (BeanDefinitionValidationException ex) {  
           throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,  
                   &quot;Validation of bean definition failed&quot;, ex);  
       }  
   }  
   //注册的过程中需要线程同步，以保证数据的一致性  
   synchronized (this.beanDefinitionMap) {  
       Object oldBeanDefinition = this.beanDefinitionMap.get(beanName);  
       //检查是否有同名的BeanDefinition已经在IoC容器中注册，如果已经注册，  
       //并且不允许覆盖已注册的Bean，则抛出注册失败异常  
       if (oldBeanDefinition != null) {  
           if (!this.allowBeanDefinitionOverriding) {  
               throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName,  
                       &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean &apos;&quot; + beanName +  
                       &quot;&apos;: There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;);  
           }  
           else {//如果允许覆盖，则同名的Bean，后注册的覆盖先注册的  
               if (this.logger.isInfoEnabled()) {  
                   this.logger.info(&quot;Overriding bean definition for bean &apos;&quot; + beanName +  
                           &quot;&apos;: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;);  
               }  
           }  
       }  
       //IoC容器中没有已经注册同名的Bean，按正常注册流程注册  
       else {  
           this.beanDefinitionNames.add(beanName);  
           this.frozenBeanDefinitionNames = null;  
       }  
       this.beanDefinitionMap.put(beanName, beanDefinition);  
       //重置所有已经注册过的BeanDefinition的缓存  
       resetBeanDefinition(beanName);  
   }  
}
</code></pre><p>至此，Bean定义资源文件中配置的Bean被解析并且注册到IoC容器中。现在IoC容器中已经存在了所有Bean的配置信息，这些BeanDefinition信息已经可以使用，并且可以被检索，IoC容器的作用就是对这些注册的Bean定义信息进行处理和维护。因为IOC容器持有这些BeanDefinition信息，所以可以根据描述进行bean的注入。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现在通过上面的代码，总结一下IOC容器初始化的基本步骤：</p>
<ul>
<li><p>初始化的入口在容器实现中的 refresh()调用来完成</p>
</li>
<li><p>对 bean 定义载入 IOC 容器使用的方法是 loadBeanDefinition,</p>
<blockquote>
<p>其中的大致过程如下：</p>
<p>通过 ResourceLoader 来完成资源文件位置的定位，DefaultResourceLoader 是默认的实现，同时上下文本身就给出了 ResourceLoader 的实现，可以从类路径，文件系统, URL 等方式来定为资源位置;</p>
<p>如果是 XmlBeanFactory作为 IOC 容器，那么需要为它指定 bean 定义的资源，也就是说 bean 定义文件时通过抽象成 Resource 来被 IOC 容器处理的;</p>
<p>容器通过 BeanDefinitionReader来完成定义信息的解析和 Bean 信息的注册,往往使用的是XmlBeanDefinitionReader 来解析 bean 的 xml 定义文件 (实际的处理过程是委托给 BeanDefinitionParserDelegate 来完成的)，从而得到 bean 的定义信息;</p>
<p>这些信息在 Spring 中使用 BeanDefinition 对象来表示( 这个名字可以让我们想到loadBeanDefinition,RegisterBeanDefinition  这些相关的方法 ) 他们都是为处理 BeanDefinitin 服务的， </p>
<p>容器解析得到 BeanDefinitionIoC 以后，需要把它在 IOC 容器中注册，这由 IOC 实现 BeanDefinitionRegistry 接口来实现。</p>
<p>注册过程就是在 IOC 容器内部维护的一个HashMap 来保存得到的 BeanDefinition 的过程。这个 HashMap 是 IoC 容器持有 bean 信息的场所，以后对 bean 的操作都是围绕这个HashMap 来实现的.</p>
</blockquote>
</li>
</ul>
<hr>
<blockquote>
<p>在使用 Spring IOC 容器的时候我们还需要区别两个概念:Beanfactory 和 Factory bean，</p>
<ul>
<li>BeanFactory 指的是 IOC 容器的编程抽象，比如 ApplicationContext， XmlBeanFactory 等，这些都是 IOC 容器的具体表现，需要使用什么样的容器由客户决定,但 Spring 为我们提供了丰富的选择。 </li>
<li>FactoryBean 只是一个可以在 IOC而容器中被管理的一个 bean,是对各种处理过程和资源使用的抽象,Factory bean 在需要时产生另一个对象，而不返回 FactoryBean本身,我们可以把它看成是一个抽象工厂，对它的调用返回的是工厂生产的产品。所有的 Factory bean 都实现特殊的org.springframework.beans.factory.FactoryBean 接口，当使用容器中 factory bean 的时候，返回其生成的对象。</li>
</ul>
</blockquote>
]]></content>
    
    <summary type="html">
    
      spring几大核心组件中有一个就是IOC(Inversion of Control)，那么什么是IOC呢？它的原理是什么？它对我们的编程有什么影响?我们应该怎么样使用？下面我们就来分析分析
    
    </summary>
    
      <category term="spring" scheme="http://gamesdoa.com/categories/spring/"/>
    
    
      <category term="spring" scheme="http://gamesdoa.com/tags/spring/"/>
    
      <category term="ioc" scheme="http://gamesdoa.com/tags/ioc/"/>
    
  </entry>
  
  <entry>
    <title>高并发系统优化</title>
    <link href="http://gamesdoa.com/highly-concurrent.html"/>
    <id>http://gamesdoa.com/highly-concurrent.html</id>
    <published>2017-07-19T16:00:00.000Z</published>
    <updated>2017-08-22T04:31:24.999Z</updated>
    
    <content type="html"><![CDATA[<p>现在社会尤其是电商互联网促销方式的出现，造成的网站面临着并发量越来越大的问题，对于这个状况如果解决不好将严重影响系统的响应速度，严重的情况下可能会造成服务器宕机等极其恶劣的影响，那么该如何解决或者说优化这个问题呢？根据实际工作中涉及到的方方面面，大体可以归结为以下几点：</p>
<h3 id="应用和静态资源分离"><a href="#应用和静态资源分离" class="headerlink" title="应用和静态资源分离"></a>应用和静态资源分离</h3><p>刚开始的时候应用和静态资源是保存在一起的，当并发量达到一定程度时就需要将静态资源保存到专门的服务器中，静态资源主要包括图片、视频、js、css和一些资源文件等，这些文件因为没有状态，所以分离比较简单，直接存放到相应的服务器就可以了，一般会使用专门的域名去访问，比如，京东的图片保存在img**.jd.com二级域名服务器上，通过不同的域名可以让浏览器直接访问资源服务器而不需要再访问应用服务器了。</p>
<p>对于js、css和一些资源文件，可以直接放在资源服务器上，但是对于图片这种最常见的做法是建立单独的图片服务器，会使用到类似HDFS这种技术的分布式文件存储，同时一般会提供多个不同的域名，这些不同的域名都可以访问到相同的图片信息，这样的好处是：如果一个页面有很多图片的时候，对于一个域名的并发访问时有限制的，如果只是一个域名，那么加载图片就会出现排队加载的情况，提供多个域名，并发量就上去了，加载页面速度也就提供高了。</p>
<h3 id="页面缓存"><a href="#页面缓存" class="headerlink" title="页面缓存"></a>页面缓存</h3><p>顾名思义页面缓存就是把内容缓存在客户端cookie的作法，这种技术一般是对于不经常发生数据变化的页面，技术实现比较简单就是在HTML的头部加入以下代码</p>
<pre><code>&lt;HEAD&gt; 
    &lt;META HTTP-EQUIV=&quot;Pragma&quot; CONTENT=&quot;no-cache&quot;&gt; 
    &lt;META HTTP-EQUIV=&quot;Cache-Control&quot; CONTENT=&quot;no-cache&quot;&gt; 
    &lt;META HTTP-EQUIV=&quot;Expires&quot; CONTENT=&quot;0&quot;&gt; 
&lt;/HEAD&gt;
</code></pre><blockquote>
<p>说明：HTTP头信息“Expires”和“Cache-Control”为应用程序服务器提供了一个控制浏览器和代理服务器上缓存的机制。HTTP头信息Expires告诉代理服务器它的缓存页面何时将过期。HTTP1.1规范中新定义的头信息Cache-Control可以通知浏览器不缓存任何页面。当点击后退按钮时，浏览器重新访问服务器已获取页面。</p>
<p>Cache-Control的常用的参数：</p>
<ul>
<li>no-cache，浏览器和缓存服务器都不应该缓存页面信息；</li>
<li>public，浏览器和缓存服务器都可以缓存页面信息；</li>
<li>no-store，请求和响应的信息都不应该被存储在对方的磁盘系统中；</li>
<li>must-revalidate，对于客户机的每次请求，代理服务器必须想服务器验证缓存是否过时；</li>
</ul>
<p>Last-Modified 指页面的最后生成时间，GMT格式；</p>
<p>expires 过期时限值，GMT格式，指浏览器或缓存服务器在该时间点后必须从服务器中获取新的页面信息；</p>
<p>上面两个值在JSP中设置值为字符型的GMT格式，无法生效，设置long类型才生效；</p>
</blockquote>
<h3 id="集群与分布式"><a href="#集群与分布式" class="headerlink" title="集群与分布式"></a>集群与分布式</h3><p>什么是集群什么是分布式？简单的说就是：</p>
<p>集群：同一个业务，部署在多个服务器上，同时对外提供服务，可以形成容灾以及提供并发支持数等</p>
<p>分布式：一个业务分拆多个子业务，部署在不同的服务器上，不同业务之间相互独立，减少不必要的影响，提高响应，对于某个子业务挂掉的情况下不影响其他的子业务的运行。</p>
<p>一般在大型网站的生产环境，这两种技术是同时应用的，业务在拆分成多个子业务的前提下，再把每个子业务部署到集群环境中去。现在比较大型的公司基本上都是使用云技术，在物理机上搭建许多docker服务器提供云服务，很方便应用的扩容和缩容。</p>
<h3 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h3><p>基本上的思路呢就是服务器端的负载均衡器，客户端只能感知到代理服务器而不会知道具体是哪个服务器提供的处理。<br><img src="https://github.com/gamesdoa/img0/raw/master/optimization/reverse-proxy.jpg" alt="反向代理"></p>
<p>反向代理的实现</p>
<ol>
<li>需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上</li>
<li>服务器返回服务处理之后的结果到负载均衡设备</li>
<li>负载均衡将服务器的服务返回用户<blockquote>
<p>通俗的说用户和负载均衡设备直接通信，也意味着用户做服务器域名解析时，解析得到的IP其实是负载均衡的IP，而不是服务器的IP，这样有一个好处是，当新加入/移走服务器时，仅仅需要修改负载均衡的服务器列表，而不会影响现有的服务。</p>
</blockquote>
</li>
</ol>
<h3 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h3><p>CDN的全称是Content Delivery Network，即<strong>内容分发网络</strong>。</p>
<p>其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。</p>
<h4 id="关键技术"><a href="#关键技术" class="headerlink" title="关键技术"></a>关键技术</h4><ul>
<li>内容发布：它借助于建立索引、缓存、流分裂、组播（Multicast）等技术，将内容发布或投递到距离用户最近的远程服务点（POP）处；</li>
<li>内容路由：它是整体性的网络负载均衡技术，通过内容路由器中的重定向（DNS）机制，在多个远程POP上均衡用户的请求，以使用户请求得到最近内容源的响应；</li>
<li>内容交换：它根据内容的可用性、服务器的可用性以及用户的背景，在POP的缓存服务器上，利用应用层交换、流分裂、重定向（ICP、WCCP）等技术，智能地平衡负载流量；</li>
<li>性能管理：它通过内部和外部监控系统，获取网络部件的状况信息，测量内容发布的端到端性能（如包丢失、延时、平均带宽、启动时间、帧速率等），保证网络处于最佳的运行状态。</li>
</ul>
<h4 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h4><ol>
<li>本地Cache加速 提高了企业站点(尤其含有大量图片和静态页面站点)的访问速度，并大大提高以上性质站点的稳定性</li>
<li>镜像服务 消除了不同运营商之间互联的瓶颈造成的影响，实现了跨运营商的网络加速，保证不同网络中的用户都能得到良好的访问质量。</li>
<li>远程加速 远程访问用户根据DNS负载均衡技术智能自动选择Cache服务器，选择最快的Cache服务器，加快远程访问的速度</li>
<li>带宽优化 自动生成服务器的远程Mirror（镜像）cache服务器，远程用户访问时从cache服务器上读取数据，减少远程访问的带宽、分担网络流量、减轻原站点WEB服务器负载等功能。</li>
<li>集群抗攻击 广泛分布的CDN节点加上节点之间的智能冗余机制，可以有效地预防黑客入侵以及降低各种D.D.o.S攻击对网站的影响，同时保证较好的服务质量 。</li>
</ol>
<h3 id="算法优化"><a href="#算法优化" class="headerlink" title="算法优化"></a>算法优化</h3><p>算法优化是性能局部优化的首先，常采用各种性能软件来度量CPU时间，内存占用，函数调用次数等以定位问题，然后根据具体情况采用不同的调优方法进行调优，比如利用空间换时间，或者使用合理的数据结构。</p>
<blockquote>
<p>例如对于比较大的多层循环，可以做成多个map，将多层循环转换成单重循环。</p>
</blockquote>
<p>算法优化也有不足点：只能够帮助消除一些明显的编程细节引起的瓶颈，如果想只是用算法优化完全解决性能问题基本上是不可能的，而且还具有非常大的难度。</p>
<h3 id="软件优化"><a href="#软件优化" class="headerlink" title="软件优化"></a>软件优化</h3><ul>
<li>合理的操作系统优化</li>
<li>数据库优化</li>
<li>中间件技术</li>
<li>本地缓存</li>
<li>分布式缓存</li>
</ul>
<h3 id="硬件优化"><a href="#硬件优化" class="headerlink" title="硬件优化"></a>硬件优化</h3><ul>
<li>更快的CPU</li>
<li>加内存减少分页</li>
<li>更快的网络IO设备（光纤以及专线加带宽，使用万兆千兆网卡代替千兆百兆网卡）</li>
<li>更快的本地IO设备（内存替代硬盘，SSD替代机械硬盘）</li>
<li>快速计算资源代替慢速计算资源（快速存储代替慢速存储）</li>
<li>本地计算换网络传输的优化（采用压缩内容的优化方式）</li>
</ul>
<h3 id="算法与资源之间的交互"><a href="#算法与资源之间的交互" class="headerlink" title="算法与资源之间的交互"></a>算法与资源之间的交互</h3><ul>
<li><p>减少单台服务器的处理量（分而治之）</p>
<blockquote>
<p>把大应用按业务分成独立的互相合作的系统，如：高层采用SOA，底层采用数据库分库分表</p>
<p>web服务器、应用服务器、数据库服务器、文件服务器，独立搭建部署</p>
<p>采用读写分离，快慢服务分离</p>
<p>数据库分库分表</p>
</blockquote>
</li>
<li><p>充分利用系统资源</p>
<blockquote>
<p>采用多进程、多线程、异步操作以及负载均衡等手段<br>负载均衡主要是防止某台服务器过满或过闲</p>
</blockquote>
</li>
<li><p>减少不必要的计算次数</p>
<blockquote>
<p>缓存计算结果，尤其服务器端缓存，以减少不必要的计算</p>
</blockquote>
</li>
<li><p>减少不惜要的IO次数</p>
<blockquote>
<p>网络IO次数：客户端缓存，CDN缓存，合并资源以减少请求次数</p>
<p>磁盘IO次数：缓存常用数据，如利用redis、memcached进行缓存</p>
</blockquote>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      对于高并发系统怎么样才能把系统优化的更好？响应时间更短？速度更快？总结一些工作中的经验来看一下。
    
    </summary>
    
      <category term="优化" scheme="http://gamesdoa.com/categories/%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="优化" scheme="http://gamesdoa.com/tags/%E4%BC%98%E5%8C%96/"/>
    
      <category term="高并发" scheme="http://gamesdoa.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>海量数据系统优化</title>
    <link href="http://gamesdoa.com/big-data-optimization.html"/>
    <id>http://gamesdoa.com/big-data-optimization.html</id>
    <published>2017-07-14T16:00:00.000Z</published>
    <updated>2017-08-09T10:19:43.198Z</updated>
    
    <content type="html"><![CDATA[<h2 id="海量数据优化"><a href="#海量数据优化" class="headerlink" title="海量数据优化"></a>海量数据优化</h2><p>现在社会尤其是互联网方面的蓬勃发展，造成的网站面临着数据量越来越大的问题，对于这个状况如果解决不好将严重影响系统的运行速度，那么该如何解决或者说优化这个问题呢？根据实际工作中涉及到的方方面面，大体可以归结为以下几点：</p>
<h3 id="页面静态化"><a href="#页面静态化" class="headerlink" title="页面静态化"></a>页面静态化</h3><p>页面静态化是将程序最后生成的页面保存起来，使用页面静态化后就不需要每次请求都重新生成页面了，这样不但不需要查询持久化存储，而且连应用程序处理都不需要，所以页面静态化同时对数据量大和并发量高两大问题都有好处。页面静态化可以在程序中使用模板技术生成，如常用的Velocity都可以根据模板生成静态页面，另外也可以使用缓存服务器在应用服务器的上一层缓存生成的页面，如可以使用varnish或者squid，另外Nginx也提供了相应的功能。</p>
<h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><p>缓存就是将从持久化存储中获取的数据暂时保存起来，在下次使用的时候无需重新到持久化存储中获取而直接使用，这样可以大大降低持久化存储的压力。</p>
<p>缓存的使用一般可以分为以下两种</p>
<ul>
<li>直接保存在程序内存中<blockquote>
<p>程序直接操作主要是使用Map数据集合，尤其是ConcurrentHashMap线程安全的集合，在不需要强一致性的环境中也可以使用HashMap，毕竟ConcurrentHashMap需要同步处理，即便再轻量级的锁，还是会有额外开销，造成性能消耗。</p>
</blockquote>
</li>
<li>使用缓存框架<blockquote>
<p>Memcache和Redis是目前比较成熟的缓存框架，也是很多大型网站会用到的缓存框架，对于Memcache和Redis两者的主要区别</p>
<p>Redis的作者Salvatore Sanfilippo曾经对这两种基于内存的数据存储系统进行过比较：</p>
<ul>
<li><strong>Redis支持服务器端的数据操作</strong>：Redis相比Memcached来说，拥有更多的数据结构和并支持更丰富的数据操作，通常在Memcached里，你需要将数据拿到客户端来进行类似的修改再set回去。这大大增加了网络IO的次数和数据体积。在Redis中，这些复杂的操作通常和一般的GET/SET一样高效。所以，如果需要缓存能够支持更复杂的结构和操作，那么Redis会是不错的选择。</li>
<li><strong>内存使用效率对比</strong>：使用简单的key-value存储的话，Memcached的内存利用率更高，而如果Redis采用hash结构来做key-value存储，由于其组合式的压缩，其内存利用率会高于Memcached。</li>
<li><strong>性能对比</strong>：由于Redis只使用单核，而Memcached可以使用多核，所以平均每一个核上Redis在存储小数据时比Memcached性能更高。而在100k以上的数据中，Memcached性能要高于Redis，虽然Redis最近也在存储大数据的性能上进行优化，但是比起Memcached，还是稍有逊色。</li>
</ul>
</blockquote>
</li>
</ul>
<p>缓存使用过程中最重要问题是什么时候创建或者更新获取，又或者缓存什么时候失效？对于这个问题：一般情况下有以下两种做法：</p>
<ul>
<li>在程序获取数据的时候，如果缓存中不存在，则到持久化缓存中获取数据并创建缓存。<blockquote>
<p>针对程序读取并创建缓存的情况，需要注意针对空值的处理，一般情况下空值也会存储一个缓存记录，防止出现无限查询持久化缓存的问题。同时针对这种情况，可能会造成数据的非实时一致，对于强一致性的地方不适合使用该方法。 </p>
</blockquote>
</li>
<li>在数据创建时，存储到持久化缓存之后，同步创建缓存。<blockquote>
<p>这种做法一般是针对几乎不变化的数据，同时数据是由管理台创建出来的情况。同时针对这个情况，数据一般会以缓存数据为主，这种情况下程序处理过程中一般不会查询持久化存储更新缓存数据，程序在缓存中如果没有获取到数据默认就认为没有相应数据。</p>
</blockquote>
</li>
</ul>
<p>一般针对缓存都会设置一个过期时间，这样的好处是数据过期之后就可以再次获取最新的数据继续缓存，相当于变相的更新缓存数据。</p>
<h3 id="数据库优化"><a href="#数据库优化" class="headerlink" title="数据库优化"></a>数据库优化</h3><p>数据库优化主要的目的是在不增加硬件的情况下提高处理效率。数据库优化的方法非常多，常用的手段有表结构优化、SQL语句优化、分区、分表、索引优化、分库。</p>
<h4 id="表结构优化"><a href="#表结构优化" class="headerlink" title="表结构优化"></a>表结构优化</h4><p>表结构设计的合理与否直接影响到性能，因为表结构是数据存储的基础。</p>
<p>一般没有固定的表结构设计，只能说那种设计更适合，虽然之前教科书上说表结构要满足第三范式，然而在实际使用中并没有什么鸟用，在表设计的时候往往会<strong>故意引入冗余</strong>，或者需要<strong>把一张表拆分成多张表处理冷热字段数据</strong>，不过这些情况都要根据实际进行设计，或许你能让表结构满足第三范式，但是小生在实际工作中很少能见到满足第三范式的表设计。</p>
<h4 id="SQL语句优化"><a href="#SQL语句优化" class="headerlink" title="SQL语句优化"></a>SQL语句优化</h4><p>SQL语句优化是查询数据优化中很重要的一部分，一般情况下SQL语句优化需要和索引优化配合使用，不过SQL优化一般都是可以从数据量上过滤方面下手，比如同一个语句你可以先过滤出少量的数据肯定比在大量数据中处理要速度快的多，在优化SQL的过程中一般可以使用explain查看语句执行花费来做为优化依据。对于查询sql来说还有一点，不要广泛的使用Select * 而是需要什么数据就查询什么数据，一个是可以使用到索引覆盖，另外就是会减少网络带宽占用。</p>
<h4 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h4><p>索引优化一般是根据对表的查询操作的所有SQL的整合，结合数据库存储引擎的原理，来设计优化索引，比如如果存储引擎使用了B+Tree方式存储数据，那么你的索引创建时就要遵循最左前缀，再比如如果你的存储引擎是聚族索引以及非聚族索引方式组织数据的，就要考虑索引能否覆盖等一系列的优化方案？</p>
<p>在索引优化的时候，同样需要尽量少的创建索引，并且能创建联合索引的情况下尽量创建联合索引而不是创建多个单列索引，因为索引在提高查询效率的情况下，会降低增删改的速度，因为每次数据改变的情况下，都需要更新索引信息。</p>
<h4 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h4><p>在支持分区的数据库引擎中，在数据量不断变大的情况下，如果可以使用分区存储数据的话无疑是很好的。</p>
<p>分区是将一张表的数据按照一定的规则分别存储到不同的区中保存，这样在查询数据的时候，按照分区的规则查询数据就可以直接定位到数据所在分区，只查询该分区上的数据，毕竟数据量才是造成效率下降的“罪魁祸首”，如果查询的数据范围小了，性能也就提高了。</p>
<p>分区还有一个好处就是对程序透明，不需要程序不需要做任何改动，唯一要求就是需要数据库存储引擎需要支持分区。</p>
<h4 id="分表"><a href="#分表" class="headerlink" title="分表"></a>分表</h4><p>分表一般是对于数据量对于分区之后还是显的数据较大的表，把原有的一张表拆分成多张表结构一样的表，然后按照某种路由规则，把数据平均的分散到各个表中。这样的好处就是分而治之，对于一张表的数据只是原有数据的一小部分，再表内还可以再分区，就可以极大的增加数据的数量级。</p>
<p>分表需要注意的一个很大的问题就是唯一主键的问题，因为数据将会被存储到多个表中，表中的主键就不能使用原来的自增主键这种简单的方式处理，很多时候会是使用主键生成器来实现主键的唯一性，主语主键生成器的设计思路，小生会单独开一篇博文介绍。</p>
<p>对于分表之后的查询，需要程序内做修改，需要指定每条记录的路由到哪个表上查询数据。</p>
<h4 id="分库"><a href="#分库" class="headerlink" title="分库"></a>分库</h4><p>对于更大级别的数据量来说，单单的分表页不能满足查询的性能需求了，这时候就需要分表了，把一个表分成多个库的多个表，以便承受更大的数据压力，这样的好处就是在查询时针对不同的数据查询的库都不一致，提高数据存储级别的同时增加了查询性能。</p>
<p>分库还有一种说法是不用的模块分到不同的库中，这是应用的水平拆分，可以提高查询性能，分摊数据库服务器的压力。</p>
<h3 id="分离活跃数据"><a href="#分离活跃数据" class="headerlink" title="分离活跃数据"></a>分离活跃数据</h3><p>有些应用虽然数据量很大，但是其中的活跃数据很少，对于这种类型的应用可以分离出来活跃数据，单独存储，而非活跃数据存储在另外一个表中。比如一个大型的论坛，注册用户很多，但是真正活跃登录用户只占很少一部分，这时候就可以把活跃用户单独存储在一个表，这种设计就要求程序要处理非活跃用户到活跃用户，以及清理活跃用户中的非活跃用户信息。</p>
<h3 id="延迟修改"><a href="#延迟修改" class="headerlink" title="延迟修改"></a>延迟修改</h3><p>这种一般是针对非关键性数据，并且修改极其频繁的情况，比如记录用户的pv，uv等信息，可以先记录缓存，然后隔一段时间去持久化一次数据，而不是每次数据变化就直接持久化数据。</p>
<h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>读写分离的本质是对数据库进行集群，这样就可以在高并发的情况下将数据库的操作分配到多个数据库服务器去处理从而降低单台服务器的压力，对于数据库数据的一致性一般采用主备技术实现，而且都是一主多备，主服务器负责数据写入，备服务器负责数据读取。<br>这种技术的核心问题是数据一致性，也就是主备之间的数据同步问题，避免多点写的情况出现，所以一般就是采用一主多备架构，而且数据的同步可以使用各个数据库的备份技术实现，对于远地备份数据情况，最好是写专门的程序处理。</p>
<h3 id="NoSQL-和-Hadoop"><a href="#NoSQL-和-Hadoop" class="headerlink" title="NoSQL 和 Hadoop"></a>NoSQL 和 Hadoop</h3><p>NoSQL的核心就是非结构化，在使用时不需要先将表的结构定义出来，可以非常灵活地进行操作，另外因为NoSQL通过多个块存储数据的特点，其操作大数据的速度也非常快，这其中最具代表性的就是BigTable和Hadoop。</p>
<p>Hadoop是根据BigTable论文开发的开源版本，专门针对大数据处理的一套框架，Hadoop对数据的存储和处理都提供了相应的解决方案，底层数据的存储思路类是分布式加集群的方案，不过Hadoop是将同一个表中的数据分成多块保存到多个节点（分布式），而且每一块数据都有多个节点保存（集群），这里集群除了可以并行处理相同的数据，还可以保证数据的稳定性，在其中一个节点出现问题后数据不会丢失。这里的每个节点都不包含一个完整的表的数据，但是一个节点可以保存多个表的数据。</p>
<p>Hadoop对数据的处理是先对每一块的数据找到相应的节点并进行处理，然后再对每一个处理的结果进行处理，最后生成最终的结果。比如，要查找符合条件的记录，Hadoop的处理方式是先找到每一块中符合条件的记录，然后再将所有获取到的结果合并到一起，这样就可以将同一个查询分到多个服务器处理，处理的速度也就快了，这一点传统的数据库是做不到的。</p>
]]></content>
    
    <summary type="html">
    
      对于海量数据的系统怎么样才能是系统更优？总结一些工作中的经验来看一下。
    
    </summary>
    
      <category term="优化" scheme="http://gamesdoa.com/categories/%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="大数据优化" scheme="http://gamesdoa.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BC%98%E5%8C%96/"/>
    
      <category term="优化" scheme="http://gamesdoa.com/tags/%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>springMVC 请求处理流程</title>
    <link href="http://gamesdoa.com/springmvc-request.html"/>
    <id>http://gamesdoa.com/springmvc-request.html</id>
    <published>2017-07-09T16:00:00.000Z</published>
    <updated>2017-08-09T06:49:48.392Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先看一个很low的简图"><a href="#首先看一个很low的简图" class="headerlink" title="首先看一个很low的简图"></a>首先看一个很low的简图</h2><p><img src="https://github.com/gamesdoa/img0/raw/master/spring/springmvc-request.jpg" alt="SpringMVC处理请求的流程"></p>
<h2 id="描述一下这个流程"><a href="#描述一下这个流程" class="headerlink" title="描述一下这个流程"></a>描述一下这个流程</h2><ul>
<li>用户向服务器发送请求，请求被Spring前端控制Servelt也就是DispatcherServlet捕获；</li>
<li>DispatcherServlet首先调用doService方法，从源码看首先判断是不是include请求，如果是则对request的Attribute做个快照备份， 以便doDispatch处理完之后（如果不是异步调用且未完成）进行还原，在做完快照后还对request设置一些属性，然后调用doDispatch方法。</li>
<li>根据对请求的URL进行解析，得到请求资源标识符（URI）。然后根据该URI，调用HandlerMapping获得该Handler配置的所有相关的对象（包括Handler对象以及Handler对象对应的拦截器），最后以HandlerExecutionChain对象的形式返回；</li>
<li>根据获得的Handler，选择一个合适的HandlerAdapter。（附注：如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler(…)方法）</li>
<li>提取Request中的模型数据，填充Handler入参，开始执行Handler（Controller)。 </li>
<li>Handler执行完成后，返回一个ModelAndView对象；</li>
<li><p>调用processDispatchResult方法处理返回的ModelAndView对象</p>
<blockquote>
<p>选择一个适合的ViewResolver（必须是已经注册到Spring容器中的ViewResolver)返回一个View；<br>ViewResolver 结合Model和View，来渲染视图,然后返回到DispatcherServlet</p>
</blockquote>
</li>
<li><p>将渲染结果返回给客户端。</p>
</li>
</ul>
<h2 id="概念解析"><a href="#概念解析" class="headerlink" title="概念解析"></a>概念解析</h2><ul>
<li>HandlerMapping：是用来查找Handler的，在SpringMVC中会处理很多请求，每个请求都需要一个Handler来处理，具体接收到一个请求后使用哪个Handler来处理呢？这就是HandlerMapping要做的事情。</li>
<li>Handler：也就是处理器，它直接对应着MVC中的C也就是Controller层，它的具体表现形式有很多，可以是类，也可以是方法，如果你能想到别的表现形式也可以使用，它的类型是Object。在工程中使用@RequestMapping的所有方法都可以看成一个Handler。也就是说只要可以实际处理请求就可以是Handler。</li>
<li><p>HandlerAdapter：是一个适配器。因为SpringMVC中的Handler可以是任意的形式，只要能处理请求就OK，但是Servlet需要的处理方法的结构却是固定的，都是以request和response为参数的方法（如doService方法）。怎么让固定的Servlet处理方法调用灵活的Handler来进行处理呢？这就是HandlerAdapter要做的事情。</p>
<blockquote>
<p>通俗点的解释</p>
<p>Handler是用来干活的工具</p>
<p>HandlerMapping用于根据需要干的活找到相应的工具</p>
<p>HandlerAdapter是使用工具干活的人。</p>
</blockquote>
</li>
<li><p>View是用来展示数据的，</p>
</li>
<li>ViewResolver用来查找View。<blockquote>
<p>通俗点的解释</p>
<p>干完活后需要写报告，写报告又需要模板</p>
<p>View就是所需要的模板，内容就是Model里边的数据。</p>
<p>ViewResolver就是用来选择使用哪个模板的。</p>
</blockquote>
</li>
</ul>
<p><strong>概念解析完成之后换一种解释doDispatch方法就是：使用HandlerMapping找到干活的Handler，找到使用Handler的HandlerAdapter，让HandlerAdapter使用Handler干活，干完活后将结果写个报告通过View展示给用户。</strong></p>
<h2 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h2><h3 id="doService方法源码"><a href="#doService方法源码" class="headerlink" title="doService方法源码"></a>doService方法源码</h3><pre><code>// org.springframework.web.servlet.DispatcherServlet
@Override
protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception {
    if (logger.isDebugEnabled()) { //日志级别为debug，输出日志
        String requestUri = urlPathHelper.getRequestUri(request);
        String resumed = WebAsyncUtils.getAsyncManager(request).hasConcurrentResult() ? &quot; resumed&quot; : &quot;&quot;;
        logger.debug(&quot;DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;&quot; + resumed +
                &quot; processing &quot; + request.getMethod() + &quot; request for [&quot; + requestUri + &quot;]&quot;);
    }

    // 如果是include请求, 保存请求属性的快照
    // 用于该include请求完成之后恢复原始属性.
    Map&lt;String, Object&gt; attributesSnapshot = null;
    if (WebUtils.isIncludeRequest(request)) {
        logger.debug(&quot;Taking snapshot of request attributes before include&quot;);
        attributesSnapshot = new HashMap&lt;String, Object&gt;();
        Enumeration&lt;?&gt; attrNames = request.getAttributeNames();
        while (attrNames.hasMoreElements()) {
            String attrName = (String) attrNames.nextElement();
            if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) {
                attributesSnapshot.put(attrName, request.getAttribute(attrName));
            }
        }
    }

    // 处理一些request的属性，使框架对象可用于处理程序和查看对象。
    request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext());
    request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver);
    request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver);
    request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource());

    FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response);
    if (inputFlashMap != null) {
        request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));
    }
    request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap());
    request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager);

    try {
        doDispatch(request, response); // 调用doDispatch方法处理流程
    }
    finally {
        if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) {
            return;
        }
        // 如果是include请求并且请求被正常处理，恢复原始属性快照。
        if (attributesSnapshot != null) {
            restoreAttributesAfterInclude(request, attributesSnapshot);
        }
    }
}
</code></pre><p>doService方法中首先判断是不是include请求，如果是则对request的Attribute做个快照备份， 以便doDispatch处理完之后（如果不是异步调用且未完成）进行还原，在做完快照后还对request设置了一些属性，然后调用doDispatch方法。</p>
<h3 id="doDispatch源码"><a href="#doDispatch源码" class="headerlink" title="doDispatch源码"></a>doDispatch源码</h3><pre><code>// org.springframework.web.servlet.DispatcherServlet
protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {
    HttpServletRequest processedRequest = request;
    HandlerExecutionChain mappedHandler = null;
    boolean multipartRequestParsed = false;

    WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);

    try {
        ModelAndView mv = null;
        Exception dispatchException = null;

        try {
            // 检查是不是上传请求
            processedRequest = checkMultipart(request);
            multipartRequestParsed = processedRequest != request;

            // 根据 request 找到需要处理的handler，返回的是一个HandlerExecutionChain对象
            mappedHandler = getHandler(processedRequest, false);
            if (mappedHandler == null || mappedHandler.getHandler() == null) {
                noHandlerFound(processedRequest, response);
                return;
            }

            // 根据 Handler 找到 HandlerAdapter
            HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());

            // 处理 GET、HEAD 请求的Last-Modified
            String method = request.getMethod();
            boolean isGet = &quot;GET&quot;.equals(method);
            if (isGet || &quot;HEAD&quot;.equals(method)) {
                long lastModified = ha.getLastModified(request, mappedHandler.getHandler());
                if (logger.isDebugEnabled()) {
                    String requestUri = urlPathHelper.getRequestUri(request);
                    logger.debug(&quot;Last-Modified value for [&quot; + requestUri + &quot;] is: &quot; + lastModified);
                }
                if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) {
                    return;
                }
            }
            // 执行相应 Interceptor的preHandle
            if (!mappedHandler.applyPreHandle(processedRequest, response)) {
                return;
            }

            try {
                // HandlerAdapter 使用 Handler处理请求
                mv = ha.handle(processedRequest, response, mappedHandler.getHandler());
            }
            finally {
                // 如果需要异步处理，直接返回
                if (asyncManager.isConcurrentHandlingStarted()) {
                    return;
                }
            }

            //当view为空时（比如，Handler返回值为void），根据request设置默认view
            applyDefaultViewName(request, mv);
            //执行相应Interceptor的postHandle
            mappedHandler.applyPostHandle(processedRequest, response, mv);
        }
        catch (Exception ex) {
            dispatchException = ex;
        }
        // 处理返回结果。包括处理异常、渲染页面、发出完成通知触发Interceptor的afterCompletion
        processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);
    }
    catch (Exception ex) {
        triggerAfterCompletion(processedRequest, response, mappedHandler, ex);
    }
    catch (Error err) {
        triggerAfterCompletionWithError(processedRequest, response, mappedHandler, err);
    }
    finally {
        // 判断是否执行异步请求
        if (asyncManager.isConcurrentHandlingStarted()) {
            // Instead of postHandle and afterCompletion
            mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);
            return;
        }
        // 清除上传请求的资源
        if (multipartRequestParsed) {
            cleanupMultipart(processedRequest);
        }
    }
}
</code></pre><h3 id="doDispatch方法解析"><a href="#doDispatch方法解析" class="headerlink" title="doDispatch方法解析"></a>doDispatch方法解析</h3><p>doDispatch大体可以分为两部分：处理请求和渲染页面。</p>
<h4 id="处理请求"><a href="#处理请求" class="headerlink" title="处理请求"></a>处理请求</h4><blockquote>
<p>开头部分先定义了几个变量，在后面要用到，如下：</p>
<ul>
<li>HttpServletRequestprocessedRequest：实际处理时所用的request，如果不是上传请求则直接使用接收到的request，否则封装为上传类型的request。</li>
<li>HandlerExecutionChainmappedHandler：处理请求的处理器链（包含处理器和对应的Interceptor）。</li>
<li>booleanmultipartRequestParsed：是不是上传请求的标志。</li>
<li>ModelAndViewmv：封装Model和View的容器。</li>
<li>ExceptiondispatchException：处理请求过程中抛出的异常。需要注意的是它并不包含渲染过程抛出的异常。</li>
</ul>
<p>doDispatch中首先检查是不是上传请求，如果是上传请求，则将request转换为Multi-partHttpServletRequest，并将multipartRequestParsed标志设置为true。其中使用到了Multipart-Resolver。</p>
<p>然后通过getHandler方法获取Handler处理器链，其中使用到了HandlerMapping，返回值为HandlerExecutionChain类型，其中包含着与当前request相匹配的Interceptor和Handler。</p>
</blockquote>
<p>getHandler代码如下：</p>
<pre><code>// org.springframework.web.servlet.DispatcherServlet
protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {
    for (HandlerMapping hm : this.handlerMappings) {
        if (logger.isTraceEnabled()) {
            logger.trace(
                    &quot;Testing handler map [&quot; + hm + &quot;] in DispatcherServlet with name &apos;&quot; + getServletName() + &quot;&apos;&quot;);
        }
        HandlerExecutionChain handler = hm.getHandler(request);
        if (handler != null) {
            return handler;
        }
    }
    return null;
}
</code></pre><blockquote>
<p>其中hm.getHandler()方法如下：</p>
</blockquote>
<pre><code>//org.springframework.web.servlet.handler.AbstractHandlerMapping
public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {
    Object handler = getHandlerInternal(request);
    if (handler == null) {
        handler = getDefaultHandler();
    }
    if (handler == null) {
        return null;
    }
    // Bean name or resolved handler?
    if (handler instanceof String) {
        String handlerName = (String) handler;
        handler = getApplicationContext().getBean(handlerName);
    }
    return getHandlerExecutionChain(handler, request);
}
</code></pre><blockquote>
<p>执行时先依次执行Interceptor的preHandle方法，最后执行Handler，返回的时候按相反的顺序执行Interceptor的postHandle方法。就好像要去一个地方，Interceptor是要经过的收费站，Handler是目的地，去的时候和返回的时候都要经过加油站，但两次所经过的顺序是相反的。</p>
</blockquote>
<p>获取到Handler之后接下来是处理GET、HEAD请求的Last-Modified。当浏览器第一次跟服务器请求资源（GET、Head请求）时，服务器在返回的请求头里面会包含一个Last-Modified的属性，代表本资源最后是什么时候修改的。在浏览器以后发送请求时会同时发送之前接收到的Last-Modified，服务器接收到带Last-Modified的请求后会用其值和自己实际资源的最后修改时间做对比，如果资源过期了则返回新的资源（同时返回新的Last-Modified），否则直接返回304状态码表示资源未过期，浏览器直接使用之前缓存的结果。</p>
<p>接下来依次调用相应Interceptor的preHandle。</p>
<p>处理完Interceptor的preHandle后就到了此方法最关键的地方——让HandlerAdapter使用Handler处理请求，Controller就是在这个地方执行的。这里主要使用了HandlerAdapter，具体内容在后面详细讲解。</p>
<p>Handler处理完请求后，如果需要异步处理，则直接返回，如果不需要异步处理，当view为空时（如Handler返回值为void），设置默认view，然后执行相应Interceptor的postHandle。设置默认view的过程中使用到了ViewNameTranslator。</p>
<h4 id="渲染页面"><a href="#渲染页面" class="headerlink" title="渲染页面"></a>渲染页面</h4><p>接下来使用processDispatchResult方法处理前面返回的结果，其中包括处理异常、渲染页面、触发Interceptor的afterCompletion方法三部分内容。</p>
<p>doDispatch的异常处理结构:</p>
<blockquote>
<p>doDispatch有两层异常捕获:</p>
<blockquote>
<p>内层是捕获在对请求进行处理的过程中抛出的异常，</p>
<p>外层主要是在处理渲染页面时抛出的。</p>
<p>内层的异常，也就是执行请求处理时的异常会设置到dispatchException变量，然后在processDispatchResult方法中进行处理，</p>
<p>外层则是处理processDispatchResult方法抛出的异常。</p>
</blockquote>
</blockquote>
<p>processDispatchResult代码如下：</p>
<pre><code>// org.springframework.web.servlet.DispatcherServlet
private void processDispatchResult(HttpServletRequest request, HttpServletResponse response,
        HandlerExecutionChain mappedHandler, ModelAndView mv, Exception exception) throws Exception {

    boolean errorView = false;

    //如果请求处理的过程中有异常抛出则处理异常
    if (exception != null) {
        if (exception instanceof ModelAndViewDefiningException) {
            logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, exception);
            mv = ((ModelAndViewDefiningException) exception).getModelAndView();
        }
        else {
            Object handler = (mappedHandler != null ? mappedHandler.getHandler() : null);
            mv = processHandlerException(request, response, handler, exception);
            errorView = (mv != null);
        }
    }

    // 处理程序是否返回一个视图用于呈现？
    if (mv != null &amp;&amp; !mv.wasCleared()) {
        render(mv, request, response);
        if (errorView) {
            WebUtils.clearErrorRequestAttributes(request);
        }
    }
    else {
        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Null ModelAndView returned to DispatcherServlet with name &apos;&quot; + getServletName() +
                    &quot;&apos;: assuming HandlerAdapter completed request handling&quot;);
        }
    }

    if (WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) {
        // 如果启动了异步处理则返回
        return;
    }

    //发出请求处理完成的通知，触发Interceptor的afterCompletion
    if (mappedHandler != null) {
        mappedHandler.triggerAfterCompletion(request, response, null);
    }
}
</code></pre><ul>
<li>processDispatchResult方法解析：<blockquote>
<p>processDispatchResult处理异常的方式其实就是将相应的错误页面设置到View，在其中的processHandlerException方法中用到了HandlerExceptionResolver。</p>
<p>渲染页面具体在render方法中执行，render中首先对response设置了Local，过程中使用到了LocaleResolver，然后判断View如果是String类型则调用resolveViewName方法使用ViewResolver得到实际的View，最后调用View的render方法对页面进行具体渲染，渲染的过程中使用到了ThemeResolver。</p>
<p>通过mappedHandler的triggerAfterCompletion方法触发Interceptor的afterCompletion方法，这里的Interceptor也是按反方向执行的。</p>
</blockquote>
</li>
</ul>
<ul>
<li>最终再返回doDispatch方法<blockquote>
<p>在最后的finally中判断是否请求启动了异步处理，如果启动了则调用相应异步处理的拦截器，否则如果是上传请求则删除上传请求过程中产生的临时资源。</p>
</blockquote>
</li>
</ul>
<h3 id="doDispatcher的流程图"><a href="#doDispatcher的流程图" class="headerlink" title="doDispatcher的流程图"></a>doDispatcher的流程图</h3><p><img src="https://github.com/gamesdoa/img0/raw/master/spring/dispatcherServlet-doDispatch.jpg" alt="doDispatch流程图"></p>
<ul>
<li>左边是Interceptor相关处理方法的调用位置.</li>
<li>右边是doDispatcher方法处理过程中所涉及的组件。</li>
<li><strong>中间是doDispatcher的处理流程图.</strong><blockquote>
<p>上半部分的处理请求对应着MVC中的Controller也就是C层，</p>
<p>下半部分的processDispatchResult主要对应了MVC中的View也就是V层，</p>
<p>M层也就是Model贯穿于整个过程中。</p>
</blockquote>
</li>
</ul>
]]></content>
    
    <summary type="html">
    
      一个客户端请求是怎么样被springMVC处理的？我们来通过几个很low的简图和高大上的源码简要分析一下
    
    </summary>
    
      <category term="spring" scheme="http://gamesdoa.com/categories/spring/"/>
    
    
      <category term="java" scheme="http://gamesdoa.com/tags/java/"/>
    
      <category term="spring" scheme="http://gamesdoa.com/tags/spring/"/>
    
  </entry>
  
  <entry>
    <title>mysql InnoDB 索引分析及优化</title>
    <link href="http://gamesdoa.com/mysql-innodb-index.html"/>
    <id>http://gamesdoa.com/mysql-innodb-index.html</id>
    <published>2017-06-30T16:00:00.000Z</published>
    <updated>2017-08-08T02:05:57.513Z</updated>
    
    <content type="html"><![CDATA[<h2 id="B-Tree索引"><a href="#B-Tree索引" class="headerlink" title="B+Tree索引"></a>B+Tree索引</h2><p>B+Tree的数据结构这里就不详细表述了，如果你还不了解什么是B+Tree，请参考这里<a href="https://zh.wikipedia.org/wiki/B%2B%E6%A0%91" title="B+树" target="_blank" rel="external">https://zh.wikipedia.org/wiki/B%2B%E6%A0%91</a>，如果你不想花费时间研究B+Tree，在这里也附上一张个人理解的InnoDB实现的B+Tree图，并会稍作说明。</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/mysql/innodb-index/B%2BTree.jpg" alt="B+Tree个人理解图"></p>
<ul>
<li>B+Tree是一个多路查找树，扁平结构。</li>
<li>非叶子节点只存储指向下层节点的指针。</li>
<li>兄弟非叶子节点之间不存在指向指针。</li>
<li><strong>数据只存储在叶子节点上。</strong></li>
<li>每个叶子节点都有一个指向下个叶子节点的指针(持有兄弟叶子节点的指针)。</li>
<li>每个节点都是一个16k大小的页</li>
<li>数据插入时需要考虑负载因子和页分裂(页数据半分或者直接新页)</li>
<li>数据删除时需要考虑负载因子和页合并</li>
<li>非叶子节点指向叶子节点的指针，只能指向该叶子节点的页，具体数据需要把页加载到内存中然后使用二分查找定位数据。</li>
<li>所有的值都是顺序存储的，叶子结点中</li>
<li>在查找的时候必须按照最左前缀原则并且不能跳列，不然无法使用索引。</li>
<li>在查询使用索引的时候如果遇到范围查询，范围查询的列右边的列将不会被使用到索引。</li>
</ul>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><h4 id="索引优点："><a href="#索引优点：" class="headerlink" title="索引优点："></a>索引优点：</h4><ul>
<li>大大减少服务器需要扫描的数据量</li>
<li>帮助服务器避免排序和临时表</li>
<li>将随机I/O变为顺序I/O</li>
</ul>
<h4 id="索引缺点："><a href="#索引缺点：" class="headerlink" title="索引缺点："></a>索引缺点：</h4><ul>
<li>对于小表，索引会增加额外的功能，全表扫描反而更快</li>
<li>对于特大表，建立索引的代价太高，不适用，可以使用分区表。</li>
</ul>
<h4 id="如何建立高性能索引？"><a href="#如何建立高性能索引？" class="headerlink" title="如何建立高性能索引？"></a>如何建立高性能索引？</h4><ul>
<li>索引列的干净，独立<blockquote>
<p>索引列不能是表达式的一部分，也不能是函数的参数。使用时也只能是干净的列。</p>
</blockquote>
</li>
<li>缩小索引列的数据<blockquote>
<p>对于索引列数据量特别大的情况，如果全量存储会使索引变得大而且也会慢：大是因为数据量大而产生的数据在索引页中占用大量空间，对于固定页大下的InnoDB存储引用，单个数据量大造成每个页上存储的数据的数量变少，而且还会造成索引树的高度增加，对于相同数量级的数据，I/O次数会更多。</p>
<p>前缀索引是个不错的选择，取数据开始的一部分进行索引，要考虑索引的选择性问题，选择性越高，索引效率越好，但是也可能占用的空间越大。</p>
<p>对于BLOB、TEXT、很长的VARCHAR都需要前缀索引</p>
<p>ADD KEY (col(num)) 创建前缀索引。</p>
</blockquote>
</li>
<li><p>多列索引</p>
<blockquote>
<p>mysql中单列索引是针对每个需要索引的列单独设置索引，但是这种设置索引的方式对于where单条件查询来说很方便，但是我们很多时候都是需要多个索引相交操作的，这时候多个单列索引最好的情况也就只能是索引合并，索引合并涉及计算并不会统计在查询成本中。</p>
<p>所以一般情况下，我们不会针对单列创建索引，而是根据具体使用sql创建多列索引。</p>
<p><strong>多列索引列顺序</strong>：</p>
<blockquote>
<ol>
<li>依赖于使用该索引的查询，并要符合最左前缀原则</li>
<li>需要考虑如何更好的满足排序和分组的需要</li>
</ol>
</blockquote>
<p>如果不需要考虑排序和分组时，将选择性最高的列放在索引最前面同时最好选择数据基数小的列在前面</p>
</blockquote>
</li>
<li><p>聚族索引</p>
<blockquote>
<p>InnoDB采用的是聚族索引方式，就是按照ID生成的B+Tree结构， 完整数据存储在该树的叶子节点。<br>对于非ID的索引生成的B+Tree结构，最终叶子节点存储的是指向聚族索引的key，也就是ID，因此为了顺序的写入减少随机IO，在设计表的时候尽量对于每一张表设计一个自增主键最为ID。</p>
</blockquote>
</li>
<li>非聚族索引<blockquote>
<p>针对除了主键ID产生的B+Tree之外的索引树，都是非聚族索引。该树的最终叶子节点存储的是聚族索引的ID，也就导致如果需要查询该行所有的记录的话，需要再回源聚族索引。同时在非聚族索引的列中默认会在最后添加ID，已达到索引的key唯一性。也就是说如果创建（列1，列2）的索引，那么最终的索引形式表现为（列1，列2，ID）这样的结构</p>
</blockquote>
</li>
<li>覆盖索引<blockquote>
<p>对于非聚族索引，如果能在查询时select的列中所有的数据对存在于队列索引中，那么该查询在最终叶子节点中能找到所有的数据不需要再到聚族索引中去回源数据。这样就节省了回源的开销和IO。在EXPLAIN中可以展示为Using index</p>
</blockquote>
</li>
<li><p>使用索引扫描来做排序</p>
<blockquote>
<p>扫描索引速度很快，只需要从一条索引记录移动到紧接着的下一条记录，但是如果索引不能覆盖查询所需的全部列，就不能不把扫描到的行回源聚族索引读取对应行记录，这个操作是一个随机I/O，速度将会很慢，所以如果能将一个索引即满足排序，又用于查找行，那么查询的速度无疑是最好的。当然只有当索引的列顺序和ORDER BY子句的顺序完全一致并且所有列的排序方向都一致时，才会使用到索引扫描排序。</p>
<p>必须在排序子句中完全满足最左前缀，并且排序顺序一致，当然如果最左前缀的前面一项或者几项是常量的话可以不关注该项，但是该项必须出现在where子句中，这样也能满足最左前缀。</p>
</blockquote>
</li>
</ul>
<p>以上是一些自己的小看法，如果有不足之处，希望各位看客批评指正。</p>
]]></content>
    
    <summary type="html">
    
      mysql的InnoDB索引是如何实现的？为什么InnoDB的索引要遵循最左前缀的规则？什么是聚族索引，什么又是辅助索引或者非聚族索引，他们之间的关系是怎么样的？如何根据InnoDB的实现来优化我们自己的sql语句？且听小生慢慢道来。
    
    </summary>
    
      <category term="mysql" scheme="http://gamesdoa.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://gamesdoa.com/tags/mysql/"/>
    
      <category term="InnoDB" scheme="http://gamesdoa.com/tags/InnoDB/"/>
    
      <category term="B+Tree" scheme="http://gamesdoa.com/tags/B-Tree/"/>
    
  </entry>
  
  <entry>
    <title>hotspot GC分析</title>
    <link href="http://gamesdoa.com/hotspot-gc.html"/>
    <id>http://gamesdoa.com/hotspot-gc.html</id>
    <published>2017-06-19T16:00:00.000Z</published>
    <updated>2017-06-29T14:46:57.261Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需要关注GC以及内存分配"><a href="#为什么需要关注GC以及内存分配" class="headerlink" title="为什么需要关注GC以及内存分配"></a>为什么需要关注GC以及内存分配</h2><blockquote>
<p>jvm内存的动态分配和内存回收技术已经相当成熟了，我们看起来不需要关注GC和内存分配也能很好地工作，那么我们为什么还要去了解GC和内存分配呢？</p>
<p>其实答案很简单：当需要排查各种内存溢出、内存泄漏问题时，当GC成为系统达到更高并发的瓶颈时，我们只有知道了它的工作原理，才能对其进行监控分析，才能找到问题解决问题。</p>
</blockquote>
<p><strong>在进行hotspot虚拟机的算法实现分析之前，我们需要先了解一下下面这些概念。</strong></p>
<h2 id="区分对象是死亡还是存活的算法"><a href="#区分对象是死亡还是存活的算法" class="headerlink" title="区分对象是死亡还是存活的算法"></a>区分对象是死亡还是存活的算法</h2><h3 id="引用计算算法"><a href="#引用计算算法" class="headerlink" title="引用计算算法"></a>引用计算算法</h3><p><strong>引用计算(Reference Counting)</strong>：给对象添加一个引用计数器，每当有一个地方引用它时，计数器加1，当引用失效是计数器减1，任何时刻计数器为0时，说明对象不可能被使用。</p>
<p>这种算法实现简单，判断效率很高，但是会有循环引用问题，A引用B，B也引用了A，这样即使没有其他对象引用，也不会被垃圾回收。</p>
<h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a><span id="ra">可达性分析算法</span></h3><p><strong>可达性分析(Reachability Analysis)</strong>：通过一系列被称为”GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链的时候，说明对象不可用。<br>这种算法的效率和存活对象大小有关，当大量存活对象存在时，效率比较低，但是不会有循环引用不问题。java内存回收一般就是使用这种算法实现的。</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/%E5%8F%AF%E8%BE%BE%E6%80%A7%E5%88%86%E6%9E%90.jpg" alt="可达性分析对象是否能被回收"></p>
<p>在java语言中，可作为GC Roots的对象包括以下几种：</p>
<ul>
<li>虚拟机栈(栈帧中的本地变量表)中引用的对象。</li>
<li>方法区中的静态属性引用的对象。</li>
<li>方法区中常量引用的对象。</li>
<li>本地方法栈中JNI引用的对象。</li>
</ul>
<h2 id="垃圾收集算法"><a href="#垃圾收集算法" class="headerlink" title="垃圾收集算法"></a>垃圾收集算法</h2><h3 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h3><p>最基础的收集算法，分为标记和清除两个阶段，标记阶段采用可达性分析算法，清除阶段，直接清除可回收的对象。</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/%E6%A0%87%E8%AE%B0-%E6%B8%85%E9%99%A4.jpg" alt="标记-清除算法"></p>
<p>不足：</p>
<ul>
<li>效率问题：标记和清除两个过程的效率都不高。</li>
<li>空间问题：标记清除之后会产生大量不连续的内存碎片，可能导致分配较大对象时，虽然有足够空间，但是却不能分配，会导致提前出发另外一种垃圾收集动作(后面讲CMS收集器的时候，并发失效的情况就有一种情况是因为这个原因造成的)<h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3>为了解决效率问题，于是出现了复制算法(Copying)，它的实现是把内存按照容量划分成大小相等的两块，每次只使用其中一块，当这一块内存用完，就将还存活的对象复制到另一块上面，然后再把已使用过的内存开间一次清理掉。这样就可以每次对整个半区进行内存回收，内存分配时也就不会出现碎片问题，而且只需要移动堆顶的指针，按顺序分配内存即可，实现简单，运行效率高。</li>
</ul>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/copying.jpg" alt="copying算法示意图"></p>
<p>不足：</p>
<blockquote>
<p>内存分为两部分，可使用一下子就只剩下原有内存的一半，代价优点太高了，但是根据新生对象朝生夕死的特点，不需要分成对等的两部分，可以按照8：1：1分成3部分(具体实现详见hotspot新生代内存管理)</p>
<p>存活对象较多的时候复制代价比较大，效率也会比较低。</p>
</blockquote>
<h3 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h3><p>针对标记-清除算法的空间碎片问题，提出了改方案，就是标记阶段和标记-清除一样，但是之后的阶段为整理，就是把存活对象都向一端移动，然后直接清理掉边界以外的内存：</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/mark-compact.jpg" alt="标记-整理算法示意图"></p>
<h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>根据对象存活的特点把内存划分成几块，比如划分为新生代和老年代，这样就能根据不同年代的特点采用不用的收集算法。</p>
<ul>
<li>在新生代，对象一般都是朝生夕死，存活对象相对较少，这种就适用复制算法</li>
<li>在老年代，对象存活比较久，存活对象数量比较多，很显然不适合复制算法，只能使用标记-清除或者标记-整理算法。</li>
</ul>
<p><strong>了解了以上的概念之后，我们再来看一下hotspot算法的实现</strong></p>
<h2 id="Hotspot算法实现"><a href="#Hotspot算法实现" class="headerlink" title="Hotspot算法实现"></a>Hotspot算法实现</h2><h3 id="枚举根节点"><a href="#枚举根节点" class="headerlink" title="枚举根节点"></a>枚举根节点</h3><p>使用到我们之前说到的<a href="#ra">可达性分析算法</a>,其中可作为GC Roots的节点主要是全局性的引用与执行上下文，在方法区特别大的时候如果逐个检查必然会消耗很多时间，而且在可达性分析时还要求分析工作必须确保<strong>分析过程中的一致性</strong>，也就造就了这一阶段必须停顿所有执行线程也就是俗称的 <strong>Stop The World(STW)</strong>。那么即要求STW又会消耗很多时间，而对于程序执行而言，同样希望停顿时间越短越好，那么有什么好的解决办法呢？</p>
<p>对于Hotspot来说，Hotspot使用一组称为OopMap的数据结构来处理，在类加载完成的时候，Hotspot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编辑过程中也会在特定的位置记录下栈和寄存器中那些位置是引用，这样GC在扫描的时候就可以直接通过OopMap得知这些信息，不需要一个不漏的检查所有执行上下文和全局的引用位置，已达到高效的目的，缩短STW时间。</p>
<h3 id="安全点"><a href="#安全点" class="headerlink" title="安全点"></a>安全点</h3><p>在OopMap的协助下，Hotspot可以快速准确的完成GC Roots枚举，但是因为Oopmap内容变化的指令非常多，不可能为每一条指令都生成对应的OopMap，只能在特定的位置上记录这些信息，这个特定位置称为安全点(Safepoint)</p>
<blockquote>
<p>也就是所程序并不是在所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。</p>
</blockquote>
<p>怎么样才能在GC发生时让所有线程都跑到最近的安全点上再停顿下来呢？</p>
<p>Hotspot采用主动式中断思想，当GC需要中断线程的时候，不直接对线程操作，仅仅简单的设置一个标志，各个线程执行时主动去轮询这个标志，发现中断标志为真时就自己中断挂起。<strong>轮询标志的地方和安全点设置成重合的，</strong>同时还是创建对象需要分配内存的地方。</p>
<h3 id="安全区域"><a href="#安全区域" class="headerlink" title="安全区域"></a>安全区域</h3><p>当线程处于Sleep或者Blocked状态的时候，线程明显就是不能相应中断请求，跑到安全点去，而且JVM也不可能等待线程重新被分配CPU时间，所以就需要安全区域(Safe Region)来解决。</p>
<blockquote>
<p>安全区域是指，在一段代码中引用关系不会发生变化，在这个区域的任意地方开始GC都是安全的。</p>
</blockquote>
<p>在线程执行到Saft Region的时候，首先标识自己已近进入到Safe Region，那么，当在这期间JVM发起GC时，就不管标识自己为Safe Region的线程。当线程要离开Safe Region时，它要检查系统是否已经完成类跟节点枚举或者整个GC过程，如果完成，那么线程继续，否则，它必须等待收到可以安全离开Safe Region信号为止。</p>
<h2 id="Hotspot堆内存划分"><a href="#Hotspot堆内存划分" class="headerlink" title="Hotspot堆内存划分"></a>Hotspot堆内存划分</h2><p>Hotspot的堆内存首先是划分为新生代和老年的，两个大的概念</p>
<ul>
<li>新生代：根据复制算法的特点，新生代又划分成3个部分，一个Eden区，两个Survivor区。使用规则是：内存分配在Eden区开始，当Eden区被耗尽时，发生GC，这时存活的对象进入一个Survivor区(S0)，下一次再发生GC时，存活对象由Eden区和S0区进入S1区，如此反复。默认的分配比例<strong>Eden:S0:S1 = 8:1:1</strong></li>
<li>老年的：不再划分区域。当老年的内存不足以存放进入老年的内存是发生GC。</li>
</ul>
<h2 id="Hotspot中的GC收集器"><a href="#Hotspot中的GC收集器" class="headerlink" title="Hotspot中的GC收集器"></a>Hotspot中的GC收集器</h2><h3 id="Serial收集器"><a href="#Serial收集器" class="headerlink" title="Serial收集器"></a>Serial收集器</h3><p>特点：</p>
<ul>
<li>单线程收集</li>
<li>只会使用一个CPU或者一个收集线程完成垃圾收集工作。</li>
<li>必须暂停其他所有的工作线程，也就是Stop The World(STW)。</li>
<li>由虚拟机后台发起并自动完成，用户不可控的。<blockquote>
<p>根据Serial收集器的特点不难看出，在很多大型应用的场景下，这个收集器是不可接受的，那么它能在哪里使用呢？</p>
<p>sun公司把它设置成Client模式下新生代的默认收集器，在单个CPU的环境下，效率最高。</p>
</blockquote>
</li>
</ul>
<h3 id="Throughput收集器"><a href="#Throughput收集器" class="headerlink" title="Throughput收集器"></a>Throughput收集器</h3><h4 id="MinorGC"><a href="#MinorGC" class="headerlink" title="MinorGC"></a><span id="tmgc">MinorGC</span></h4><p>Eden空间耗尽时，新创建的对象无法分配到内存时发生GC，这时的GC称为MinorGC。</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/throughput-minor.jpg" alt="throughput minor GC"></p>
<p>如上图所示：在发生一次MinorGC的时候，会把Eden区和当前正在使用的Survivor区内的存活对象复制到另外一个空余的Survivor区内，然后清空eden区和使用的Survivor区。如此反复操作，每次GC时都是使存活对象存储在另外一个没有使用的Survivor区中。</p>
<ul>
<li>当存活对象太多，Survivor区无法存放的情况下，会有部分存活对象直接进入老年代。</li>
<li>当对象在Survivor区经过多次GC周期(到达晋升阈值时)还存活的，则进入老年代。<blockquote>
<p>可以通过-XX:InitialTenuringThreshold=N 设置晋升老年代的阈值(默认7)</p>
<p>如希望跟踪每次minor GC后新的存活周期的阈值，可在启动参数上增加：-XX:+PrintTenuringDistribution，</p>
<p>输出的信息中的：Desired survivor size 1086516 bytes, new threshold 7 (max 15)</p>
<p>new threshold 7即标识新的存活周期的阈值为7。</p>
</blockquote>
</li>
</ul>
<h4 id="FullGC"><a href="#FullGC" class="headerlink" title="FullGC"></a>FullGC</h4><p>当老年代空间耗尽，无法存放新进入老年代对象时，发生GC，这种GC称为FullGC，一般时间比较长。</p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/throughput-full.jpg" alt="throughput full GC"></p>
<p>如上图所示，发生FullGC的时候会默认清理新生代以及老年代的内存，并压缩活跃对象在老年代中保持。</p>
<ul>
<li><p>需要注意的是FullGC之后Eden和两个Survivor区，也就是整个新生代全部清空。</p>
  <figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//GC日志如下：</span></div><div class="line"><span class="number">3007005.033</span>: [Full GC [PSYoungGen: <span class="number">8786</span>K-&gt;<span class="number">0</span>K(<span class="number">679936</span>K)]		<span class="comment">//新生代清空</span></div><div class="line">[ParOldGen: <span class="number">690616</span>K-&gt;<span class="number">71645</span>K(<span class="number">699392</span>K)]		<span class="comment">// 老年代压缩</span></div><div class="line"><span class="number">699402</span>K-&gt;<span class="number">71645</span>K(<span class="number">1379328</span>K)		<span class="comment">// 总的堆内存变化</span></div><div class="line">[PSPermGen: <span class="number">55092</span>K-&gt;<span class="number">55092</span>K(<span class="number">55296</span>K)]		<span class="comment">//永久代</span></div><div class="line">, <span class="number">0.3721260</span> secs]		<span class="comment">//耗时</span></div><div class="line">[Times: user=<span class="number">0.61</span> sys=<span class="number">0.00</span>, real=<span class="number">0.38</span> secs]		<span class="comment">// CPU时间 0.61秒 真实时间 0.38秒 2个CPU处理</span></div></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="永久代GC"><a href="#永久代GC" class="headerlink" title="永久代GC"></a>永久代GC</h4><p>多数的FullGC永久代对象都不会回收，但是如果永久代空间耗尽，JVM也会发起FullGC回收永久代的对象。</p>
<h4 id="调优"><a href="#调优" class="headerlink" title="调优"></a>调优</h4><p>针对Throughput收集器的调优，主要是对可承受最大停顿时间和应用在垃圾回收上花费时间为基准的。</p>
<ul>
<li>-XX:MaxGCPauseMillis = N   可承受的最大停顿时间</li>
<li>-XX:GCTimeRatio = N        应用在垃圾回收上花费的时间，默认值99，也就是垃圾回收花费时间占应用时间的1%,计算公式(1/(1+GCTimeRatio))</li>
</ul>
<blockquote>
<p>在 -XMS  、  -Xmx  、  XX:MaxGCPauseMillis = N 、-XX:GCTimeRatio = N 这些值当中MaxGCPauseMillis优先级最高，如果设置了这个值，新生代和老年代会随之进行调整，直到满足对应的停顿时间。一旦这个目标达成，堆得总容量就开始逐渐增大直到运行时间的比率达到设定值，这两个目标都达成后，JVM会尝试缩减堆得大小，尽可能以最小堆大小来满足这两个目标</p>
</blockquote>
<h3 id="CMS收集器"><a href="#CMS收集器" class="headerlink" title="CMS收集器"></a>CMS收集器</h3><p>CMS : Concurrent Mark Sweep ,一款基于”标记-清除”算法实现的收集器，以获取最短回收停顿时间为目标的收集器。主要会做下面三件事情：</p>
<ol>
<li>对新生代的对象进行回收(Stop The World) 所有应用线程会被暂停。</li>
<li>启动一个或多个并发线程对老年代空间的垃圾进行回收。</li>
<li>如果有必要，CMS会发起FullGC</li>
</ol>
<h4 id="新生代GC"><a href="#新生代GC" class="headerlink" title="新生代GC"></a>新生代GC</h4><p>新生代GC和Throughput收集器的MinorGC基本一样，<a href="#tmgc">可以看这里</a></p>
<h4 id="并发老年代GC"><a href="#并发老年代GC" class="headerlink" title="并发老年代GC"></a>并发老年代GC</h4><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/CMS-old.jpg" alt="并发收集老年代"></p>
<p><strong>整个并发回收的过程是：</strong></p>
<ol>
<li>初始标记  ：  暂停所有应用程序线程 STW</li>
<li>标记阶段  ：  应用程序线程持续运行，不会被中断 </li>
<li>预清理    ： 与应用程序并行</li>
<li>重新标记  ： 可中断预清理(比如发生新生代GC) STW</li>
<li>清除     ：  并发运行(可以被新生代垃圾回收中断)</li>
<li>并发重置</li>
</ol>
<p><strong><span id="cmsf">并发失效的情况</span>：</strong></p>
<ul>
<li><p>新生代垃圾回收，同时老年代又没有足够空间容纳晋升的对象时。日志中会出现(<strong><font color="#FF0000">concurrent mode failure</font></strong>)</p>
<pre><code>1285.946: [GC 1285.946: [ParNew: 353920K-&gt;353920K(353920K), 0.8003983 secs]
1286.747: [CMS1287.338: [CMS-con current-sweep: 7.902/9.624 secs] 
[Times: user=96.62 sys=2.35, real=9.62 secs] 
(concurrent mode failure): 
2531317K-&gt;1161025K(2752512K), 24.8330303 secs] 
2860005K-&gt;1161025K(3106432K), 
[CMS Perm : 37117K-&gt;3 6905K(62368K)], 25.6341706 secs] 
[Times: user=26.41 sys=0.05, real=25.63 secs]
</code></pre></li>
<li><p>老年代空间可以容纳晋升对象，但是由于空间碎片化导致失败时。日志中会出现(<strong><font color="#FF0000">promotion failed</font></strong>)</p>
<pre><code>35333.562 : [GC  35333.562 : 
[ParNew (promotion failed): 1877376K-&gt;1877376K(1877376K),  15.7989680  secs] 
35349.361 : [CMS: 2144171K-&gt;2129287K(2146304K),  10.4200280  secs] 
3514052K-&gt;2129287K(4023680K), 
[CMS Perm : 119979K-&gt;118652K(190132K)],  26.2193500  secs] 
[Times: user= 30.35  sys= 5.19 , real= 26.22  secs]
</code></pre></li>
</ul>
<p>都会退化为FullGC，单线程处理并且Stop The World</p>
<h4 id="FullGC-1"><a href="#FullGC-1" class="headerlink" title="FullGC"></a>FullGC</h4><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/cms-fullgc.jpg" alt="CMS的FullGC"></p>
<p>并发失败后的退化为FullGC的情况下，示意图如上。</p>
<h4 id="永久代-元空间-GC"><a href="#永久代-元空间-GC" class="headerlink" title="永久代(元空间)GC"></a>永久代(元空间)GC</h4><p>永久代空间耗尽，需要回收时，会发生FullGC，日志一般如下：</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//GC日志如下：</span></div><div class="line"><span class="number">3007005.033</span>: [Full GC <span class="number">3007005.033</span>:</div><div class="line">	[CMS: <span class="number">8786</span>K-&gt;<span class="number">5847</span>K(<span class="number">679936</span>K), <span class="number">0.6421260</span> secs]	</div><div class="line">	<span class="number">699402</span>K-&gt;<span class="number">5847</span>K(<span class="number">1379328</span>K),		<span class="comment">// 总的堆内存变化</span></div><div class="line">[CMS Perm : <span class="number">55092</span>K-&gt;<span class="number">43092</span>K(<span class="number">55296</span>K)],	<span class="comment">//永久代</span></div><div class="line">, <span class="number">0.6721260</span> secs]		<span class="comment">//耗时</span></div></pre></td></tr></table></figure>
</code></pre><p>CMS收集后永久代空间大小减小了，Java8中，元空间也是一样的情况。</p>
<blockquote>
<p>默认情况：CMS收集器不会对永久代(元空间)进行收集，但是，它一旦被耗尽，就需要进行Full GC，所有没有被引用的类都会被回收。</p>
</blockquote>
<h4 id="调优-1"><a href="#调优-1" class="headerlink" title="调优"></a>调优</h4><ol>
<li><p>针对并发模式失效的调优</p>
<ul>
<li>想办法增大老年代空间.<blockquote>
<p>增加更多的堆空间(个人推荐)</p>
<p>移动部分新生代空间到老年代:个人不推荐这种方式，因为新生代变小会带来一系列问题</p>
<blockquote>
<p>如非必要的对象可能会更快晋升到老年代，使老年代对象占用空间增加过快。</p>
<p>会使新生代GC频率过高，导致对并发GC的中断，反而使并发更容易失效</p>
</blockquote>
</blockquote>
</li>
<li><p>尽早开启并发收集，更早的启动并发收集，完成垃圾收集的几率就更大。</p>
<blockquote>
<p>-XX:CMSInitiatingOccupancyFraction=N : 设置当老年代内的对象占老年代内存的百分之多少的时候，开启并发收集，默认值70.</p>
<blockquote>
<p>我应该怎么样设置CMSInitiatingOccupancyFraction？<br>在GC日志中查找并发模式失效第一次出现的位置(<a href="#cmsf">如何查找</a>)，然后再反向查找最近的一个启动日志，日志中含有CMS-initial-mark,然后827596k/1379328K=60% ，也就是60%的时候开始的并发收集。建议可以减少10-20%。</p>
</blockquote>
</blockquote>
<pre><code>6457.548: [GC [1 CMS-initial-mark:827596k(1379328K)]
        66428k(2379328K), 0.0830120 secs]
        [Times: user=0.08 sys=0.00, real=0.08 secs]]
</code></pre><blockquote>
<p>-XX:+UseCMSInitiatingOccupancyOnly ： 直接使用设定的CMSInitiatingOccupancyFraction的值，还是虚拟机用更加复杂的方式计算出来开启占比？设置成true，直接使用。默认是false，虚拟机计算。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<pre><code>- 使用更多的后台回收线程
&gt;每个CMS后台线程都会100%的占用机器上的一个CPU，如果应用并发模式失效，并且又有额外的CPU周期可用，可以设置-XX:ConcGCThreads=N标志，增加后台线程数目。默认情况下:ConcGCThreads = (3 + ParallelGCThreads) / 4;
&gt;&gt; 为什么每个CMS线程都独占一个CPU？
&gt;&gt; 其实这个不难理解，如果不是独占CPU的话，和别的应用程序公用，会出现资源竞争，会导致CMS线程的lose its race (失速)。
</code></pre><ol>
<li>针对永久代的调优<br> 默认情况下CMS不会对永久代进行垃圾回收，但是我们可以设置成与老年代同样的方式进行回收。<ul>
<li>开启 -XX:+CMSPermGenSweepingEnabled ： 该值默认是关闭的，开启后会启动与老年代一样的处理方式，但是使用的CPU和触发标志都是跟老年代<strong>独立</strong>的</li>
<li>-XX:CMSInitiatingPermOccupancyFraction=N  ： 设置占比达到多少时开启收集线程，默认是80(80%)</li>
<li>-XX:+CMSClassUnloadingEnabled ： 开启释放不再被引用的类，默认只能释放少量的无效对象，类的元数据并不会被释放，只有开启之后才能释放类的元数据。<blockquote>
<p>java8中CMSClassUnloadingEnabled值默认是开启的。</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h3 id="G1-Garbage-First-收集器"><a href="#G1-Garbage-First-收集器" class="headerlink" title="G1(Garbage-First)收集器"></a>G1(Garbage-First)收集器</h3><p>G1：Garbage-First，顾名思义，会先收集垃圾最多的分区(region)。分区既可以归属老年代，也可以归属新生代(在使用的时候谁申请就分配给谁)，默认分区2048个，同一个代的分区不需要保持连续。</p>
<ul>
<li><strong>新生代</strong>：其实没有绝对的必要分区，因为新生代进行垃圾回收时整个新生代空间要么被回收要么被晋升(移动到Survivor或者老年代)。采用分区的原因是可以方便的调整代的大小。</li>
<li><strong>老年代</strong>：可以把大的区域拆分，这样每次都关注垃圾最多的区域，降低花费时间。</li>
</ul>
<p>G1收集器的收集活动主要包含4种操作：</p>
<ol>
<li>新生代垃圾收集；</li>
<li>后台收集，并发周期；</li>
<li>混合式垃圾收集；</li>
<li>必要时的FullGc。</li>
</ol>
<h4 id="G1分区的大小"><a href="#G1分区的大小" class="headerlink" title="G1分区的大小"></a>G1分区的大小</h4><p>分区大小不是动态变化的，具体值在启动的时候依据堆得大小的最小值得出，分区大小的最小值是1MB。如果堆得最小值超过2GB：</p>
<p>分区大小 = 1 &lt;&lt; log(初始堆的大小/2048) //使用基数为2取log的算法</p>
<p>分区大小是2的最小的N次幂，并使其结果接近2048个分区</p>
<blockquote>
<p>分区限制：最小值1MB，最大值32MB</p>
<p>可以使用-XX:G1HeapRegionSize=N设置值，N应该是2的幂，否则会向下取整到最近的2的幂。</p>
</blockquote>
<h4 id="新生代垃圾收集"><a href="#新生代垃圾收集" class="headerlink" title="新生代垃圾收集"></a>新生代垃圾收集</h4><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/g1-young.jpg" alt="G1的新生代回收示意图"></p>
<p>注：每一个小方块代表一个G1分区，黑色分区代表数据，[E]代表Eden、[O]代表老年代、[S]代表Survivor。</p>
<blockquote>
<p>虽然Eden以及Survivor是按照区块分配的，但是Eden和Survivor区的格式还是像之前的内存格式，大小也是固定的。不要以为还有空闲的分区就能无限申请内存分配给Eden区或者Survivor区。</p>
</blockquote>
<ul>
<li><strong>空的区域不属于任何一个代，需要的时候G1收集器会强制指定这些空的分区用于任何需要的代。</strong></li>
</ul>
<p>Eden空间耗尽会触发G1垃圾收集器进行新生代垃圾收集(示意图中6个Eden分区)，新生代收集之后不会立刻又Eden区分配，但是会至少有一个Survivor区。<br>这里同样存在如果Survivor区扣减被填满，无法容纳的对象也会直接晋升到老年代。</p>
<h4 id="并发G1垃圾收集周期"><a href="#并发G1垃圾收集周期" class="headerlink" title="并发G1垃圾收集周期"></a>并发G1垃圾收集周期</h4><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/g1-curr.jpg" alt="G1的并发收集示意图"></p>
<p>注：一些分区被标注了X，他们就是标记周期找到的包含最多垃圾的分区(优先清理垃圾最多的区)。</p>
<ul>
<li>示意图中新生代发生变化：说明在并发周期内至少有一次新生代GC。 </li>
<li>X标注的区域属于老年代，同时依然保持有数据。 </li>
<li>老年代(O和X),在标记周期结束后可能会变得更大，新生代有对象会晋升到老年代。</li>
</ul>
<p>下面来看一下并发周期包含哪些阶段，每个阶段都有哪些需要注意的点：</p>
<ul>
<li>初始-标记(initial-mark) ： 会暂停所有应用线，这里的实现是重用了新生代GC周期完成这部分工作，因此<strong>会做一次新生代收集</strong>工作。</li>
<li>扫描根分区(root region) ： 并发运行，但是<strong>不能发送新生代收集</strong>，如果有新生代收集必须等待扫描结束才能继续新生代收集，会造成新生代收集停顿耗时更长。</li>
<li>并发标记(concurrent mark) ： 完全在后台进行，开始和完成分别会刷出一行日志，[GC concurrent-mark-start] 和 [GC concurrent-mark-end,6.3345 sec] ,可以被新生代GC中断。</li>
<li>重新标记(remarking) ： 暂停所有应用。</li>
<li>清理 ： 暂停所有应用。</li>
<li>并发清理</li>
</ul>
<p>通过上面几个步骤，垃圾的定位就完成了(会清理很少的垃圾，主要是定位垃圾最多的分区，也就是X区)。</p>
<h4 id="混合式垃圾回收-mixed-GC"><a href="#混合式垃圾回收-mixed-GC" class="headerlink" title="混合式垃圾回收(mixed GC)"></a>混合式垃圾回收(mixed GC)</h4><p>混合式垃圾回收：不仅进行正常的新生代垃圾收集，同时也会回收部分后台扫描线程标记的分区。<br><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/g1-gc.jpg" alt="G1的混合GC示意图"></p>
<p>注：G1收集器已经清空了Eden空间，同时调整了Survivor空间，并且三个标记X的分区也被回收，活跃数据移动到另外一个分区(减低了磁盘碎片化问题)。</p>
<ul>
<li>混合式垃圾回收周期会持续运行直到所有标记的分区都被回收，然后G1收集器恢复正常的新生代垃圾回收周期，并重新开启一轮并发周期，标记下一次哪些区域需要垃圾释放。</li>
</ul>
<h4 id="FullGC-2"><a href="#FullGC-2" class="headerlink" title="FullGC"></a>FullGC</h4><p>G1垃圾收集器在什么时候回启动FullGC？</p>
<ul>
<li><p>并发模式失败</p>
<blockquote>
<p>老年代在标记周期完成之前就被填满，放弃标记周期</p>
</blockquote>
<pre><code>234.34: [GC concurrent-mark-start]
245.23: [Full GC 4095M-&gt;1395M(4096M),8.12322 secs]
        [Times: user=6.40 sys=0.00 real=8.12 secs]
254.34: [GC concurrent-mark-abort]
</code></pre><blockquote>
<p>出现这种情况可以通过一下手段解决：</p>
<ul>
<li>增加堆得大小</li>
<li>更早开启后台处理</li>
<li>增加后台处理的线程数</li>
</ul>
</blockquote>
</li>
<li>晋升失败<blockquote>
<p>完成标记阶段，开始启动混合垃圾回收，清理老年代的分区，但是老年代空间在垃圾回收释放出足够内存之前，内存被耗尽。</p>
<p>日志中可以看到在混合GC之后立刻一次FullGC</p>
</blockquote>
</li>
<li><p>疏散失败</p>
<blockquote>
<p>进行新生代垃圾收集时，Survivor区和老年代没有足够的空间容纳所有的幸存对象。</p>
</blockquote>
<pre><code>345.33: [GC pause (young) (to-space overflow), 0.823456700 secs]
</code></pre><blockquote>
<p>表明堆已经用尽或者碎片化。最简单的就是增加堆大小</p>
</blockquote>
</li>
<li>巨型对象分配失败<blockquote>
<p>分配大于分区的对象的时候，需要在老年代找几个连续的空闲分区，如果找不到，就只能进行fullGC，所以尽量避免分配巨型对象。</p>
</blockquote>
</li>
</ul>
<h4 id="调优-2"><a href="#调优-2" class="headerlink" title="调优"></a>调优</h4><p>目标：避免发生并发模式失败或者疏散失败，减少收集过程中的停顿时间最小化。可调优选项</p>
<ul>
<li>通过增加总的堆空间大小或者调整老年代、新生代之间的比例来增加老年代空间的大小(调整比例不推荐，频繁新生代GC，遇到扫描根区分还要等待).</li>
<li>增加后台线程数目(在有足够CPU资源的情况下).</li>
<li>以更高的频率进行G1的后台垃圾收集活动。</li>
<li>在混合式垃圾回收周期内完成更多的垃圾收集工作。</li>
</ul>
<p>最简单的调优方案：设置-XX:MaxGCPauseMillis=N。默认值200ms</p>
<blockquote>
<p>如果G1收集器发生STW的时长购过该值，G1收集器会尝试弥补：弥补的方法是尝试上面四种方式。<br>如果还是不能避免FullGC的情况下，可以按实际情况调整下面的值：</p>
<ul>
<li>调整后台线程数-XX:ConcGCThreads=N。默认的计算公式 ConcGCThreads = (ParalleGCThreads + 2) /4 (跟CMS收集很像是吧是？)</li>
<li>调整G1垃圾收集器运行的频率。-XX:InitiatingHeapOccupancyPercent=N,默认45(45%),和CMS不一样的是这里的基数是整个堆大小，而不是像CMS那样只有老年代的大小。</li>
<li>调整G1收集器的混合式垃圾收集周期。-XX:G1MixedGCCountTarget=N,G1垃圾收集回收分区时的最大混合式GC的周期数。默认8，减少可以帮助解决晋升失败的问题，代价是停顿时间更长。</li>
</ul>
</blockquote>
<pre><code>----------------    --------华丽的分割线--------------------------
</code></pre><h2 id="高级调优"><a href="#高级调优" class="headerlink" title="高级调优"></a>高级调优</h2><h3 id="晋升以及Survivor空间"><a href="#晋升以及Survivor空间" class="headerlink" title="晋升以及Survivor空间"></a>晋升以及Survivor空间</h3><p>新生代划分为一个Eden空间和两个Survivor空间的原因，让更多的对象在新生代内有更多的机会被回收。</p>
<pre><code>Eden-&gt;S0 //第一次
Eden + S0 -&gt; S1 //第二次
Eden + S1 -&gt; S0 //第三次  
Eden + S0 -&gt; S1 //第四次
Eden + S1 -&gt; S0 //第五次  
...
//如此循环。
</code></pre><ul>
<li>什么时候对象会进入老年代？<blockquote>
<ul>
<li><p>Survivor不足以保存该次新生代GC中存活下来的对象的时候。</p>
<blockquote>
<p>-XX:InitialSurvivorRatio=N,调整Survivor空间的值。 survivor_space_size = new_size / (initial_survivor_ratio + 2)默认initial_survivor_ratio=8，所以每一个Survivor占比10%。</p>
<p>可以设置Survivor为某一个固定值：-XX:SurvivorRatio=N。同时需要关闭自动调整，-XX:-UseAdaptiveSizePolicy。</p>
</blockquote>
</li>
<li><p>在Survivor经历了多个GC周期达到晋升阈值的时候。 </p>
<blockquote>
<p>-XX:InitialTenuringThreshold=N,设置晋升阈值(Throughput和G1默认:7，CMS默认是:6)</p>
<p>-XX:MaxTenuringThreshold=N，最大晋升阈值(Throughput和G1默认:15，CMS默认是:6)</p>
<p>注：修改这个值要考虑一直不晋升造成的直接进入老年代问题，或者一直直接晋升进入老年代问题。</p>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
<p>结：<br>如果Survivor过小，对象会直接晋升到老年代，从而触发更多的老年代GC，增加堆(至少增加新生代)的大小是最好的解决办法</p>
<h3 id="分配大对象"><a href="#分配大对象" class="headerlink" title="分配大对象"></a>分配大对象</h3><h4 id="TLAB"><a href="#TLAB" class="headerlink" title="TLAB"></a>TLAB</h4><p>TLAB：Thread Local Allocation Buffer 线程本地分配缓冲区<br>Eden区中对象分配速度更快的原因就是因为每个线程都有一个固定的TLAB用于分配对象，这样就不需要在线程间同步。<br>TLAB的大小由三个因素决定</p>
<ul>
<li>应用程序的线程数</li>
<li>Eden空间的大小</li>
<li>线程的分配率</li>
</ul>
<p>哪些程序会受益于TLAB？</p>
<ul>
<li>需要分配大量巨型对象的应用程序</li>
<li>相对于Eden空间的大小而言，应用程序线程数量过多的应用<blockquote>
<p>TLAB默认是开启的，-XX:-UseTLAB可以关闭，不够考虑到TLAB带来的性能提升，最好还是不要关闭了。</p>
</blockquote>
</li>
</ul>
<p>因为TLAB的大小基于线程的分配率，所以不太可能准确预测应用程序的TLAB的大小，但是可以监控TLAB的分配情况，如果有大量对象分配发生在TLAB之外，可以减小分配对象的大小，或者调整TLAB的参数。</p>
<blockquote>
<p>JFR可以监控TLAB的分配情况。</p>
<p>-XX:PrintTLAB标志可以在新生代GC的日志中找到相应的TLAB信息</p>
</blockquote>
<h4 id="调整TLAB"><a href="#调整TLAB" class="headerlink" title="调整TLAB"></a>调整TLAB</h4><ol>
<li>增大Eden空间TLAB的值会自动增大</li>
<li>-XX:TLABSize=N可以显式的设置TLAB的大小，为了避免每次GC的时候都调整TLAB的大小，-XX:-ResizeTLAB关闭重设大小。</li>
</ol>
<h4 id="巨型对象"><a href="#巨型对象" class="headerlink" title="巨型对象"></a>巨型对象</h4><p>对于TLAB空间无法分配的对象，JVM会尽量尝试在Eden空间中进行分配，如果Eden空间无法容纳该对象，就只能在老年代中分配空间。G1收集器，超过分区的话也只能在老年代分配空间。</p>
<h2 id="很low的调优线路图"><a href="#很low的调优线路图" class="headerlink" title="很low的调优线路图"></a>很low的调优线路图</h2><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-gc/gc.jpg" alt="GC调优线路图"></p>
]]></content>
    
    <summary type="html">
    
      hotspot作为sun公司对于jvm的实现，采用了什么思路，这一思路下各个部分是怎么样实现垃圾回收的？又有哪些GC策略？每种gc策略之间有什么区别？我们的应用又该怎么样选择gc策略？每一种gc策略要怎么样进行调优，需要关注那些调优点？对于这些问题我们来一起说道说道。
    
    </summary>
    
      <category term="java" scheme="http://gamesdoa.com/categories/java/"/>
    
    
      <category term="java" scheme="http://gamesdoa.com/tags/java/"/>
    
      <category term="jvm" scheme="http://gamesdoa.com/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>hotspot类加载机制分析</title>
    <link href="http://gamesdoa.com/hotspot-classloader.html"/>
    <id>http://gamesdoa.com/hotspot-classloader.html</id>
    <published>2017-06-09T16:00:00.000Z</published>
    <updated>2017-06-28T04:23:58.567Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是类加载"><a href="#什么是类加载" class="headerlink" title="什么是类加载"></a>什么是类加载</h2><p>类的加载指的是将类的class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且提供了访问方法区内的数据结构的接口。</p>
<h2 id="类加载的时机"><a href="#类加载的时机" class="headerlink" title="类加载的时机"></a><span id="jump">类加载的时机</span></h2><p>什么情况下需要开发类的加载过程，java虚拟机规范中并没有进行强制约束，但是对于初始化阶段，虚拟机规范有严格的规定：</p>
<ul>
<li>遇到new、getstatic、putstatic或者invokestatic这4条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。</li>
<li>使用java.lang.reflect包的方法对类进行发射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。</li>
<li>当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。</li>
<li>当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个主类。</li>
<li>当使用JDK1.7的动态语言支持时，如果一个java.lang.invoke.MrthodHandle实例最后的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄时，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。</li>
</ul>
<blockquote>
<p>注：当一个类在初始化时，要求其父类全部都已经初始化过了，但是一个接口在初始化时，并不需要其父接口全部完成了初始化，只有在真正使用到父接口的时候才会初始化。</p>
</blockquote>
<h2 id="类加载的过程"><a href="#类加载的过程" class="headerlink" title="类加载的过程"></a>类加载的过程</h2><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-classloader/class%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.jpg" alt="类加载的过程"></p>
<p>类的生命周期包括：加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)、卸载(Unloading) 7个阶段，其中验证、准备、解析3个部分统称为连接(Linking)。</p>
<p>类加载的过程包括了<font color="#FF0000">加载、验证、准备、解析、初始化</font>五个阶段。在这五个阶段中，<strong>加载、验证、准备和初始化</strong>这四个阶段发生的顺序是确定的，而<strong>解析阶段</strong>则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。</p>
<h3 id="加载"><a href="#加载" class="headerlink" title="加载"></a>加载</h3><p>加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下3件事情：</p>
<ul>
<li>通过一个类的全限定名来获取定义此类的二进制字节流。</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。</li>
<li>在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。</li>
</ul>
<blockquote>
<p>注：相对于类加载过程的其他阶段，一个非数组类的加载阶段(准确的说，是类加载阶段中获取类的二进制字节流的动作)是开发人员可控性最强的，因为加载阶段既可以使用系统提供的引导类加载器来完成，也可以由用户自定义的类加载器去完成，开发人员可以通过定义自己的类加载器去控制字节流的获取方式（重写类加载器的loadClass()方法）。</p>
<p>加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，然后在内存中实例化一个java.lang.Class类的对象，针对hotspot虚拟机而言，Class对象比较特殊，虽然是对象但是存放在方法区里面，这个对象将作为程序访问方法区中的这些类型数据的外部入口。</p>
</blockquote>
<h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><p>验证是连接阶段的第一步，目的：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。</p>
<p>从整体上看，验证阶段大致需要完成以下4个阶段的检验动作：</p>
<ul>
<li><p>文件格式验证</p>
<blockquote>
<p>验证字节流是否符合Class文件格式的规范，保证输入的字节流能正确的解析并存储于方法区之内，只有通过了这个阶段的验证后，字节流才会进入内存的方法区进行存储，后面3个验证阶段全部是基于方法区的存储结构进行的。</p>
</blockquote>
</li>
<li><p>元数据验证</p>
<blockquote>
<p>对字节码描述的信息进行语义分析，以保证其描述的信息符合java语义规范的要求</p>
</blockquote>
</li>
<li><p>字节码验证</p>
<blockquote>
<p>通过数据流和控制流分析，确定程序语义是合法的符合逻辑的，对类的方法进行校验分析，确保被验证类的方法在运行时不会做出危害虚拟机安全的事件。</p>
</blockquote>
</li>
<li><p>符号引用验证</p>
<blockquote>
<p>发生在虚拟机将符合引用转化成直接引用的时候，动作发生在连接的第三个阶段<strong>解析</strong>，验证对类本身以外(常量池中的各种符号引用)的信息进行匹配性校验。</p>
</blockquote>
<p>  注：验证阶段对于虚拟机的类加载机制上一个非常重要但不是一定必要的阶段(对程序运行期没有影响)，<br>  对于进过反复验证的代码可以在启动的时候使用-Xverify:none参数关闭大部分的类验证，以缩短虚拟机类加载时间。</p>
</li>
</ul>
<h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。</p>
<ul>
<li>内存分配只包括类变量(static)，而不包括实例变量，实例变量将会随着对象一起分配在java堆中</li>
<li>通常情况下数据类型赋值为零值，除非使用了static final标示一个变量，才会在这一阶段直接赋值。<blockquote>
<p>public static int value = 10;//准备阶段过后初始值为0，而不是10</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>public static final int value = 10；//准备阶段过后初始值为10</p>
</blockquote>
<h4 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h4><p>虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。</p>
<ul>
<li><p>符号引用:符号可以是任何形式的字面量，与虚拟机内存布局无关，并且引用的目标并不一定已经加载到内存中。</p>
</li>
<li><p>直接引用:直接指向目标的指针，相对偏移量或者一个能间接定位到目标的句柄。与虚拟机内存布局相关，并且目标必然已经存在内存中。</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>执行类构造器<clinit>()方法的过程，并为静态变量赋予正确的初始值，在Java中对类变量进行初始值设定有两种方式：</clinit></p>
</li>
<li><p>声明类变量是指定初始值</p>
</li>
<li>使用静态代码块为类变量指定初始值</li>
</ul>
<blockquote>
<p>JVM初始化步骤</p>
<ol>
<li><p>假如这个类还没有被加载和连接，则程序先加载并连接该类</p>
</li>
<li><p>假如该类的直接父类还没有被初始化，则先初始化其直接父类</p>
</li>
<li><p>假如类中有初始化语句，则系统依次执行这些初始化语句</p>
</li>
</ol>
</blockquote>
<p>类初始化时机：<a href="#jump">见文第二部分,点击跳转</a></p>
<h2 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h2><p>定义：通过一个类的全限定名来获取描述此类的二进制字节流的动作放在虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类，这个动作的代码模块称为“类加载器”。</p>
<p>类唯一性：由加载它的类加载器和类本身一同才能确定唯一性，因为每个类加载器都拥有独立的类名称空间，所以比较两个类是否相等，需要由同一个类加载器加载为前提，否则两个类即使来源同一个class文件也必定不相等。</p>
<blockquote>
<p>注：相等包括Class对象的equals()、isAssignableFrom()方法、isInstance()方法的返回结果，还有instanceof关键字对象所属关系判定等情况。</p>
</blockquote>
<h3 id="类加载"><a href="#类加载" class="headerlink" title="类加载"></a>类加载</h3><p><strong>类加载机制：</strong></p>
<blockquote>
<ul>
<li><p>全盘负责:当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入</p>
</li>
<li><p>父类委托:先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类(<a href="#pdm">详情查看双亲委派模型</a>)</p>
</li>
<li><p>缓存机制:缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效</p>
</li>
</ul>
</blockquote>
<p><strong>类加载有三种方式</strong>：</p>
<ol>
<li>命令行启动应用时候由JVM初始化加载</li>
<li>通过Class.forName()方法动态加载</li>
<li><p>通过ClassLoader.loadClass()方法动态加载</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.gamesdoa.classLoader;</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClassLoaderTest</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ClassNotFoundException </span>&#123;</div><div class="line">        ClassLoader loader = ClassLoaderTest.class.getClassLoader();</div><div class="line">        System.out.println(loader);</div><div class="line">        <span class="comment">//使用ClassLoader.loadClass()来加载类，不会执行初始化块</span></div><div class="line">        Class t = loader.loadClass(<span class="string">"com.gamesdoa.classLoader.Test2"</span>);</div><div class="line">        <span class="comment">//使用Class.forName()来加载类，默认会执行初始化块</span></div><div class="line">        <span class="comment">//Class t = Class.forName("com.gamesdoa.classLoader.Test2");</span></div><div class="line">        <span class="comment">//使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块</span></div><div class="line">        <span class="comment">//Class t = Class.forName("com.gamesdoa.classLoader.Test2", false, loader);</span></div><div class="line">        System.out.println(t);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test2</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        System.out.println(<span class="string">"我被执行了！"</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ol>
<p><strong>Class.forName()和ClassLoader.loadClass()区别</strong></p>
<table>
<thead>
<tr>
<th>Class.forName()</th>
<th style="text-align:left">ClassLoader.loadClass()</th>
</tr>
</thead>
<tbody>
<tr>
<td>将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块</td>
<td style="text-align:left">将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。</td>
</tr>
</tbody>
</table>
<blockquote>
<p>注： Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。</p>
</blockquote>
<h3 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="*双亲委派模型"></a>*双亲委派模型</h3><p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-classloader/%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%E6%A8%A1%E5%9E%8B%E5%AE%8C%E6%95%B4%E7%89%88.jpg" alt="双亲委派模型"></p>
<blockquote>
<font color="#FF0000">注:这里类加载器之间的父子关系不是以继承的关系来实现，而是使用组合关系来复用父加载器的代码</font>

</blockquote>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> Class&lt;?&gt; loadClass(String name) <span class="keyword">throws</span> ClassNotFoundException &#123;</div><div class="line">       <span class="keyword">return</span> loadClass(name, <span class="keyword">false</span>);</div><div class="line">   &#125;</div><div class="line"></div><div class="line"><span class="keyword">protected</span> Class&lt;?&gt; loadClass(String name, <span class="keyword">boolean</span> resolve)</div><div class="line">       <span class="keyword">throws</span> ClassNotFoundException</div><div class="line">   &#123;</div><div class="line">       <span class="keyword">synchronized</span> (getClassLoadingLock(name)) &#123;</div><div class="line">           <span class="comment">// First, check if the class has already been loaded</span></div><div class="line">		<span class="comment">//首先，检查类是否已经被加载</span></div><div class="line">           Class&lt;?&gt; c = findLoadedClass(name);</div><div class="line">           <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;<span class="comment">//如果没有被加载，就委托给父类加载或者委派给启动类加载器加载</span></div><div class="line">               <span class="keyword">long</span> t0 = System.nanoTime();</div><div class="line">               <span class="keyword">try</span> &#123;</div><div class="line">                   <span class="keyword">if</span> (parent != <span class="keyword">null</span>) &#123;<span class="comment">//父类不为null，也就是父类不是启动类加载器，委托给父类加载器加载</span></div><div class="line">                       c = parent.loadClass(name, <span class="keyword">false</span>);</div><div class="line">                   &#125; <span class="keyword">else</span> &#123;<span class="comment">//父类为null，也就是父类是启动类加载器，检查是否满足启动类加载器限制，满足则委托给启动类加载器加载，否则返回null</span></div><div class="line">                       c = findBootstrapClassOrNull(name);</div><div class="line">                   &#125;</div><div class="line">               &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</div><div class="line">                   <span class="comment">// ClassNotFoundException thrown if class not found</span></div><div class="line">                   <span class="comment">// from the non-null parent class loader</span></div><div class="line">               &#125;</div><div class="line"></div><div class="line">               <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;<span class="comment">//如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能</span></div><div class="line">                   <span class="comment">// If still not found, then invoke findClass in order</span></div><div class="line">                   <span class="comment">// to find the class.</span></div><div class="line">                   <span class="keyword">long</span> t1 = System.nanoTime();</div><div class="line">                   c = findClass(name);</div><div class="line"></div><div class="line">                   <span class="comment">// this is the defining class loader; record the stats</span></div><div class="line">                   sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);</div><div class="line">                   sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);</div><div class="line">                   sun.misc.PerfCounter.getFindClasses().increment();</div><div class="line">               &#125;</div><div class="line">           &#125;</div><div class="line">           <span class="keyword">if</span> (resolve) &#123;</div><div class="line">               resolveClass(c);</div><div class="line">           &#125;</div><div class="line">           <span class="keyword">return</span> c;</div><div class="line">       &#125;</div><div class="line">   &#125;</div></pre></td></tr></table></figure>
</code></pre><p><strong><span id="pdm">双亲委派的工作过程</span></strong>：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类，当最终的加载器加载失败时则会报出异常ClassNotFoundException。</p>
<p><strong>双亲委派模型目的</strong></p>
<ul>
<li><p>系统类防止内存中出现多份同样的字节码</p>
</li>
<li><p>保证Java程序安全稳定运行</p>
</li>
<li><p>隔离不同加载器加载到的类对象</p>
</li>
</ul>
<p><strong>自定义类加载</strong>：当遇到类似以下情况的时候，需要自定义类加载：</p>
<ol>
<li>在执行非信任代码之前，自动验证数字签名。</li>
<li>动态地创建符合用户特定需要的定制化构建类。</li>
<li>从特定的场所取得java class，例如数据库中和网络，尤其是还需要对数据进行解密等操作的情况下。</li>
</ol>
<blockquote>
<p>自定义类加载器一般都是继承自 ClassLoader 类，只需要重写 findClass 方法即可，如果不是因为特殊目的一般不要重写loadClass方法，因为这样容易破坏双亲委托模式。</p>
</blockquote>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.gamesdoa.classLoader;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.ByteArrayOutputStream;</div><div class="line"><span class="keyword">import</span> java.io.File;</div><div class="line"><span class="keyword">import</span> java.io.FileInputStream;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.InvocationTargetException;</div><div class="line"><span class="keyword">import</span> java.lang.reflect.Method;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyClassLoader</span> <span class="keyword">extends</span> <span class="title">ClassLoader</span> </span>&#123;</div><div class="line">    <span class="keyword">private</span> String classpath;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyClassLoader</span><span class="params">(String classpath)</span></span>&#123;</div><div class="line">        <span class="keyword">this</span>.classpath = classpath;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="meta">@Override</span></div><div class="line">    <span class="keyword">public</span> Class&lt;?&gt; findClass(String name)&#123;</div><div class="line">        <span class="keyword">byte</span>[] data = loadClassData(name);</div><div class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.defineClass(name , data , <span class="number">0</span> , data.length);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">byte</span>[] loadClassData(String name)&#123;</div><div class="line">        System.out.println(<span class="string">"加载"</span>+name);</div><div class="line">        <span class="keyword">try</span>&#123;</div><div class="line">            name = name.replace(<span class="string">"."</span> , <span class="string">"//"</span>);</div><div class="line">            FileInputStream is = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(classpath + name + <span class="string">".class"</span>));</div><div class="line">            ByteArrayOutputStream baos = <span class="keyword">new</span> ByteArrayOutputStream();</div><div class="line">            <span class="keyword">int</span> b = <span class="number">0</span> ;</div><div class="line">            <span class="keyword">while</span>((b = is.read()) != -<span class="number">1</span>)&#123;</div><div class="line">                baos.write(b);</div><div class="line">            &#125;</div><div class="line">            is.close();</div><div class="line">            <span class="keyword">return</span> baos.toByteArray();</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e)&#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InstantiationException, IllegalAccessException,</span></div><div class="line">            ClassNotFoundException, NoSuchMethodException, SecurityException, IllegalArgumentException,</div><div class="line">            InvocationTargetException &#123;</div><div class="line">        MyClassLoader myLoader = <span class="keyword">new</span> MyClassLoader(<span class="string">"E:/"</span>);</div><div class="line"></div><div class="line"></div><div class="line">        Class&lt;?&gt; clazz = myLoader.loadClass(<span class="string">"com.gamesdoa.classLoader.Apple"</span>);</div><div class="line">        Class&lt;?&gt; clazz1 = myLoader.loadClass(<span class="string">"com.gamesdoa.classLoader.Apple"</span>);</div><div class="line">        System.out.println(clazz == clazz1);</div><div class="line">        System.out.println(clazz.getClassLoader());</div><div class="line">        System.out.println(clazz1.getClassLoader());</div><div class="line"></div><div class="line">        System.out.println(<span class="string">"================"</span>);</div><div class="line"></div><div class="line">        MyClassLoader myLoader1 = <span class="keyword">new</span> MyClassLoader(<span class="string">"E:/"</span>);</div><div class="line">        Class&lt;?&gt; clazz2 = myLoader1.loadClass(<span class="string">"com.gamesdoa.classLoader.Apple"</span>);</div><div class="line">        System.out.println(clazz2 == clazz1 );</div><div class="line">        System.out.println(clazz2.getClassLoader());</div><div class="line"></div><div class="line">        System.out.println(<span class="string">"================"</span>);</div><div class="line"></div><div class="line">        Object newInstance = clazz.newInstance();</div><div class="line">        Method declaredMethod = clazz.getDeclaredMethod(<span class="string">"say"</span>, <span class="keyword">new</span> Class[]&#123;&#125;);</div><div class="line">        declaredMethod.invoke(newInstance, <span class="keyword">new</span> Object[]&#123;&#125;);</div><div class="line">    &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Apple</span> </span>&#123;</div><div class="line">    <span class="keyword">static</span>&#123;</div><div class="line">        System.out.println(<span class="string">"int Apple"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">say</span><span class="params">()</span></span>&#123;</div><div class="line">        System.out.println(<span class="string">"I am a apple.."</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</code></pre><blockquote>
<p>这个类本身可以被 AppClassLoader 类加载，因此我们不能把 com/gamesdoa/classLoader/MyClassLoader.class 放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由 AppClassLoader 加载，而不会通过我们自定义类加载器来加载。</p>
</blockquote>
<h3 id="破坏双亲委派模型-OSGI"><a href="#破坏双亲委派模型-OSGI" class="headerlink" title="破坏双亲委派模型(OSGI)"></a>破坏双亲委派模型(OSGI)</h3><p>双亲委派模型出现过3次大规模的“被破坏”情况</p>
<ul>
<li>双亲委派模式出现之前：JDK1.2之前</li>
<li>线程上下文类加载器(Thread Context ClassLoader): 基础类又要调用回用户的代码(JNDI、JDBC、JCE、JAXB、JBI等)</li>
<li>用户对于程序动态性的追求:代码热替换(HotSwap)、模块热部署(Hot Deploment)等</li>
</ul>
<p><strong>OSGI(Open Service Gateway Initiative)</strong>：java模块化标准：每一个程序模块(OSGI中称Bundle)都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换。因此在OSGI环境中类加载器发展为复杂的网状结构。下面来分析一下这个类加载器模型。</p>
<p><strong>OSGI各个Bundle类加载之间的规则：</strong></p>
<ul>
<li>某个Bundle声明了一个它依赖的Package，如果有其他Bundle声明发布了这个Package，那么所有对于这个Package的类加载动作都会委派给发布它的Bundle类加载器去完成。</li>
<li>不涉及某个具体Package时，各个Bundle加载器都是平级关系，只有具体使用某个Package和Class的时候，才会根据Package导入导出定义来构造Bundle间的委派和依赖。</li>
<li>一个Bundle类加载器为其他Bundle提供服务时，会根据Export-Package列表严格控制访问范围。一个类存在于Bundle的类库但是没有被Export，那么这个Bundle的类加载器能找到这个类，但是不会提供给其他Bundle使用，而且OSGI平台也不会把其他Bundle的类加载请求分配给这个Bundle来处理。</li>
</ul>
<p><strong>OSGI类加载器架构：</strong></p>
<p><img src="https://github.com/gamesdoa/img0/raw/master/java/hotspot-classloader/OSGI%E7%9A%84%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%E6%9E%B6%E6%9E%84.jpg" alt="OSGI类加载器架构"></p>
<p><strong>OSGI类加载时查找规则如下：</strong></p>
<ul>
<li>以java.* 开头的类，委派给父类加载器加载。</li>
<li>否则，委派列表名单内的类，委派给父类加载器加载。</li>
<li>否则，Import 列表中的类，委派给Export这个类的Bundle的类加载器加载。</li>
<li>否则，查找当前Bundle 的 Classpath，使用自己的类加载器加载。</li>
<li>否则，查找是否在自己的 Fragement Bundle 中，如果是，则委派给 Fragment Bundle 的类加载器加载</li>
<li>否则，查找Dynamic Import 列表的 Bundle， 委派给对应Bundle的类加载器加载。</li>
<li>否则，查找失败。</li>
</ul>
<blockquote>
<p>注：OSGI的Bundle相互引用有可能会造成死锁，因为当前类加载器在实例对象时需要先锁定，java.lang.ClassLoader.loadClass()方法是一整个synchronized块。当BundleA依赖PackageB,同时BundleB依赖PackageA时可能会死锁。</p>
<p>loadClass的这个特性也就造就了<strong>饿汉模式</strong>的<strong>单例模式实现</strong></p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      什么是JAVA类加载？JAVA类什么时候类加载？类加载都有哪些过程？类加载机制是怎么样的？双亲委派模型设计特点是怎么样的？有哪些优点？OSGI的类加载器为什么会火？OSGI类加载器原理是怎么样的？来来来一起说道说道。
    
    </summary>
    
      <category term="java" scheme="http://gamesdoa.com/categories/java/"/>
    
    
      <category term="java" scheme="http://gamesdoa.com/tags/java/"/>
    
      <category term="jvm" scheme="http://gamesdoa.com/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>hotspot内存模型分析</title>
    <link href="http://gamesdoa.com/hotspot-jvm.html"/>
    <id>http://gamesdoa.com/hotspot-jvm.html</id>
    <published>2017-05-31T16:00:00.000Z</published>
    <updated>2017-06-28T04:26:35.013Z</updated>
    
    <content type="html"><![CDATA[<p>Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同数据区域。这些区域都有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而存在，有些区域则是依赖用户线程的启动和结束而建立和销毁。先直观的看一下虚拟机内存的划分。<br><img src="https://github.com/gamesdoa/img0/raw/master/java/jvm/jvm.jpg" alt="jvm运行时数据区"></p>
<ul>
<li>Java堆(GC管理的主要区域)</li>
<li>方法区(内含运行时常量池)</li>
<li>程序计数器</li>
<li>虚拟机栈</li>
<li>本地方法栈</li>
<li>直接内存</li>
</ul>
<p>接下来分别看一下各个区域的职责：</p>
<ul>
<li><h2 id="Java堆"><a href="#Java堆" class="headerlink" title="Java堆"></a>Java堆</h2></li>
</ul>
<blockquote>
<ul>
<li>Java堆（java heap）是Java虚拟机所管理的内存中最大的一块</li>
<li>它是被所有线程共享的一块内存区域，在虚拟机启动时创建</li>
</ul>
<p>hotspot虚拟机</p>
<ul>
<li>采用分代收集算法，所以java堆还可以细分为：新生代和老年的以及永久代(Java8的元空间)，新生代又可以分为一个eden空间和两个survivor空间。</li>
<li>内存分配采用TLAB(Thread Local Allocation Buffer) 线程本地分配缓存区，这样在多线程的情况下创建对象速度会有较明显的提升。</li>
</ul>
<p>Java堆是垃圾收集管理的主要区域。根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。</p>
</blockquote>
<ul>
<li><h2 id="方法区-内含运行时常量池"><a href="#方法区-内含运行时常量池" class="headerlink" title="方法区(内含运行时常量池)"></a>方法区(内含运行时常量池)</h2></li>
</ul>
<blockquote>
<ul>
<li><strong>方法区（Method Area）</strong>与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。别名又叫Non-Heap(非堆)</li>
</ul>
<p>在hotspot中这一块又叫做<strong>永久代(Permanent Generation)</strong>:这样的好处是垃圾管理器可以像管理java堆那样管理这一部分内存，但是一般性能不佳，尤其是对于类的卸载条件相当严苛。<em>在JDK1.7中原来存放在永久代的字符串常量池已经从永久代移出</em>。</p>
<p>Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。<br>根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。</p>
<ul>
<li><strong>运行时常量池(Runtime Constant Pool)</strong>：是方法区的一部分，Class文件中除了有关的版本、字段、方法、接口等描述信息外，还有一项信息就是常量池(Constant Pool Table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。<br>运行时常量池另外一个重要特征是具备动态性：运行期间也可能将新的常量放入常量池中，例如：String类的intern()方法。</li>
</ul>
</blockquote>
<ul>
<li><h2 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h2></li>
</ul>
<blockquote>
<ul>
<li>当前线程所执行的字节码行号指示器</li>
<li>字节码解释器工作依赖计数器控制完成</li>
<li>通过执行线程行号记录，让线程轮流切换各条线程之间计数器互不影响</li>
<li>线程私有，生命周期与线程相同，随JVM启动而生，JVM关闭而死</li>
<li>线程执行Java方法时，记录其正在执行的虚拟机字节码指令地址</li>
<li>线程执行Nativan方法时，计数器记录为空（Undefined）</li>
<li>唯一在Java虚拟机规范中没有规定任何OutOfMemoryError情况区域</li>
</ul>
<p>程序计数器（Program Counter Register）是一块较小的内存空间，它可以看做是当前线程所执行的字节码行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。</p>
<p>由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核） 只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响、独立存储，因此需要是“线程私有”的。</p>
<p>如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空 （Undefined）。</p>
</blockquote>
<ul>
<li><h2 id="Java虚拟机栈"><a href="#Java虚拟机栈" class="headerlink" title="Java虚拟机栈"></a>Java虚拟机栈</h2></li>
</ul>
<blockquote>
<ul>
<li>线程私有，生命周期与线程相同</li>
<li>用于存储局部变量、操作栈、动态链接、方法出口</li>
<li>每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</li>
</ul>
<p>Java虚拟机栈（Java Vitual Machine Stacks）也是线程私有的，他的生命周期与线程相同。<br>虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧 （Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。</p>
<p>局部变量表存放了编译器克制的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（Object reference）和字节码指令地址（returnAddress类型）。</p>
<p>在Java虚拟机规范中，对于此区域规定了两种异常状况：</p>
<blockquote>
<ul>
<li><p>如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；</p>
</li>
<li><p>如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。</p>
</li>
</ul>
</blockquote>
<p>对于32位的jvm，默认大小为256kb, 而64位的jvm, 默认大小为512kb,可以通过-Xss设置虚拟机栈的最大值。不过如果设置过大，会影响到可创建的线程数量。</p>
</blockquote>
<ul>
<li><h2 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h2></li>
</ul>
<blockquote>
<p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用非常类似，区别在于虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的Native方法服务。</p>
<p>在hotspot实现中，本地方法栈和虚拟机栈合二为一</p>
</blockquote>
<ul>
<li><h2 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h2></li>
</ul>
<blockquote>
<p>直接内存(Direct Memory) :不是虚拟机运行时数据区的一部分，也不是java虚拟机规范中定义的内存区域，但是有可能导OutOfMemoryError异常。<br>主要使用在NIO(new Input/Output)类，这个类基于通道(Channel)和缓存区(Buffer)的I/O方式，使用Native函数直接分配堆外内存，这样的好处是提高性能，可以预先分配一个大的内存块，使用的时候直接在上面切分，类似TLAB，不需要每次都重新在系统上分配。<br>但是这个区域是不受java堆限制的，所以可能会造成内存溢出。</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      hotspot的内存模型是什么样子的？运行时数据区有哪些部分组成？每个部分都有哪些作用？我们平时工作中常说的GC又是工作在那些部分的？来来来一起说道说道。
    
    </summary>
    
      <category term="java" scheme="http://gamesdoa.com/categories/java/"/>
    
    
      <category term="java" scheme="http://gamesdoa.com/tags/java/"/>
    
      <category term="jvm" scheme="http://gamesdoa.com/tags/jvm/"/>
    
  </entry>
  
  <entry>
    <title>mysql InnoDB redo log 分析</title>
    <link href="http://gamesdoa.com/mysql-innodb-redo-log.html"/>
    <id>http://gamesdoa.com/mysql-innodb-redo-log.html</id>
    <published>2017-05-04T16:00:00.000Z</published>
    <updated>2017-06-28T04:26:02.487Z</updated>
    
    <content type="html"><![CDATA[<h2 id="redo-log简介"><a href="#redo-log简介" class="headerlink" title="redo log简介"></a>redo log简介</h2><p><strong>重做日志（redo log）</strong> 用来实现事物的持久化，即事务ACID中的D。redo log由两部分组成：</p>
<ul>
<li>内存中的redo log buffer 易丢失</li>
<li>外存中的redo log file 持久的</li>
</ul>
<p>InnoDB通过force log at commit机制实现事务的持久化，即当事务commit时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待完成后事务的commit操作才算完成。</p>
<p>redo log基本上是<strong>顺序写</strong>，并且在数据库运行期间不需要对redo log的文件进行读取操作。</p>
<p>为了确保每次日志都写入到redo log file，在每次将redo log buffer写入到redo log file后，InnoDB存储引擎都需要调用一次fsync操作，因为redo log先写入到文件系统缓存，为了确保redo log写入到磁盘，必须进行一次fsync操作，这里也一般是数据库系统的瓶颈。事务TPS取决于磁盘性能。</p>
<blockquote>
<p>参数innodb_flush_log_at_trx_commit可以设置磁盘刷新策略</p>
<ul>
<li>0：事务不强制写入redo log，写入操作仅在master thread中进行完成，而master thread中每一秒进行一次redo log的fsync，因此宕机时有可能丢失最后一秒的数据。</li>
<li>1：InnoDB默认值，每次事务提交都调用fsync操作，保证事务的完整性。</li>
<li>2：事务提交时，redo log写入redo log file，仅写入到文件系统的缓存中，不进行fsync操作。数据库宕机，操作系统不宕机数据不丢失，操作系统宕机会丢失未从文件系统缓存刷新到redo log file那部分的数据。</li>
</ul>
</blockquote>
<pre><code>对于插入50W数据的情况下设置不同值对于插入的速度影响如下
innodb_flush_log_at_trx_commit         执行所用时间
                0                        13.90s
                1                        1m53.11s
                2                        23.37s
</code></pre><h2 id="物理逻辑日志"><a href="#物理逻辑日志" class="headerlink" title="物理逻辑日志"></a>物理逻辑日志</h2><p>不同的数据库系统针对重做日志有不同的实现方式，一般会有以下几种类型</p>
<ul>
<li>物理日志</li>
<li>逻辑日志</li>
<li>物理逻辑日志</li>
</ul>
<p><strong>物理日志(physical logging)</strong>：又称old value-new value logging，该日志是幂等的，保存的是页中发生变化的字节。<strong>问题</strong>是日志产生的量相对较大，例如对页整理的话，日志大小可能为页的大小</p>
<p><strong>逻辑日志</strong>：记录的是对于表的操作，因此日志量很小(基本上是只记录操作语句)。<strong>问题</strong>是恢复时可能无法保证数据的一致性(宕机时可能使数据处于未知状态)。</p>
<p><strong>物理逻辑日志</strong>：设计思路是：physical-to-a-page，logical-within-a-page。也就是对于也是记录物理日志，对于页内的操作是记录逻辑日志，这能很好地结合物理日志和逻辑日志的优点。例如对于页整理，如果使用物理日志形式，日志量需要一个页大小，而使用物理逻辑日志形式，只需要记录页的编号以及日志的类型</p>
<h2 id="LSN-log-sequence-number-日志序列号"><a href="#LSN-log-sequence-number-日志序列号" class="headerlink" title="LSN : log sequence number(日志序列号)"></a>LSN : log sequence number(日志序列号)</h2><p>LSN特点是单调递增，代表每个重做日志的编号，这就意味着每一个日志都有一个LSN与之一一对应。<br>存在于多个对象中，表示的含义各不相同</p>
<ul>
<li>操作日志</li>
<li>页</li>
<li>检查点</li>
</ul>
<p><strong>操作日志</strong>：LSN是事务写入操作日志的字节总量，LSN记录的是操作日志的增量，单位字节。例如当前LSN1000，事务T1产生100字节的操作日志，那么LSN变成1100，事务T2产生200字节的操作日志，那么当前LSN为1300。<strong>InnoDB存储引擎</strong>首先是将重做日志写入到一个缓存中，因此存在已经写入到重做日志缓冲和重做日志文件的两部分LSN信息。</p>
<p><strong>页</strong>：页的头信息中FIL_PAGE_LSN存储的是页的LSN，表示该页最后刷新的LSN大小，由于操作日志记录的是每个页的日志，因此页中的LSN可以用来判断该页是否需要进行恢复操作。例如：页P1的LSN为1000，数据库启动时InnoDB检测到写入重做日志中该页的LSN为1300并且事务已经提交，那么数据库需要进行恢复操作，需要将重做日志应用到P1中。如果重做日志的LSN小于P1页的LSN，则不需要进行重做操作。</p>
<p><strong>检查点</strong>：表示页已经刷新到磁盘的LSN位置，当数据库重启时，仅需要从检查点开始进行恢复操作。若检查点的LSN与操作日志的LSN相同，表示所有页都已经刷新到磁盘，不需要进行恢复操作。这样的好处是减少数据库重启时间。</p>
<pre><code>mysql&gt; SHOW INNODB STATUS\G;
......
---
LOG
---
Log sequence number 0 11347131
Log flushed up to   0 11338553
Log checkpoint at   0 11056147
......
</code></pre><blockquote>
<p>Log sequence number表示重做日志缓冲中已经写入的LSN值，Log flushed up to表示已经刷新到重做日志文件的LSN值，由于重做日志缓冲在master thread中会每秒定期地进行刷新到磁盘的操作，因此两者之间的差距很小。</p>
<p>Log checkpoint at表示最新一次页刷新到磁盘时的LSN。该值与前两个值差距可能比较大。具体原因见下一部分的检查点相关</p>
</blockquote>
<h2 id="检查点"><a href="#检查点" class="headerlink" title="检查点"></a>检查点</h2><p>InnoDB存储引擎采用write ahead log(WAL)策略实现事务的持久性，即当事务提交时，首先将重做日志写入到文件，实际数据页刷新到磁盘的操作由检查点（checkpoint）负责。也就是说事务的日志在事务提交时确定写入到外存，但是缓冲池(buffer pool)中的页并没有刷新到磁盘，<strong>这是因为事务提交时仅仅是把事务操作所涉及页的重做日志都写入到磁盘(顺序写)</strong>。页的刷新时异步的，也就是检查点技术。</p>
<p><strong>检查点的操作</strong>就是将缓冲池中的页刷新到磁盘,最终达到外存和内存中的页的数据一致。</p>
<p><strong>检查点的作用</strong>缩短当数据库发生宕机时数据库恢复所需要的时间。</p>
<p><strong>宕机后的恢复</strong>：检查点的值是根据LSN记录的，当检查点的值是1000，重做日志刷新到的位置为1300，那么1000之后的重做日志需要回放(replay)。也就是说因为有检查点操作回放重做日志只需要进行1000到1300之间的数据，如果没有进行过checkpoint那么需要回放所有的重做日志。</p>
<p>InnoDB中存在两种检查点：</p>
<ul>
<li>sharp checkpoint</li>
<li>fuzzy checkpoint</li>
</ul>
<blockquote>
<p>sharp checkpoint将缓冲池中修改的页(脏页)，全部刷新到磁盘。<strong>优点</strong>是可以大大缩短宕机恢复所需要的时间。<strong>缺点</strong>是在进行sharp checkpoint时不能进行其他的DML操作，生产环境不可接受。</p>
<p>fuzzy checkpoint将缓冲池中修改的页(脏页)，慢慢的刷新回磁盘。<strong>优点</strong>大大提高数据库的可用性，刷新时也可以进行DML操作。<strong>注意项</strong>脏页需要根据第一次被修改时的LSN进行排序，然后将最老的页先刷回到磁盘，也就使得页的刷新和日志的LSN顺序是一样的，从而保证恢复操作的准确性。</p>
</blockquote>
<h2 id="归档日志与恢复"><a href="#归档日志与恢复" class="headerlink" title="归档日志与恢复"></a>归档日志与恢复</h2><ul>
<li><p><strong>归档日志</strong>：InnoDB存储引擎中，重做日志文件的大小是固定的，如果写入的日志大于重做日志文件的固定大小，就需要循环使用重做日志文件，这种方式称为round robin(轮循)。也就意味着之前写入的日志可能被新的日志覆盖，为了保留之前的重做日志，InnoDB存储引擎设计了归档日志，与重做日志文件的内容是完全相同的。</p>
</li>
<li><p><strong>恢复</strong>：InnoDB存储引擎在启动时不管上次数据库是否正常关闭，都会尝试进行恢复操作。重做日志记录的是物理逻辑日志因此恢复起来速度很快，并且InnoDB存储引擎也对恢复进行了优化，采用顺序读取并行应用重做日志方式加速恢复。而且因为有checkpoint技术存在，恢复过程中仅需要恢复checkpoint记录的LSN之后的日志部分，再次加速了恢复过程。</p>
</li>
</ul>
<h2 id="重做日志物理架构"><a href="#重做日志物理架构" class="headerlink" title="重做日志物理架构"></a>重做日志物理架构</h2><p>InnoDB存储引擎中的重做日志由以下几个部分组成</p>
<ul>
<li>重做日志缓存(redo log buffer)</li>
<li>重做日志组(redo log group)</li>
<li>每个重做日志组包含多个重做日志文件(redo log file)</li>
<li>归档重做日志文件</li>
</ul>
<p><img src="https://github.com/gamesdoa/img0/raw/master/mysql/redo-log/redo%E7%89%A9%E7%90%86%E6%9E%B6%E6%9E%84.jpg" alt="重做日志存储结构"></p>
<p>其中重做日志组是完全相同的镜像关系，目的是提高数据库的可用性，当一组中的介质损坏时。InnoDB存储引擎依然能够提供服务，虽然mysql的InnoDB这样设计了重做日志组，但是从源码层面看，其实并不能把重做日志组设置为1以外的值，否则会抛出InnoDB： or a wrong number of mirrored log group导致数据库不能启动，这是因为考虑到InnoDB存储引擎的性能，并且数据本身可以通过RAID保证数据的可靠性造成的。</p>
<p>重做日志文件是round robin(轮循)的多个同样大小的文件，默认前缀ib_logfile，总文件大小不能超过4GB。</p>
<p>归档日志是针对重做日志的备份归档，默认前缀ib_arch<em>log</em>，并且归档只对重做日志组1中的文件进行归档。</p>
<h2 id="重做日志块"><a href="#重做日志块" class="headerlink" title="重做日志块"></a>重做日志块</h2><p>在InnoDB存储引擎中重做日志都是以512字节进行存储的，即重做日志缓存，重做日志文件，归档重做日志都是以块的方式保存的。但是如果一个页中产生的重做日志数量大于512字节，那么就需要分割为多个重做日志块进行存储</p>
<p><strong>重做日志块的大小跟磁盘扇区大小一样</strong>，都是512字节，因此重做日志的写入可以保证原子性，不需要doublewrite技术。</p>
<p><strong>从数据结构看</strong>：重做日志块除了日志本身，还有日志块头和日志块尾两部分，日志头一共占12个字节，日志尾占用8个字节，因此每个日志块其实只能存储492字节的日志。</p>
<h2 id="重做日志组与重做日志文件"><a href="#重做日志组与重做日志文件" class="headerlink" title="重做日志组与重做日志文件"></a>重做日志组与重做日志文件</h2><p>InnoDB存储引擎的重做日志组在源码层面被限定成了一个，因此这里不过多的关注。</p>
<p>重做日志组由多个重做日志文件组成，而重做日志文件存储的是log buffer中保存的log block，因此也是存储的512字节大小的数据块。<br>在InnoDB存储引擎运行期间log buffer根据一定的规则将内存中的log block刷新到磁盘，这里包括：</p>
<ul>
<li>事务提交时</li>
<li>写入检查点值时</li>
<li>当log buffer中有已使用空间超过某个阈值时</li>
</ul>
<p>重做日志组中每个文件的前2KB的部分不存储log block信息，但是在且仅在重做日志组的第一个重做日志文件存储固定的内容，其余文件留空。</p>
<blockquote>
<pre><code>redo log file前2KB部分内容
        存储内容       大小(字节)
    log file header      512
    checkpoint1          512
    空                   512
    checkpoint2          512
</code></pre></blockquote>
<p>当写入log block的时候，需要更新前2KB部分的信息，这就导致了log block的写入不是完全顺序的。</p>
<p>从上面结构中看出<strong>检查点(checkpoint)</strong>有两个字，这个设计是为了避免介质失败，提高可用性。这两个checkpoint block是交替更新，因此在恢复数据是，只需要更新LSN大于较大的checkpoint的值的重做日志就可以。<br><img src="https://github.com/gamesdoa/img0/raw/master/mysql/redo-log/InnoDB%E4%B8%AD%E5%90%84%E7%A7%8DLSN.jpg" alt="InnoDB中的各种LSN"></p>
<blockquote>
<p>除了重做日志缓冲在事务提交时需要刷新到磁盘外，其他的LSN信息都是异步的刷新到持久存储上。</p>
</blockquote>
<h2 id="组提交"><a href="#组提交" class="headerlink" title="组提交"></a>组提交</h2><p>我们知道事务提交时为了确保重做日志持久化到磁盘上，需要调用一次fsync操作，而fsync性能又比较低，那么为了提高数据库性能，所以提出了组提交的概念。</p>
<p>当重做日志缓冲刷新到重做日志文件时，InnoDB存储引擎会对最后一个操作日志块进行复制，为什么要这样实现？原因是：重做日志文件的写入都是由缓存写的，fsync操作在log-&gt;mutex之后，这样使其他事物可以继续将重做日志写入到redo log buffer中，实现组提交功能。</p>
<h2 id="重做日志恢复"><a href="#重做日志恢复" class="headerlink" title="重做日志恢复"></a>重做日志恢复</h2><p>如何判断数据库是否需要恢复：数据库关闭时最后刷新页的LSN和重做日志中保存的检查点比较，如果相等，则不需要恢复，否则需要恢复，查找重做日志文件中的两个检查点的较大值，恢复区间为最后刷新页的LSN到重做日志文件最大检查点之间的数据。<br>恢复方式是：每次读取64KB（64K/512=128个重做日志块），进行分析，判断重做日志块中的日志是否包含上一个日志的内容(一个日志存在于多个日志块中)，之后根据日志对于的（space，offset）的哈希值插入到哈希表，最后根据哈希表中的日志进行页的恢复。</p>
]]></content>
    
    <summary type="html">
    
      mysql的InnoDB存储引擎通过redo log实现事务的持久化，那么redo log的实现原理是怎么样的呢？LSN的作用是什么，为什么LSN会贯穿整个redo log的实现中？检查点又是来做什么的？redo log的架构是怎么样的？为什么说redo log不需要使用doublewrite技术？为了提供数据库性能，redo log做了哪些优化？且听小生慢慢道来。
    
    </summary>
    
      <category term="mysql" scheme="http://gamesdoa.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://gamesdoa.com/tags/mysql/"/>
    
      <category term="redo log" scheme="http://gamesdoa.com/tags/redo-log/"/>
    
  </entry>
  
  <entry>
    <title>hexo 随笔</title>
    <link href="http://gamesdoa.com/hexo.html"/>
    <id>http://gamesdoa.com/hexo.html</id>
    <published>2017-04-30T16:00:00.000Z</published>
    <updated>2017-08-22T04:30:26.435Z</updated>
    
    <content type="html"><![CDATA[<h2 id="本地预览hexo创建的blog"><a href="#本地预览hexo创建的blog" class="headerlink" title="本地预览hexo创建的blog"></a>本地预览hexo创建的blog</h2><pre><code>hexo s
是简写：hexo server
</code></pre><h2 id="发布本地文件到github库"><a href="#发布本地文件到github库" class="headerlink" title="发布本地文件到github库"></a>发布本地文件到github库</h2><pre><code>hexo clean  //清理
hexo g         //重新构建    
hexo d        //发布
</code></pre>]]></content>
    
    <summary type="html">
    
      hexo常用命令
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo的next主题优化定制</title>
    <link href="http://gamesdoa.com/hexo-next-tailor-made.html"/>
    <id>http://gamesdoa.com/hexo-next-tailor-made.html</id>
    <published>2017-04-30T16:00:00.000Z</published>
    <updated>2020-08-05T08:50:25.465Z</updated>
    
    <content type="html"><![CDATA[<p>刚开始使用next主题，需要慢慢折腾，在折腾过程中，遇到的问题记录下来，做个备忘。</p>
<h2 id="调整首页博文之间的间距"><a href="#调整首页博文之间的间距" class="headerlink" title="调整首页博文之间的间距"></a>调整首页博文之间的间距</h2><h3 id="博文间的距离"><a href="#博文间的距离" class="headerlink" title="博文间的距离"></a>博文间的距离</h3><p>想让首页的博文之间的间距缩小一些，看着紧凑些，如此处理呢？其实只需要修改themes\你的主题\source\css_variables\base.styl文件内的$post-eof-margin-top和$post-eof-margin-bottom这两个值，影响的是博文之间分割线的上下间距，如果想紧凑就调小，如果想宽松就是放大。</p>
<h3 id="博文描述与全文阅读之间的间距"><a href="#博文描述与全文阅读之间的间距" class="headerlink" title="博文描述与全文阅读之间的间距"></a>博文描述与全文阅读之间的间距</h3><p>看着博文描述与全文阅读按钮之间的间距太宽？这里也是可以修改的，需要修改的文件路径是themes\你的主题\source\css_common\components\post\post-button.styl，查找并调整。</p>
<pre><code>.post-button {
    margin-top: 60px; //默认60个像素，可以根据自己的需求调整大小
</code></pre><h3 id="调整博文作者行和博文描述的间距"><a href="#调整博文作者行和博文描述的间距" class="headerlink" title="调整博文作者行和博文描述的间距"></a>调整博文作者行和博文描述的间距</h3><p>感觉博文作者行与博文描述间的具体太宽？或者你感觉还不够？怎么办呢？其实只需要修改themes\你的主题\source\css_common\components\post\post-meta.styl文件内的</p>
<pre><code>.posts-expand .post-meta {
    margin: 3px 0 60px 0; 
    //修改这里的第三个值的大小就可以实现修改博文作者行与博文描述间的距离
    //第一个值是干什么的？你也好奇？其实只是修改博文作者行与上面博文标题的间距的，你可以调整试一下
    color: $grey-dark;
    font-family: $font-family-posts;
    font-size: 12px;
    text-align: center;
</code></pre><h2 id="调整博文阅读区域"><a href="#调整博文阅读区域" class="headerlink" title="调整博文阅读区域"></a>调整博文阅读区域</h2><p>我感觉博文阅读区域太窄了，看着不舒服，怎么办？其实很简单的，只需要修改themes\你的主题\source\css_schemes\Pisces_layout.styl内的</p>
<pre><code>//这一部分调整侧边栏博客描述以及导航信息
.header {
    position: relative;
    margin: 0 auto;
    width: 70%; //直接设置百分比，你想调整多少就多少

//这一部分调整博文以及目录信息
.container .main-inner {
    width: 70%;
</code></pre><blockquote>
<p>这里针对Pisces主题的设置，原来的设计思路是显示器小于1600像素时阅读区展示700px，大于1600像素时阅读区展示900px。其实这里需要在行宽以及阅读舒适度方面做一个折中，毕竟单独的设置宽度太宽，阅读起来也不是很友好不是？ 就个人而言，太宽有时候会看串行啊。</p>
</blockquote>
<h2 id="在侧边栏添加邮箱"><a href="#在侧边栏添加邮箱" class="headerlink" title="在侧边栏添加邮箱"></a>在侧边栏添加邮箱</h2><p>在<strong>主题配置文件</strong> source/_data/next.yml 中添加social配置：</p>
<pre><code># Social links
social:
  Email: mailto:gamesdoa@gmail.com

social_icons:
  enable: true
  Email: envelope
</code></pre><p>其他的还在慢慢折腾，有其他问题随时补充。</p>
]]></content>
    
    <summary type="html">
    
      首页每个博文展示之间的宽度太宽？我怎么样才能调窄一些让它看起来紧凑一些？看着net的布局中内容展示区太窄，如何定制next主题阅读器宽度？
    
    </summary>
    
      <category term="hexo" scheme="http://gamesdoa.com/categories/hexo/"/>
    
    
      <category term="hexo" scheme="http://gamesdoa.com/tags/hexo/"/>
    
      <category term="next" scheme="http://gamesdoa.com/tags/next/"/>
    
  </entry>
  
</feed>
